2025-06-16 16:42:26,977	INFO worker.py:1843 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
2025-06-16 16:42:27,636 - INFO - Random seeds set to 42
2025-06-16 16:42:27,736 - INFO - Optional negatives loaded from CSV with 5000 entries.
2025-06-16 16:42:27,736 - INFO - Loading original negatives...
2025-06-16 16:42:27,745 - INFO - Negatives column names: ['Article ID', 'Title', 'Author', 'Publication year', 'Title secondary', 'URL', 'DOI', 'Abstract', 'Criteria for exclusion A', ' Criteria for exclusion B', ' Criteria for exclusion C', 'labels', 'Keywords']
2025-06-16 16:42:27,745 - INFO - Loading original positives...
2025-06-16 16:42:27,762 - INFO - Positives column names: ['Article ID', 'Title', 'Author', 'Secondary authors', 'Keywords', 'title of unpublished reference', 'primary date', 'publication year', 'notes', 'reprint status', 'start page number', 'ending page number', 'periodical full name', 'periodical standard abbreviation', 'periodical in which article was published', 'periodical name - user abbreviation 1', 'periodical name - user abbreviation 2', 'volume number', 'issue number', 'title secondary', 'city of publication', 'publisher', 'user definable 1', 'user definable 5', 'title series', 'Abstract', 'ISSN/ISBN', 'availability', 'Misc. 1', 'Misc. 2', 'address', 'Web/URL', 'link to PDF', 'link to full-text', 'related records', 'images', 'DOI', 'labels']
2025-06-16 16:42:27,767 - INFO - Class balance:
labels
1    326
0    123
Name: count, dtype: int64
2025-06-16 16:42:27,767 - INFO -    Article ID  ...  Criteria for exclusion C
0       12959  ...                       NaN
1       13470  ...                       NaN
2        4686  ...                       NaN
3        2503  ...                       NaN
4        2951  ...                       NaN

[5 rows x 44 columns]
2025-06-16 16:42:27,791 - INFO - Original dataset size: 449
2025-06-16 16:42:27,791 - INFO - Optional negatives size: 5000
2025-06-16 16:42:27,796 - INFO - Optional negatives:                                                title  ... labels
0  Towards evidence-based conservation of subterr...  ...     -1
1                  Marine biodiversity conservation.  ...     -1
2  Climate teleconnections modulate global burned...  ...     -1
3  Integrating carbon sequestration and biodivers...  ...     -1
4  Principle, technique and application of grassl...  ...     -1

[5 rows x 7 columns]
2025-06-16 16:42:27,800 - INFO - Combined dataset size: 549
2025-06-16 16:42:27,800 - INFO - Before cleaning, head:
                                               title  ... labels
0  Feral pig (Sus scrofa) disturbance facilitates...  ...      1
1  Effects of woody plant diversity on abovegroun...  ...      1
2  Scaling species richness and endemism of tropi...  ...      1
3  Not as the crow flies: Assessing effective iso...  ...      0
4  Species-group concepts and biogeography of the...  ...      1

[5 rows x 5 columns]
2025-06-16 16:42:27,805 - INFO - Null counts before cleaning:
title        0
abstract     0
Keywords     8
doi         36
labels       0
dtype: int64
2025-06-16 16:42:27,808 - INFO - Total duplicate title: 0
2025-06-16 16:42:27,811 - INFO - Conflicts on title (same value, multiple labels):
Empty DataFrame
Columns: [title, n_labels]
Index: []
2025-06-16 16:42:27,814 - INFO - Total duplicate abstract: 0
2025-06-16 16:42:27,820 - INFO - Conflicts on abstract (same value, multiple labels):
Empty DataFrame
Columns: [abstract, n_labels]
Index: []
2025-06-16 16:42:27,822 - INFO - Total duplicate doi: 18
2025-06-16 16:42:27,824 - INFO - Conflicts on doi (same value, multiple labels):
Empty DataFrame
Columns: [doi, n_labels]
Index: []
2025-06-16 16:42:27,825 - INFO - Cleaned dataset size: 497
2025-06-16 16:42:27,825 - INFO - Number of positives : 293
2025-06-16 16:42:27,826 - INFO - Number of negatives : 204
2025-06-16 16:42:27,826 - INFO - clean_og_df size : 397
2025-06-16 16:42:27,826 - INFO - opt_neg_df size : 100
2025-06-16 16:42:27,830 - INFO - Fold 1:
2025-06-16 16:42:27,830 - INFO -   Train label distribution: {1: 0.5192878338278932, -1: 0.29673590504451036, 0: 0.18397626112759644}
2025-06-16 16:42:27,831 - INFO -   Test label distribution: {1: 0.7375, 0: 0.2625}
2025-06-16 16:42:27,833 - INFO - Fold 2:
2025-06-16 16:42:27,833 - INFO -   Train label distribution: {1: 0.5192878338278932, -1: 0.29673590504451036, 0: 0.18397626112759644}
2025-06-16 16:42:27,833 - INFO -   Test label distribution: {1: 0.7375, 0: 0.2625}
2025-06-16 16:42:27,835 - INFO - Fold 3:
2025-06-16 16:42:27,835 - INFO -   Train label distribution: {1: 0.5177514792899408, -1: 0.2958579881656805, 0: 0.1863905325443787}
2025-06-16 16:42:27,835 - INFO -   Test label distribution: {1: 0.7468354430379747, 0: 0.25316455696202533}
2025-06-16 16:42:27,837 - INFO - Fold 4:
2025-06-16 16:42:27,838 - INFO -   Train label distribution: {1: 0.5207100591715976, -1: 0.2958579881656805, 0: 0.1834319526627219}
2025-06-16 16:42:27,838 - INFO -   Test label distribution: {1: 0.7341772151898734, 0: 0.26582278481012656}
2025-06-16 16:42:27,840 - INFO - Fold 5:
2025-06-16 16:42:27,840 - INFO -   Train label distribution: {1: 0.5207100591715976, -1: 0.2958579881656805, 0: 0.1834319526627219}
2025-06-16 16:42:27,840 - INFO -   Test label distribution: {1: 0.7341772151898734, 0: 0.26582278481012656}
2025-06-16 16:42:27,843 - INFO - Fold 1:
2025-06-16 16:42:27,843 - INFO -   Train label distribution: {1: 0.5192878338278932, -1: 0.29673590504451036, 0: 0.18397626112759644}
2025-06-16 16:42:27,843 - INFO -   Test label distribution: {1: 0.7375, 0: 0.2625}
2025-06-16 16:42:27,845 - INFO - Fold 2:
2025-06-16 16:42:27,845 - INFO -   Train label distribution: {1: 0.5192878338278932, -1: 0.29673590504451036, 0: 0.18397626112759644}
2025-06-16 16:42:27,845 - INFO -   Test label distribution: {1: 0.7375, 0: 0.2625}
2025-06-16 16:42:27,847 - INFO - Fold 3:
2025-06-16 16:42:27,847 - INFO -   Train label distribution: {1: 0.5177514792899408, -1: 0.2958579881656805, 0: 0.1863905325443787}
2025-06-16 16:42:27,847 - INFO -   Test label distribution: {1: 0.7468354430379747, 0: 0.25316455696202533}
2025-06-16 16:42:27,849 - INFO - Fold 4:
2025-06-16 16:42:27,849 - INFO -   Train label distribution: {1: 0.5207100591715976, -1: 0.2958579881656805, 0: 0.1834319526627219}
2025-06-16 16:42:27,849 - INFO -   Test label distribution: {1: 0.7341772151898734, 0: 0.26582278481012656}
2025-06-16 16:42:27,851 - INFO - Fold 5:
2025-06-16 16:42:27,852 - INFO -   Train label distribution: {1: 0.5207100591715976, -1: 0.2958579881656805, 0: 0.1834319526627219}
2025-06-16 16:42:27,852 - INFO -   Test label distribution: {1: 0.7341772151898734, 0: 0.26582278481012656}
2025-06-16 16:42:27,852 - INFO - Indices of clean_df remain the same after resetting.
2025-06-16 16:42:27,865 - INFO - clean_df index : RangeIndex(start=0, stop=497, step=1)
Stringifying the column:   0%|          | 0/497 [00:00<?, ? examples/s]Stringifying the column: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 497/497 [00:00<00:00, 98663.82 examples/s]
Casting to class labels:   0%|          | 0/497 [00:00<?, ? examples/s]Casting to class labels: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 497/497 [00:00<00:00, 113836.23 examples/s]
2025-06-16 16:42:27,880 - INFO - Number of positives : 293
2025-06-16 16:42:27,880 - INFO - Number of negatives : 204
2025-06-16 16:42:27,881 - INFO - All 5 testâ€folds in run 1 are pairwise disjoint.
2025-06-16 16:42:27,881 - INFO - All 5 testâ€folds in run 2 are pairwise disjoint.
2025-06-16 16:42:27,884 - INFO - Confusion matrix: TN=0, FP=21, FN=0, TP=59
2025-06-16 16:42:30,625 - INFO - Metrics: {'f1': 0.8489208633093526, 'recall': 1.0, 'precision': 0.7375, 'accuracy': 0.7375, 'AP': 0.7375, 'MCC': 0.0, 'NDCG': 0.9120270205293689, 'kappa': 0.0, 'TN': 0, 'FP': 21, 'FN': 0, 'TP': 59}
2025-06-16 16:42:30,628 - INFO - Confusion matrix: TN=21, FP=0, FN=59, TP=0
/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-16 16:42:33,342 - INFO - Metrics: {'f1': 0.0, 'recall': 0.0, 'precision': 0.0, 'accuracy': 0.2625, 'AP': 0.7375, 'MCC': 0.0, 'NDCG': 0.9120270205293689, 'kappa': 0.0, 'TN': 21, 'FP': 0, 'FN': 59, 'TP': 0}
2025-06-16 16:42:33,345 - INFO - Confusion matrix: TN=0, FP=21, FN=0, TP=59
2025-06-16 16:42:36,144 - INFO - Metrics: {'f1': 0.8489208633093526, 'recall': 1.0, 'precision': 0.7375, 'accuracy': 0.7375, 'AP': 0.7375, 'MCC': 0.0, 'NDCG': 0.9120270205293689, 'kappa': 0.0, 'TN': 0, 'FP': 21, 'FN': 0, 'TP': 59}
2025-06-16 16:42:36,146 - INFO - Confusion matrix: TN=21, FP=0, FN=59, TP=0
/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-16 16:42:38,907 - INFO - Metrics: {'f1': 0.0, 'recall': 0.0, 'precision': 0.0, 'accuracy': 0.2625, 'AP': 0.7375, 'MCC': 0.0, 'NDCG': 0.9120270205293689, 'kappa': 0.0, 'TN': 21, 'FP': 0, 'FN': 59, 'TP': 0}
2025-06-16 16:42:38,910 - INFO - Confusion matrix: TN=0, FP=20, FN=0, TP=59
2025-06-16 16:42:41,642 - INFO - Metrics: {'f1': 0.855072463768116, 'recall': 1.0, 'precision': 0.7468354430379747, 'accuracy': 0.7468354430379747, 'AP': 0.7468354430379747, 'MCC': 0.0, 'NDCG': 0.9154183363805276, 'kappa': 0.0, 'TN': 0, 'FP': 20, 'FN': 0, 'TP': 59}
2025-06-16 16:42:41,644 - INFO - Confusion matrix: TN=20, FP=0, FN=59, TP=0
/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-16 16:42:44,752 - INFO - Metrics: {'f1': 0.0, 'recall': 0.0, 'precision': 0.0, 'accuracy': 0.25316455696202533, 'AP': 0.7468354430379747, 'MCC': 0.0, 'NDCG': 0.9154183363805276, 'kappa': 0.0, 'TN': 20, 'FP': 0, 'FN': 59, 'TP': 0}
2025-06-16 16:42:44,756 - INFO - Confusion matrix: TN=0, FP=21, FN=0, TP=58
2025-06-16 16:42:47,456 - INFO - Metrics: {'f1': 0.8467153284671532, 'recall': 1.0, 'precision': 0.7341772151898734, 'accuracy': 0.7341772151898734, 'AP': 0.7341772151898734, 'MCC': 0.0, 'NDCG': 0.9105722839842212, 'kappa': 0.0, 'TN': 0, 'FP': 21, 'FN': 0, 'TP': 58}
2025-06-16 16:42:47,458 - INFO - Confusion matrix: TN=21, FP=0, FN=58, TP=0
/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-16 16:42:50,463 - INFO - Metrics: {'f1': 0.0, 'recall': 0.0, 'precision': 0.0, 'accuracy': 0.26582278481012656, 'AP': 0.7341772151898734, 'MCC': 0.0, 'NDCG': 0.9105722839842212, 'kappa': 0.0, 'TN': 21, 'FP': 0, 'FN': 58, 'TP': 0}
2025-06-16 16:42:50,467 - INFO - Confusion matrix: TN=0, FP=21, FN=0, TP=58
2025-06-16 16:42:53,125 - INFO - Metrics: {'f1': 0.8467153284671532, 'recall': 1.0, 'precision': 0.7341772151898734, 'accuracy': 0.7341772151898734, 'AP': 0.7341772151898734, 'MCC': 0.0, 'NDCG': 0.9105722839842212, 'kappa': 0.0, 'TN': 0, 'FP': 21, 'FN': 0, 'TP': 58}
2025-06-16 16:42:53,127 - INFO - Confusion matrix: TN=21, FP=0, FN=58, TP=0
/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-16 16:42:55,806 - INFO - Metrics: {'f1': 0.0, 'recall': 0.0, 'precision': 0.0, 'accuracy': 0.26582278481012656, 'AP': 0.7341772151898734, 'MCC': 0.0, 'NDCG': 0.9105722839842212, 'kappa': 0.0, 'TN': 21, 'FP': 0, 'FN': 58, 'TP': 0}
2025-06-16 16:42:55,809 - INFO - Metrics stored successfully at /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/metrics/naive_metrics.csv
2025-06-16 16:42:55,809 - INFO - with_title : True
2025-06-16 16:42:55,809 - INFO - with_keywords : False
2025-06-16 16:42:55,809 - INFO - fold indexes for run no.1: [[392, 341, 378, 173, 113, 324, 114, 177, 302, 216, 267, 44, 264, 187, 70, 68, 73, 226, 15, 300, 223, 163, 236, 337, 112, 65, 327, 12, 125, 385, 103, 43, 274, 330, 94, 220, 18, 225, 123, 199, 295, 120, 355, 389, 28, 137, 357, 23, 89, 134, 145, 339, 308, 171, 228, 356, 373, 76, 323, 203, 258, 222, 133, 111, 313, 36, 319, 375, 256, 61, 393, 175, 344, 116, 260, 3, 334, 396, 273, 107, 139, 60, 109, 303, 42, 194, 343, 248, 320, 332, 37, 4, 72, 81, 118, 146, 246, 135, 286, 151, 380, 183, 170, 46, 115, 346, 35, 189, 235, 237, 354, 55, 172, 278, 261, 150, 305, 368, 304, 395, 83, 161, 215, 325, 366, 162, 232, 105, 64, 127, 381, 269, 229, 205, 318, 59, 307, 96, 149, 136, 331, 24, 27, 99, 19, 252, 39, 309, 66, 144, 117, 292, 342, 168, 210, 247, 82, 374, 14, 169, 190, 348, 181, 376, 63, 159, 299, 377, 294, 121, 91, 192, 95, 391, 253, 204, 200, 148, 10, 358, 38, 138, 97, 265, 132, 104, 33, 209, 394, 243, 370, 31, 155, 321, 62, 126, 384, 387, 350, 263, 40, 369, 87, 48, 217, 54, 130, 276, 244, 2, 157, 6, 219, 317, 32, 336, 141, 268, 312, 166, 7, 49, 353, 196, 176, 185, 306, 207, 93, 21, 297, 77, 224, 233, 290, 41, 202, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496], [174, 311, 45, 242, 251, 241, 188, 102, 283, 250, 388, 239, 328, 255, 230, 84, 333, 29, 67, 279, 227, 338, 80, 211, 56, 315, 218, 206, 386, 129, 245, 158, 301, 262, 291, 314, 178, 8, 88, 254, 0, 57, 329, 367, 156, 266, 289, 284, 213, 147, 285, 296, 191, 322, 85, 214, 98, 100, 282, 212, 52, 53, 30, 51, 179, 131, 298, 167, 352, 326, 365, 92, 34, 363, 78, 26, 71, 1, 17, 50], [5, 9, 11, 13, 16, 20, 22, 25, 47, 58, 69, 74, 75, 79, 86, 90, 101, 106, 108, 110, 119, 122, 124, 128, 140, 142, 143, 152, 153, 154, 160, 164, 165, 180, 182, 184, 186, 193, 195, 197, 198, 201, 208, 221, 231, 234, 238, 240, 249, 257, 259, 270, 271, 272, 275, 277, 280, 281, 287, 288, 293, 310, 316, 335, 340, 345, 347, 349, 351, 359, 360, 361, 362, 364, 371, 372, 379, 382, 383, 390]]
2025-06-16 16:42:55,809 - INFO - Run no 1/2
2025-06-16 16:42:55,809 - INFO - Loss Type : BCE
2025-06-16 16:42:55,809 - INFO - Ensemble learning pipeline
2025-06-16 16:42:55,809 - INFO - Training model 1/5: microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract
2025-06-16 16:42:56,244 - INFO - Cleared CUDA cache. Memory allocated: 0.00 GB, Memory reserved: 0.00 GB
2025-06-16 16:42:56,244 - INFO - 
fold number 1 / 5
2025-06-16 16:42:56,249 - INFO - train split size : 337
2025-06-16 16:42:56,250 - INFO - dev split size : 80
2025-06-16 16:42:56,250 - INFO - test split size : 80
Map (num_proc=32):   0%|          | 0/337 [00:00<?, ? examples/s]Map (num_proc=32):   3%|â–Ž         | 11/337 [00:00<00:03, 85.27 examples/s]Map (num_proc=32):  20%|â–ˆâ–‰        | 66/337 [00:00<00:00, 314.33 examples/s]Map (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 121/337 [00:00<00:00, 374.43 examples/s]Map (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 176/337 [00:00<00:00, 428.80 examples/s]Map (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 237/337 [00:00<00:00, 442.92 examples/s]Map (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 287/337 [00:00<00:00, 457.64 examples/s]Map (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 337/337 [00:00<00:00, 465.24 examples/s]Map (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 337/337 [00:00<00:00, 378.54 examples/s]
Map (num_proc=32):   0%|          | 0/80 [00:00<?, ? examples/s]Map (num_proc=32):   4%|â–         | 3/80 [00:00<00:02, 29.67 examples/s]Map (num_proc=32):  22%|â–ˆâ–ˆâ–Ž       | 18/80 [00:00<00:00, 88.94 examples/s]Map (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/80 [00:00<00:00, 109.45 examples/s]Map (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 48/80 [00:00<00:00, 119.37 examples/s]Map (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [00:00<00:00, 111.12 examples/s]Map (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/80 [00:00<00:00, 102.14 examples/s]Map (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<00:00, 92.02 examples/s] 
Map (num_proc=32):   0%|          | 0/80 [00:00<?, ? examples/s]Map (num_proc=32):   4%|â–         | 3/80 [00:00<00:02, 27.65 examples/s]Map (num_proc=32):  22%|â–ˆâ–ˆâ–Ž       | 18/80 [00:00<00:00, 92.33 examples/s]Map (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/80 [00:00<00:00, 113.04 examples/s]Map (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 48/80 [00:00<00:00, 125.22 examples/s]Map (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 62/80 [00:00<00:00, 107.80 examples/s]Map (num_proc=32):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 74/80 [00:00<00:00, 102.98 examples/s]Map (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<00:00, 91.33 examples/s] 
2025-06-16 16:43:00,388 - INFO - 3 datasets tokenized successfully
2025-06-16 16:43:00,453 - INFO - Fold 1 max seq len = 512
2025-06-16 16:43:00,454 - INFO - Starting hyperparameter search for BCE loss
[36m(train_hpo pid=3775578)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3775578)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3775578)[0m 2025-06-16 16:43:09,207 - INFO - pos_weight value in TrainingArguments : 6.828424226204718
[36m(train_hpo pid=3775578)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3775578)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3775743)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3775743)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3775743)[0m 2025-06-16 16:43:15,750 - INFO - pos_weight value in TrainingArguments : 6.094080202241274
[36m(train_hpo pid=3775743)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3775743)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3775937)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3775937)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3775937)[0m 2025-06-16 16:43:22,150 - INFO - pos_weight value in TrainingArguments : 7.183206941666034
[36m(train_hpo pid=3775937)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3775937)[0m   super().__init__(*args, **kwargs)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Configuration for experiment     train_hpo_2025-06-16_16-43-00   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Search algorithm                 SearchGenerator                 â”‚
â”‚ Scheduler                        AsyncHyperBandScheduler         â”‚
â”‚ Number of trials                 12                              â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

View detailed results here: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00
To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-06-16_16-42-25_595113_3771642/artifacts/2025-06-16_16-43-00/train_hpo_2025-06-16_16-43-00/driver_artifacts`

Trial status: 1 PENDING
Current time: 2025-06-16 16:43:01. Total running time: 0s
Logical resource usage: 0/32 CPUs, 0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status       pos_weight     learning_rate     weight_decay     num_train_epochs â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_6f0497ae   PENDING         6.82842       1.49561e-06          0.13641                    6 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_6f0497ae started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_6f0497ae config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                             0 â”‚
â”‚ num_train_epochs                          6 â”‚
â”‚ pos_weight                          6.82842 â”‚
â”‚ weight_decay                        0.13641 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3775578)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})

Trial train_hpo_5b73a863 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_5b73a863 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                             0 â”‚
â”‚ num_train_epochs                          5 â”‚
â”‚ pos_weight                          6.09408 â”‚
â”‚ weight_decay                        0.12303 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3775743)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=20, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=5, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3775578)[0m {'loss': 1.6367, 'grad_norm': 7.283572196960449, 'learning_rate': 1.1840219327085947e-06, 'epoch': 1.0}

Trial train_hpo_a944c0bb started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_a944c0bb config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         8e-05 â”‚
â”‚ num_train_epochs                          3 â”‚
â”‚ pos_weight                          7.18321 â”‚
â”‚ weight_decay                        0.25122 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3775937)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3775937)[0m {'loss': 1.5206, 'grad_norm': 1.4995089769363403, 'learning_rate': 4.6597713532890536e-05, 'epoch': 1.0}

Trial status: 3 RUNNING | 1 PENDING
Current time: 2025-06-16 16:43:31. Total running time: 30s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status       pos_weight     learning_rate     weight_decay     num_train_epochs â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_6f0497ae   RUNNING         6.82842       1.49561e-06         0.13641                     6 â”‚
â”‚ train_hpo_5b73a863   RUNNING         6.09408       4.55539e-06         0.123031                    5 â”‚
â”‚ train_hpo_a944c0bb   RUNNING         7.18321       7.98818e-05         0.251217                    3 â”‚
â”‚ train_hpo_c92e5949   PENDING         7.43106       1.10121e-06         0.13345                     4 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[36m(train_hpo pid=3775937)[0m 2025-06-16 16:43:42,350 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3775937)[0m 2025-06-16 16:43:42,355 - INFO - eval_result: {'eval_loss': 0.9783954620361328, 'eval_f1': 0.855072463768116, 'eval_accuracy': 0.75, 'eval_kappa': 0.06868451688009314, 'eval_precision': 0.7468354430379747, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9081844091415405, 'eval_AP': 0.8126428274160886, 'eval_MCC': 0.18858311834736916, 'eval_NDCG': 0.9353500204594986, 'eval_runtime': 3.3463, 'eval_samples_per_second': 23.907, 'eval_steps_per_second': 1.195, 'epoch': 2.4705882352941178}
2025-06-16 16:43:42,722 - INFO - Cleaning up trial a944c0bb
2025-06-16 16:43:42,722 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_a944c0bb_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-43-14
[36m(train_hpo pid=3775937)[0m 2025-06-16 16:43:42,696 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
[36m(train_hpo pid=3776512)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3776512)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3776512)[0m 2025-06-16 16:43:50,707 - INFO - pos_weight value in TrainingArguments : 7.431057651685638
[36m(train_hpo pid=3776512)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3776512)[0m   super().__init__(*args, **kwargs)

[36m(train_hpo pid=3775937)[0m {'loss': 0.9507, 'grad_norm': 2.8773140907287598, 'learning_rate': 1.3313632437968722e-05, 'epoch': 2.0}[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(train_hpo pid=3775937)[0m {'train_runtime': 16.2124, 'train_samples_per_second': 62.36, 'train_steps_per_second': 0.74, 'train_loss': 1.177101194858551, 'epoch': 2.4705882352941178}
[36m(train_hpo pid=3775937)[0m STATE at ending of training  :  TrainerState(epoch=2.4705882352941178, global_step=12, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=219155152505688.0, log_history=[{'loss': 1.5206, 'grad_norm': 1.4995089769363403, 'learning_rate': 4.6597713532890536e-05, 'epoch': 1.0, 'step': 5}, {'loss': 0.9507, 'grad_norm': 2.8773140907287598, 'learning_rate': 1.3313632437968722e-05, 'epoch': 2.0, 'step': 10}, {'loss': 0.8842, 'grad_norm': 8.054903984069824, 'learning_rate': 0.0, 'epoch': 2.4705882352941178, 'step': 12}, {'train_runtime': 16.2124, 'train_samples_per_second': 62.36, 'train_steps_per_second': 0.74, 'total_flos': 219155152505688.0, 'train_loss': 1.177101194858551, 'epoch': 2.4705882352941178, 'step': 12}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3775937)[0m {'eval_loss': 0.9783954620361328, 'eval_f1': 0.855072463768116, 'eval_accuracy': 0.75, 'eval_kappa': 0.06868451688009314, 'eval_precision': 0.7468354430379747, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9081844091415405, 'eval_AP': 0.8126428274160886, 'eval_MCC': 0.18858311834736916, 'eval_NDCG': 0.9353500204594986, 'eval_runtime': 3.3463, 'eval_samples_per_second': 23.907, 'eval_steps_per_second': 1.195, 'epoch': 2.4705882352941178}
[36m(train_hpo pid=3775937)[0m {'loss': 0.8842, 'grad_norm': 8.054903984069824, 'learning_rate': 0.0, 'epoch': 2.4705882352941178}

Trial train_hpo_a944c0bb finished iteration 1 at 2025-06-16 16:43:42. Total running time: 41s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_a944c0bb result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    21.5057 â”‚
â”‚ time_total_s                        21.5057 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               2.47059 â”‚
â”‚ eval_AP                             0.81264 â”‚
â”‚ eval_MCC                            0.18858 â”‚
â”‚ eval_NDCG                           0.93535 â”‚
â”‚ eval_accuracy                          0.75 â”‚
â”‚ eval_f1                             0.85507 â”‚
â”‚ eval_kappa                          0.06868 â”‚
â”‚ eval_loss                            0.9784 â”‚
â”‚ eval_optim_threshold                0.90818 â”‚
â”‚ eval_precision                      0.74684 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.3463 â”‚
â”‚ eval_samples_per_second              23.907 â”‚
â”‚ eval_steps_per_second                 1.195 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_a944c0bb completed after 1 iterations at 2025-06-16 16:43:42. Total running time: 41s
[36m(train_hpo pid=3775578)[0m {'loss': 1.3951, 'grad_norm': 2.149923801422119, 'learning_rate': 5.608524944409133e-07, 'epoch': 3.0}

Trial train_hpo_c92e5949 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_c92e5949 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                             0 â”‚
â”‚ num_train_epochs                          4 â”‚
â”‚ pos_weight                          7.43106 â”‚
â”‚ weight_decay                        0.13345 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3776512)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3776512)[0m {'loss': 2.1167, 'grad_norm': 11.338726043701172, 'learning_rate': 7.570838612609137e-07, 'epoch': 1.0}[32m [repeated 2x across cluster][0m

Trial status: 3 RUNNING | 1 TERMINATED | 1 PENDING
Current time: 2025-06-16 16:44:01. Total running time: 1min 0s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_6f0497ae   RUNNING           6.82842       1.49561e-06         0.13641                     6                                                                                        â”‚
â”‚ train_hpo_5b73a863   RUNNING           6.09408       4.55539e-06         0.123031                    5                                                                                        â”‚
â”‚ train_hpo_c92e5949   RUNNING           7.43106       1.10121e-06         0.13345                     4                                                                                        â”‚
â”‚ train_hpo_a944c0bb   TERMINATED        7.18321       7.98818e-05         0.251217                    3        1            21.5057      0.978395    0.855072              0.75      0.0686845 â”‚
â”‚ train_hpo_2789f075   PENDING           2.2031        4.03208e-05         0.243719                    5                                                                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[36m(train_hpo pid=3776512)[0m 2025-06-16 16:44:15,599 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3776512)[0m 2025-06-16 16:44:15,605 - INFO - eval_result: {'eval_loss': 2.516695261001587, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.6548241376876831, 'eval_AP': 0.7424699854055901, 'eval_MCC': 0.0, 'eval_NDCG': 0.8816947722909534, 'eval_runtime': 3.3571, 'eval_samples_per_second': 23.83, 'eval_steps_per_second': 1.192, 'epoch': 3.235294117647059}
2025-06-16 16:44:15,864 - INFO - Cleaning up trial c92e5949
2025-06-16 16:44:15,865 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_c92e5949_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-43-21
2025-06-16 16:44:15,865 - INFO - Current best: a944c0bb with eval_kappa : 0.06868451688009314 at iteration 1
[36m(train_hpo pid=3776512)[0m 2025-06-16 16:44:15,844 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB

[36m(train_hpo pid=3776512)[0m {'loss': 1.9286, 'grad_norm': 9.064620018005371, 'learning_rate': 4.129548334150438e-07, 'epoch': 2.0}[32m [repeated 3x across cluster][0m
[36m(train_hpo pid=3776512)[0m {'loss': 1.8598, 'grad_norm': 5.115418434143066, 'learning_rate': 6.882580556917397e-08, 'epoch': 3.0}
[36m(train_hpo pid=3776512)[0m {'loss': 2.1796, 'grad_norm': 34.17715072631836, 'learning_rate': 0.0, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3776512)[0m {'train_runtime': 21.0591, 'train_samples_per_second': 64.01, 'train_steps_per_second': 0.76, 'train_loss': 1.981555849313736, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3776512)[0m STATE at ending of training  :  TrainerState(epoch=3.235294117647059, global_step=16, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=286774086604632.0, log_history=[{'loss': 2.1167, 'grad_norm': 11.338726043701172, 'learning_rate': 7.570838612609137e-07, 'epoch': 1.0, 'step': 5}, {'loss': 1.9286, 'grad_norm': 9.064620018005371, 'learning_rate': 4.129548334150438e-07, 'epoch': 2.0, 'step': 10}, {'loss': 1.8598, 'grad_norm': 5.115418434143066, 'learning_rate': 6.882580556917397e-08, 'epoch': 3.0, 'step': 15}, {'loss': 2.1796, 'grad_norm': 34.17715072631836, 'learning_rate': 0.0, 'epoch': 3.235294117647059, 'step': 16}, {'train_runtime': 21.0591, 'train_samples_per_second': 64.01, 'train_steps_per_second': 0.76, 'total_flos': 286774086604632.0, 'train_loss': 1.981555849313736, 'epoch': 3.235294117647059, 'step': 16}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3775578)[0m STATE at ending of training  :  TrainerState(epoch=4.9411764705882355, global_step=24, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=438587802461016.0, log_history=[{'loss': 1.6367, 'grad_norm': 7.283572196960449, 'learning_rate': 1.1840219327085947e-06, 'epoch': 1.0, 'step': 5}, {'loss': 1.4662, 'grad_norm': 5.064402103424072, 'learning_rate': 8.724372135747541e-07, 'epoch': 2.0, 'step': 10}, {'loss': 1.3951, 'grad_norm': 2.149923801422119, 'learning_rate': 5.608524944409133e-07, 'epoch': 3.0, 'step': 15}, {'loss': 1.3532, 'grad_norm': 2.953418254852295, 'learning_rate': 2.4926777530707256e-07, 'epoch': 4.0, 'step': 20}, {'loss': 1.563, 'grad_norm': 12.39674186706543, 'learning_rate': 0.0, 'epoch': 4.9411764705882355, 'step': 24}, {'train_runtime': 65.7142, 'train_samples_per_second': 30.77, 'train_steps_per_second': 0.365, 'total_flos': 438587802461016.0, 'train_loss': 1.479493776957194, 'epoch': 4.9411764705882355, 'step': 24}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3776512)[0m {'eval_loss': 2.516695261001587, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.6548241376876831, 'eval_AP': 0.7424699854055901, 'eval_MCC': 0.0, 'eval_NDCG': 0.8816947722909534, 'eval_runtime': 3.3571, 'eval_samples_per_second': 23.83, 'eval_steps_per_second': 1.192, 'epoch': 3.235294117647059}

Trial train_hpo_c92e5949 finished iteration 1 at 2025-06-16 16:44:15. Total running time: 1min 14s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_c92e5949 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    25.9862 â”‚
â”‚ time_total_s                        25.9862 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               3.23529 â”‚
â”‚ eval_AP                             0.74247 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.88169 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                            2.5167 â”‚
â”‚ eval_optim_threshold                0.65482 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.3571 â”‚
â”‚ eval_samples_per_second               23.83 â”‚
â”‚ eval_steps_per_second                 1.192 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_c92e5949 completed after 1 iterations at 2025-06-16 16:44:15. Total running time: 1min 14s
[36m(train_hpo pid=3775743)[0m {'loss': 1.2485, 'grad_norm': 3.051130533218384, 'learning_rate': 0.0, 'epoch': 4.0}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3775743)[0m {'train_runtime': 60.0926, 'train_samples_per_second': 28.04, 'train_steps_per_second': 0.333, 'train_loss': 1.5731520175933837, 'epoch': 4.0}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3775743)[0m STATE at ending of training  :  TrainerState(epoch=4.0, global_step=20, max_steps=20, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=5, num_input_tokens_seen=0, total_flos=354393020703576.0, log_history=[{'loss': 2.1297, 'grad_norm': 9.073959350585938, 'learning_rate': 3.416543648145448e-06, 'epoch': 1.0, 'step': 5}, {'loss': 1.5834, 'grad_norm': 5.10286808013916, 'learning_rate': 2.2776957654302987e-06, 'epoch': 2.0, 'step': 10}, {'loss': 1.331, 'grad_norm': 2.515691041946411, 'learning_rate': 1.1388478827151493e-06, 'epoch': 3.0, 'step': 15}, {'loss': 1.2485, 'grad_norm': 3.051130533218384, 'learning_rate': 0.0, 'epoch': 4.0, 'step': 20}, {'train_runtime': 60.0926, 'train_samples_per_second': 28.04, 'train_steps_per_second': 0.333, 'total_flos': 354393020703576.0, 'train_loss': 1.5731520175933837, 'epoch': 4.0, 'step': 20}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})

Trial train_hpo_6f0497ae finished iteration 1 at 2025-06-16 16:44:19. Total running time: 1min 18s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_6f0497ae result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    71.3551 â”‚
â”‚ time_total_s                        71.3551 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               4.94118 â”‚
â”‚ eval_AP                              0.7498 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.92513 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           1.61995 â”‚
â”‚ eval_optim_threshold                0.78002 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         4.0061 â”‚
â”‚ eval_samples_per_second               19.97 â”‚
â”‚ eval_steps_per_second                 0.998 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯2025-06-16 16:44:19,716 - INFO - Cleaning up trial 6f0497ae
2025-06-16 16:44:19,716 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_6f0497ae_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-43-01
2025-06-16 16:44:19,716 - INFO - Current best: a944c0bb with eval_kappa : 0.06868451688009314 at iteration 1
2025-06-16 16:44:19,716 - INFO - Cleaning up trial c92e5949
2025-06-16 16:44:19,716 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_c92e5949_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-43-21
2025-06-16 16:44:20,104 - INFO - Cleaning up trial 5b73a863
2025-06-16 16:44:20,104 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_5b73a863_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-43-08
2025-06-16 16:44:20,104 - INFO - Cleaning up trial 6f0497ae
2025-06-16 16:44:20,104 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_6f0497ae_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-43-01
2025-06-16 16:44:20,105 - INFO - Current best: a944c0bb with eval_kappa : 0.06868451688009314 at iteration 1
2025-06-16 16:44:20,105 - INFO - Cleaning up trial c92e5949
2025-06-16 16:44:20,105 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_c92e5949_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-43-21
[36m(train_hpo pid=3777185)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3777185)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3775743)[0m 2025-06-16 16:44:19,840 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3775743)[0m 2025-06-16 16:44:19,845 - INFO - eval_result: {'eval_loss': 1.4940340518951416, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.7497521042823792, 'eval_AP': 0.7086592636370473, 'eval_MCC': 0.0, 'eval_NDCG': 0.8626533283038593, 'eval_runtime': 3.3566, 'eval_samples_per_second': 23.834, 'eval_steps_per_second': 1.192, 'epoch': 4.0}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3775743)[0m 2025-06-16 16:44:20,083 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3777185)[0m 2025-06-16 16:44:23,789 - INFO - pos_weight value in TrainingArguments : 2.2031009297759248
[36m(train_hpo pid=3777185)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3777185)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3777403)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3777403)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3777403)[0m 2025-06-16 16:44:30,163 - INFO - pos_weight value in TrainingArguments : 4.066204305086463
[36m(train_hpo pid=3777403)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3777403)[0m   super().__init__(*args, **kwargs)


Trial train_hpo_6f0497ae completed after 1 iterations at 2025-06-16 16:44:19. Total running time: 1min 18s

Trial train_hpo_5b73a863 finished iteration 1 at 2025-06-16 16:44:20. Total running time: 1min 18s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_5b73a863 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    65.2246 â”‚
â”‚ time_total_s                        65.2246 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                                     4 â”‚
â”‚ eval_AP                             0.70866 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.86265 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           1.49403 â”‚
â”‚ eval_optim_threshold                0.74975 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.3566 â”‚
â”‚ eval_samples_per_second              23.834 â”‚
â”‚ eval_steps_per_second                 1.192 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_5b73a863 completed after 1 iterations at 2025-06-16 16:44:20. Total running time: 1min 18s

Trial train_hpo_2789f075 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_2789f075 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         4e-05 â”‚
â”‚ num_train_epochs                          5 â”‚
â”‚ pos_weight                           2.2031 â”‚
â”‚ weight_decay                        0.24372 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3777185)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=20, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=5, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3775743)[0m {'eval_loss': 1.4940340518951416, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.7497521042823792, 'eval_AP': 0.7086592636370473, 'eval_MCC': 0.0, 'eval_NDCG': 0.8626533283038593, 'eval_runtime': 3.3566, 'eval_samples_per_second': 23.834, 'eval_steps_per_second': 1.192, 'epoch': 4.0}[32m [repeated 2x across cluster][0m

Trial train_hpo_62009dba started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_62009dba config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         3e-05 â”‚
â”‚ num_train_epochs                          3 â”‚
â”‚ pos_weight                           4.0662 â”‚
â”‚ weight_decay                        0.23987 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3777403)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3777185)[0m {'loss': 0.8549, 'grad_norm': 1.3033922910690308, 'learning_rate': 3.0240629384992103e-05, 'epoch': 1.0}

Trial status: 4 TERMINATED | 2 RUNNING | 1 PENDING
Current time: 2025-06-16 16:44:31. Total running time: 1min 30s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_2789f075   RUNNING           2.2031        4.03208e-05         0.243719                    5                                                                                        â”‚
â”‚ train_hpo_62009dba   RUNNING           4.0662        2.70039e-05         0.239866                    3                                                                                        â”‚
â”‚ train_hpo_6f0497ae   TERMINATED        6.82842       1.49561e-06         0.13641                     6        1            71.3551      1.61995     0.848921            0.7375      0         â”‚
â”‚ train_hpo_5b73a863   TERMINATED        6.09408       4.55539e-06         0.123031                    5        1            65.2246      1.49403     0.848921            0.7375      0         â”‚
â”‚ train_hpo_a944c0bb   TERMINATED        7.18321       7.98818e-05         0.251217                    3        1            21.5057      0.978395    0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_c92e5949   TERMINATED        7.43106       1.10121e-06         0.13345                     4        1            25.9862      2.5167      0.848921            0.7375      0         â”‚
â”‚ train_hpo_a57815fe   PENDING           7.57559       4.00602e-05         0.220208                    4                                                                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[36m(train_hpo pid=3777592)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3777592)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3777592)[0m 2025-06-16 16:44:36,650 - INFO - pos_weight value in TrainingArguments : 7.5755881632194
[36m(train_hpo pid=3777592)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3777592)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3777185)[0m 2025-06-16 16:44:53,770 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3777185)[0m 2025-06-16 16:44:53,775 - INFO - eval_result: {'eval_loss': 0.7435033917427063, 'eval_f1': 0.8507462686567164, 'eval_accuracy': 0.75, 'eval_kappa': 0.14438502673796794, 'eval_precision': 0.76, 'eval_recall': 0.9661016949152542, 'eval_optim_threshold': 0.7824934124946594, 'eval_AP': 0.8673144903802993, 'eval_MCC': 0.1980534816610477, 'eval_NDCG': 0.9682996079474591, 'eval_runtime': 3.4023, 'eval_samples_per_second': 23.514, 'eval_steps_per_second': 1.176, 'epoch': 4.0}
2025-06-16 16:44:54,041 - INFO - Cleaning up trial 2789f075
2025-06-16 16:44:54,041 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_2789f075_5_learning_rate=0.0000,num_train_epochs=5,pos_weight=2.2031,weight_decay=0.2437_2025-06-16_16-43-49
2025-06-16 16:44:54,041 - INFO - Cleaning up trial 6f0497ae
2025-06-16 16:44:54,041 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_6f0497ae_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-43-01
2025-06-16 16:44:54,041 - INFO - Cleaning up trial 5b73a863
2025-06-16 16:44:54,042 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_5b73a863_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-43-08
2025-06-16 16:44:54,042 - INFO - Cleaning up trial a944c0bb
2025-06-16 16:44:54,042 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_a944c0bb_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-43-14
2025-06-16 16:44:54,042 - INFO - Cleaning up trial c92e5949
2025-06-16 16:44:54,042 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_c92e5949_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-43-21
[36m(train_hpo pid=3777185)[0m 2025-06-16 16:44:54,019 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB


Trial train_hpo_a57815fe started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_a57815fe config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         4e-05 â”‚
â”‚ num_train_epochs                          4 â”‚
â”‚ pos_weight                          7.57559 â”‚
â”‚ weight_decay                        0.22021 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3777592)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3777185)[0m {'loss': 0.7196, 'grad_norm': 2.2700107097625732, 'learning_rate': 2.0160419589994734e-05, 'epoch': 2.0}
[36m(train_hpo pid=3777185)[0m {'loss': 0.599, 'grad_norm': 2.0014395713806152, 'learning_rate': 1.0080209794997367e-05, 'epoch': 3.0}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3777185)[0m {'train_runtime': 26.0746, 'train_samples_per_second': 64.622, 'train_steps_per_second': 0.767, 'train_loss': 0.6736701607704163, 'epoch': 4.0}
[36m(train_hpo pid=3777185)[0m STATE at ending of training  :  TrainerState(epoch=4.0, global_step=20, max_steps=20, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=5, num_input_tokens_seen=0, total_flos=354393020703576.0, log_history=[{'loss': 0.8549, 'grad_norm': 1.3033922910690308, 'learning_rate': 3.0240629384992103e-05, 'epoch': 1.0, 'step': 5}, {'loss': 0.7196, 'grad_norm': 2.2700107097625732, 'learning_rate': 2.0160419589994734e-05, 'epoch': 2.0, 'step': 10}, {'loss': 0.599, 'grad_norm': 2.0014395713806152, 'learning_rate': 1.0080209794997367e-05, 'epoch': 3.0, 'step': 15}, {'loss': 0.5212, 'grad_norm': 1.7147799730300903, 'learning_rate': 0.0, 'epoch': 4.0, 'step': 20}, {'train_runtime': 26.0746, 'train_samples_per_second': 64.622, 'train_steps_per_second': 0.767, 'total_flos': 354393020703576.0, 'train_loss': 0.6736701607704163, 'epoch': 4.0, 'step': 20}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3777185)[0m {'loss': 0.5212, 'grad_norm': 1.7147799730300903, 'learning_rate': 0.0, 'epoch': 4.0}
[36m(train_hpo pid=3777403)[0m {'loss': 0.8718, 'grad_norm': 2.489725351333618, 'learning_rate': 4.50065034364224e-06, 'epoch': 2.0}
[36m(train_hpo pid=3777185)[0m {'eval_loss': 0.7435033917427063, 'eval_f1': 0.8507462686567164, 'eval_accuracy': 0.75, 'eval_kappa': 0.14438502673796794, 'eval_precision': 0.76, 'eval_recall': 0.9661016949152542, 'eval_optim_threshold': 0.7824934124946594, 'eval_AP': 0.8673144903802993, 'eval_MCC': 0.1980534816610477, 'eval_NDCG': 0.9682996079474591, 'eval_runtime': 3.4023, 'eval_samples_per_second': 23.514, 'eval_steps_per_second': 1.176, 'epoch': 4.0}

Trial train_hpo_2789f075 finished iteration 1 at 2025-06-16 16:44:54. Total running time: 1min 52s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_2789f075 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                     31.095 â”‚
â”‚ time_total_s                         31.095 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                                     4 â”‚
â”‚ eval_AP                             0.86731 â”‚
â”‚ eval_MCC                            0.19805 â”‚
â”‚ eval_NDCG                            0.9683 â”‚
â”‚ eval_accuracy                          0.75 â”‚
â”‚ eval_f1                             0.85075 â”‚
â”‚ eval_kappa                          0.14439 â”‚
â”‚ eval_loss                            0.7435 â”‚
â”‚ eval_optim_threshold                0.78249 â”‚
â”‚ eval_precision                         0.76 â”‚
â”‚ eval_recall                          0.9661 â”‚
â”‚ eval_runtime                         3.4023 â”‚
â”‚ eval_samples_per_second              23.514 â”‚
â”‚ eval_steps_per_second                 1.176 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_2789f075 completed after 1 iterations at 2025-06-16 16:44:54. Total running time: 1min 52s
[36m(train_hpo pid=3777403)[0m STATE at ending of training  :  TrainerState(epoch=2.4705882352941178, global_step=12, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=219155152505688.0, log_history=[{'loss': 1.1382, 'grad_norm': 1.8494067192077637, 'learning_rate': 1.5752276202747842e-05, 'epoch': 1.0, 'step': 5}, {'loss': 0.8718, 'grad_norm': 2.489725351333618, 'learning_rate': 4.50065034364224e-06, 'epoch': 2.0, 'step': 10}, {'loss': 0.9463, 'grad_norm': 5.265532970428467, 'learning_rate': 0.0, 'epoch': 2.4705882352941178, 'step': 12}, {'train_runtime': 29.0142, 'train_samples_per_second': 34.845, 'train_steps_per_second': 0.414, 'total_flos': 219155152505688.0, 'train_loss': 0.9952354232470194, 'epoch': 2.4705882352941178, 'step': 12}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3777403)[0m {'train_runtime': 29.0142, 'train_samples_per_second': 34.845, 'train_steps_per_second': 0.414, 'train_loss': 0.9952354232470194, 'epoch': 2.4705882352941178}
[36m(train_hpo pid=3777403)[0m {'loss': 0.9463, 'grad_norm': 5.265532970428467, 'learning_rate': 0.0, 'epoch': 2.4705882352941178}[32m [repeated 2x across cluster][0m

Trial train_hpo_82d855ae started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_82d855ae config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                             0 â”‚
â”‚ num_train_epochs                          2 â”‚
â”‚ pos_weight                          6.42755 â”‚
â”‚ weight_decay                        0.18512 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 5 TERMINATED | 3 RUNNING | 1 PENDING
Current time: 2025-06-16 16:45:01. Total running time: 2min 0s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_62009dba   RUNNING           4.0662        2.70039e-05         0.239866                    3                                                                                        â”‚
â”‚ train_hpo_a57815fe   RUNNING           7.57559       4.00602e-05         0.220208                    4                                                                                        â”‚
â”‚ train_hpo_82d855ae   RUNNING           6.42755       2.7847e-06          0.185124                    2                                                                                        â”‚
â”‚ train_hpo_6f0497ae   TERMINATED        6.82842       1.49561e-06         0.13641                     6        1            71.3551      1.61995     0.848921            0.7375      0         â”‚
â”‚ train_hpo_5b73a863   TERMINATED        6.09408       4.55539e-06         0.123031                    5        1            65.2246      1.49403     0.848921            0.7375      0         â”‚
â”‚ train_hpo_a944c0bb   TERMINATED        7.18321       7.98818e-05         0.251217                    3        1            21.5057      0.978395    0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_c92e5949   TERMINATED        7.43106       1.10121e-06         0.13345                     4        1            25.9862      2.5167      0.848921            0.7375      0         â”‚
â”‚ train_hpo_2789f075   TERMINATED        2.2031        4.03208e-05         0.243719                    5        1            31.0949      0.743503    0.850746            0.75        0.144385  â”‚
â”‚ train_hpo_604674ce   PENDING           7.44006       4.73492e-05         0.163021                    6                                                                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[36m(train_hpo pid=3778101)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3778101)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3778101)[0m 2025-06-16 16:45:02,313 - INFO - pos_weight value in TrainingArguments : 6.427550651795176
[36m(train_hpo pid=3778101)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3778101)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3777403)[0m 2025-06-16 16:45:03,609 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3777403)[0m 2025-06-16 16:45:03,614 - INFO - eval_result: {'eval_loss': 0.9343434572219849, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.861347496509552, 'eval_AP': 0.8224513889315911, 'eval_MCC': 0.0, 'eval_NDCG': 0.9370468330029563, 'eval_runtime': 3.9327, 'eval_samples_per_second': 20.342, 'eval_steps_per_second': 1.017, 'epoch': 2.4705882352941178}
2025-06-16 16:45:03,874 - INFO - Cleaning up trial 62009dba
2025-06-16 16:45:03,875 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_62009dba_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-44-22
2025-06-16 16:45:03,875 - INFO - Cleaning up trial 6f0497ae
2025-06-16 16:45:03,875 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_6f0497ae_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-43-01
2025-06-16 16:45:03,876 - INFO - Cleaning up trial 5b73a863
2025-06-16 16:45:03,876 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_5b73a863_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-43-08
2025-06-16 16:45:03,876 - INFO - Cleaning up trial a944c0bb
2025-06-16 16:45:03,876 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_a944c0bb_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-43-14
2025-06-16 16:45:03,876 - INFO - Cleaning up trial c92e5949
2025-06-16 16:45:03,876 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_c92e5949_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-43-21
2025-06-16 16:45:03,876 - INFO - Current best: 2789f075 with eval_kappa : 0.14438502673796794 at iteration 1
[36m(train_hpo pid=3777403)[0m 2025-06-16 16:45:03,854 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
[36m(train_hpo pid=3778401)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3778401)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3778401)[0m 2025-06-16 16:45:12,064 - INFO - pos_weight value in TrainingArguments : 7.440064585061213
[36m(train_hpo pid=3778401)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3778401)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3777592)[0m 2025-06-16 16:45:15,241 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3777592)[0m 2025-06-16 16:45:15,247 - INFO - eval_result: {'eval_loss': 1.0622045993804932, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.934197187423706, 'eval_AP': 0.8202827495793816, 'eval_MCC': 0.0, 'eval_NDCG': 0.9475190219049701, 'eval_runtime': 3.4371, 'eval_samples_per_second': 23.275, 'eval_steps_per_second': 1.164, 'epoch': 3.235294117647059}

[36m(train_hpo pid=3778101)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=8, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=2, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3777403)[0m {'eval_loss': 0.9343434572219849, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.861347496509552, 'eval_AP': 0.8224513889315911, 'eval_MCC': 0.0, 'eval_NDCG': 0.9370468330029563, 'eval_runtime': 3.9327, 'eval_samples_per_second': 20.342, 'eval_steps_per_second': 1.017, 'epoch': 2.4705882352941178}

Trial train_hpo_62009dba finished iteration 1 at 2025-06-16 16:45:03. Total running time: 2min 2s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_62009dba result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    34.5959 â”‚
â”‚ time_total_s                        34.5959 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               2.47059 â”‚
â”‚ eval_AP                             0.82245 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.93705 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           0.93434 â”‚
â”‚ eval_optim_threshold                0.86135 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.9327 â”‚
â”‚ eval_samples_per_second              20.342 â”‚
â”‚ eval_steps_per_second                 1.017 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_62009dba completed after 1 iterations at 2025-06-16 16:45:03. Total running time: 2min 2s
[36m(train_hpo pid=3778101)[0m {'loss': 2.7338, 'grad_norm': 15.130866050720215, 'learning_rate': 1.0442639949699175e-06, 'epoch': 1.0}[32m [repeated 2x across cluster][0m

Trial train_hpo_604674ce started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_604674ce config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         5e-05 â”‚
â”‚ num_train_epochs                          6 â”‚
â”‚ pos_weight                          7.44006 â”‚
â”‚ weight_decay                        0.16302 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3777592)[0m {'train_runtime': 34.5035, 'train_samples_per_second': 39.068, 'train_steps_per_second': 0.464, 'train_loss': 1.4934016019105911, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3777592)[0m STATE at ending of training  :  TrainerState(epoch=3.235294117647059, global_step=16, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=286774086604632.0, log_history=[{'loss': 2.4687, 'grad_norm': 1.393304467201233, 'learning_rate': 2.7541361839643625e-05, 'epoch': 1.0, 'step': 5}, {'loss': 1.1354, 'grad_norm': 2.210343360900879, 'learning_rate': 1.5022561003441977e-05, 'epoch': 2.0, 'step': 10}, {'loss': 0.9692, 'grad_norm': 3.150836944580078, 'learning_rate': 2.5037601672403296e-06, 'epoch': 3.0, 'step': 15}, {'loss': 1.0282, 'grad_norm': 6.10500955581665, 'learning_rate': 0.0, 'epoch': 3.235294117647059, 'step': 16}, {'train_runtime': 34.5035, 'train_samples_per_second': 39.068, 'train_steps_per_second': 0.464, 'total_flos': 286774086604632.0, 'train_loss': 1.4934016019105911, 'epoch': 3.235294117647059, 'step': 16}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3778401)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3778101)[0m STATE at ending of training  :  TrainerState(epoch=1.7058823529411766, global_step=8, max_steps=8, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=2, num_input_tokens_seen=0, total_flos=151813715856384.0, log_history=[{'loss': 2.7338, 'grad_norm': 15.130866050720215, 'learning_rate': 1.0442639949699175e-06, 'epoch': 1.0, 'step': 5}, {'loss': 2.8372, 'grad_norm': 66.73001098632812, 'learning_rate': 0.0, 'epoch': 1.7058823529411766, 'step': 8}, {'train_runtime': 11.4012, 'train_samples_per_second': 59.117, 'train_steps_per_second': 0.702, 'total_flos': 151813715856384.0, 'train_loss': 2.7726014852523804, 'epoch': 1.7058823529411766, 'step': 8}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3777592)[0m {'eval_loss': 1.0622045993804932, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.934197187423706, 'eval_AP': 0.8202827495793816, 'eval_MCC': 0.0, 'eval_NDCG': 0.9475190219049701, 'eval_runtime': 3.4371, 'eval_samples_per_second': 23.275, 'eval_steps_per_second': 1.164, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3778101)[0m {'loss': 2.8372, 'grad_norm': 66.73001098632812, 'learning_rate': 0.0, 'epoch': 1.7058823529411766}[32m [repeated 3x across cluster][0m

Trial train_hpo_a57815fe finished iteration 1 at 2025-06-16 16:45:15. Total running time: 2min 13s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_a57815fe result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                       39.7 â”‚
â”‚ time_total_s                           39.7 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               3.23529 â”‚
â”‚ eval_AP                             0.82028 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.94752 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                            1.0622 â”‚
â”‚ eval_optim_threshold                 0.9342 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.4371 â”‚
â”‚ eval_samples_per_second              23.275 â”‚
â”‚ eval_steps_per_second                 1.164 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[36m(train_hpo pid=3777592)[0m 2025-06-16 16:45:15,495 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
2025-06-16 16:45:15,516 - INFO - Cleaning up trial a57815fe
2025-06-16 16:45:15,516 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_a57815fe_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.5756,weight_decay=0.2202_2025-06-16_16-44-29
2025-06-16 16:45:15,516 - INFO - Cleaning up trial 6f0497ae
2025-06-16 16:45:15,516 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_6f0497ae_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-43-01
2025-06-16 16:45:15,517 - INFO - Cleaning up trial 5b73a863
2025-06-16 16:45:15,517 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_5b73a863_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-43-08
2025-06-16 16:45:15,517 - INFO - Cleaning up trial a944c0bb
2025-06-16 16:45:15,517 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_a944c0bb_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-43-14
2025-06-16 16:45:15,517 - INFO - Cleaning up trial c92e5949
2025-06-16 16:45:15,517 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_c92e5949_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-43-21
2025-06-16 16:45:15,517 - INFO - Current best: 2789f075 with eval_kappa : 0.14438502673796794 at iteration 1
2025-06-16 16:45:15,517 - INFO - Cleaning up trial 62009dba
2025-06-16 16:45:15,517 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_62009dba_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-44-22
2025-06-16 16:45:17,902 - INFO - Cleaning up trial 82d855ae
2025-06-16 16:45:17,903 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_82d855ae_8_learning_rate=0.0000,num_train_epochs=2,pos_weight=6.4276,weight_decay=0.1851_2025-06-16_16-44-35
2025-06-16 16:45:17,903 - INFO - Cleaning up trial 6f0497ae
2025-06-16 16:45:17,903 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_6f0497ae_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-43-01
2025-06-16 16:45:17,903 - INFO - Cleaning up trial 5b73a863
2025-06-16 16:45:17,903 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_5b73a863_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-43-08
2025-06-16 16:45:17,903 - INFO - Cleaning up trial a944c0bb
2025-06-16 16:45:17,903 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_a944c0bb_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-43-14
2025-06-16 16:45:17,903 - INFO - Cleaning up trial c92e5949
2025-06-16 16:45:17,903 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_c92e5949_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-43-21
2025-06-16 16:45:17,903 - INFO - Cleaning up trial 2789f075
2025-06-16 16:45:17,903 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_2789f075_5_learning_rate=0.0000,num_train_epochs=5,pos_weight=2.2031,weight_decay=0.2437_2025-06-16_16-43-49
2025-06-16 16:45:17,903 - INFO - Cleaning up trial 62009dba
2025-06-16 16:45:17,904 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_62009dba_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-44-22
2025-06-16 16:45:17,904 - INFO - Cleaning up trial a57815fe
2025-06-16 16:45:17,904 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_a57815fe_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.5756,weight_decay=0.2202_2025-06-16_16-44-29
[36m(train_hpo pid=3778709)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3778709)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3778101)[0m 2025-06-16 16:45:17,544 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3778101)[0m 2025-06-16 16:45:17,550 - INFO - eval_result: {'eval_loss': 3.306662082672119, 'eval_f1': 0.7857142857142857, 'eval_accuracy': 0.7, 'eval_kappa': 0.2904656319290466, 'eval_precision': 0.8301886792452831, 'eval_recall': 0.7457627118644068, 'eval_optim_threshold': 0.5097194314002991, 'eval_AP': 0.7966556247165676, 'eval_MCC': 0.2951461213329829, 'eval_NDCG': 0.921807209750396, 'eval_runtime': 3.3256, 'eval_samples_per_second': 24.055, 'eval_steps_per_second': 1.203, 'epoch': 1.7058823529411766}
[36m(train_hpo pid=3778101)[0m 2025-06-16 16:45:17,877 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
[36m(train_hpo pid=3778709)[0m 2025-06-16 16:45:23,097 - INFO - pos_weight value in TrainingArguments : 5.904350112349562
[36m(train_hpo pid=3778709)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3778709)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3778978)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3778978)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3778978)[0m 2025-06-16 16:45:29,749 - INFO - pos_weight value in TrainingArguments : 6.7248101376462595
[36m(train_hpo pid=3778978)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3778978)[0m   super().__init__(*args, **kwargs)


Trial train_hpo_a57815fe completed after 1 iterations at 2025-06-16 16:45:15. Total running time: 2min 13s
[36m(train_hpo pid=3778101)[0m {'train_runtime': 11.4012, 'train_samples_per_second': 59.117, 'train_steps_per_second': 0.702, 'train_loss': 2.7726014852523804, 'epoch': 1.7058823529411766}

Trial train_hpo_82d855ae finished iteration 1 at 2025-06-16 16:45:17. Total running time: 2min 16s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_82d855ae result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                     16.519 â”‚
â”‚ time_total_s                         16.519 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               1.70588 â”‚
â”‚ eval_AP                             0.79666 â”‚
â”‚ eval_MCC                            0.29515 â”‚
â”‚ eval_NDCG                           0.92181 â”‚
â”‚ eval_accuracy                           0.7 â”‚
â”‚ eval_f1                             0.78571 â”‚
â”‚ eval_kappa                          0.29047 â”‚
â”‚ eval_loss                           3.30666 â”‚
â”‚ eval_optim_threshold                0.50972 â”‚
â”‚ eval_precision                      0.83019 â”‚
â”‚ eval_recall                         0.74576 â”‚
â”‚ eval_runtime                         3.3256 â”‚
â”‚ eval_samples_per_second              24.055 â”‚
â”‚ eval_steps_per_second                 1.203 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_82d855ae completed after 1 iterations at 2025-06-16 16:45:17. Total running time: 2min 16s

Trial train_hpo_8ff6b637 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_8ff6b637 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         1e-05 â”‚
â”‚ num_train_epochs                          3 â”‚
â”‚ pos_weight                          5.90435 â”‚
â”‚ weight_decay                        0.28664 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3778709)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3778101)[0m {'eval_loss': 3.306662082672119, 'eval_f1': 0.7857142857142857, 'eval_accuracy': 0.7, 'eval_kappa': 0.2904656319290466, 'eval_precision': 0.8301886792452831, 'eval_recall': 0.7457627118644068, 'eval_optim_threshold': 0.5097194314002991, 'eval_AP': 0.7966556247165676, 'eval_MCC': 0.2951461213329829, 'eval_NDCG': 0.921807209750396, 'eval_runtime': 3.3256, 'eval_samples_per_second': 24.055, 'eval_steps_per_second': 1.203, 'epoch': 1.7058823529411766}
[36m(train_hpo pid=3778401)[0m {'loss': 1.7166, 'grad_norm': 1.4815199375152588, 'learning_rate': 3.748480305116433e-05, 'epoch': 1.0}
[36m(train_hpo pid=3778401)[0m {'loss': 1.1079, 'grad_norm': 2.5470998287200928, 'learning_rate': 2.7620381195594777e-05, 'epoch': 2.0}

Trial train_hpo_27611961 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_27611961 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         3e-05 â”‚
â”‚ num_train_epochs                          6 â”‚
â”‚ pos_weight                          6.72481 â”‚
â”‚ weight_decay                        0.00109 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3778978)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})

Trial status: 8 TERMINATED | 3 RUNNING | 1 PENDING
Current time: 2025-06-16 16:45:32. Total running time: 2min 30s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_604674ce   RUNNING           7.44006       4.73492e-05       0.163021                      6                                                                                        â”‚
â”‚ train_hpo_8ff6b637   RUNNING           5.90435       6.78644e-06       0.286643                      3                                                                                        â”‚
â”‚ train_hpo_27611961   RUNNING           6.72481       3.23119e-05       0.00108909                    6                                                                                        â”‚
â”‚ train_hpo_6f0497ae   TERMINATED        6.82842       1.49561e-06       0.13641                       6        1            71.3551      1.61995     0.848921            0.7375      0         â”‚
â”‚ train_hpo_5b73a863   TERMINATED        6.09408       4.55539e-06       0.123031                      5        1            65.2246      1.49403     0.848921            0.7375      0         â”‚
â”‚ train_hpo_a944c0bb   TERMINATED        7.18321       7.98818e-05       0.251217                      3        1            21.5057      0.978395    0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_c92e5949   TERMINATED        7.43106       1.10121e-06       0.13345                       4        1            25.9862      2.5167      0.848921            0.7375      0         â”‚
â”‚ train_hpo_2789f075   TERMINATED        2.2031        4.03208e-05       0.243719                      5        1            31.0949      0.743503    0.850746            0.75        0.144385  â”‚
â”‚ train_hpo_62009dba   TERMINATED        4.0662        2.70039e-05       0.239866                      3        1            34.5959      0.934343    0.848921            0.7375      0         â”‚
â”‚ train_hpo_a57815fe   TERMINATED        7.57559       4.00602e-05       0.220208                      4        1            39.7         1.0622      0.848921            0.7375      0         â”‚
â”‚ train_hpo_82d855ae   TERMINATED        6.42755       2.7847e-06        0.185124                      2        1            16.519       3.30666     0.785714            0.7         0.290466  â”‚
â”‚ train_hpo_430f38b4   PENDING           3.50937       2.07214e-05       0.263741                      4                                                                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3778978)[0m {'loss': 1.7468, 'grad_norm': 2.498021125793457, 'learning_rate': 2.5580274158205587e-05, 'epoch': 1.0}
[36m(train_hpo pid=3778709)[0m {'loss': 1.4848, 'grad_norm': 3.3639116287231445, 'learning_rate': 3.958758137704503e-06, 'epoch': 1.0}
[36m(train_hpo pid=3778978)[0m {'loss': 0.8654, 'grad_norm': 5.846888542175293, 'learning_rate': 1.2116971969676332e-05, 'epoch': 3.0}[32m [repeated 3x across cluster][0m
[36m(train_hpo pid=3778978)[0m {'loss': 0.7529, 'grad_norm': 2.6567118167877197, 'learning_rate': 5.3853208754117024e-06, 'epoch': 4.0}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3778709)[0m {'train_runtime': 37.8726, 'train_samples_per_second': 26.695, 'train_steps_per_second': 0.317, 'train_loss': 1.3326833645502727, 'epoch': 2.4705882352941178}
[36m(train_hpo pid=3778709)[0m STATE at ending of training  :  TrainerState(epoch=2.4705882352941178, global_step=12, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=219155152505688.0, log_history=[{'loss': 1.4848, 'grad_norm': 3.3639116287231445, 'learning_rate': 3.958758137704503e-06, 'epoch': 1.0, 'step': 5}, {'loss': 1.176, 'grad_norm': 2.4795608520507812, 'learning_rate': 1.131073753629858e-06, 'epoch': 2.0, 'step': 10}, {'loss': 1.3441, 'grad_norm': 5.377496719360352, 'learning_rate': 0.0, 'epoch': 2.4705882352941178, 'step': 12}, {'train_runtime': 37.8726, 'train_samples_per_second': 26.695, 'train_steps_per_second': 0.317, 'total_flos': 219155152505688.0, 'train_loss': 1.3326833645502727, 'epoch': 2.4705882352941178, 'step': 12}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3778709)[0m {'loss': 1.3441, 'grad_norm': 5.377496719360352, 'learning_rate': 0.0, 'epoch': 2.4705882352941178}[32m [repeated 2x across cluster][0m
Trial status: 8 TERMINATED | 3 RUNNING | 1 PENDING
Current time: 2025-06-16 16:46:02. Total running time: 3min 0s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_604674ce   RUNNING           7.44006       4.73492e-05       0.163021                      6                                                                                        â”‚
â”‚ train_hpo_8ff6b637   RUNNING           5.90435       6.78644e-06       0.286643                      3                                                                                        â”‚
â”‚ train_hpo_27611961   RUNNING           6.72481       3.23119e-05       0.00108909                    6                                                                                        â”‚
â”‚ train_hpo_6f0497ae   TERMINATED        6.82842       1.49561e-06       0.13641                       6        1            71.3551      1.61995     0.848921            0.7375      0         â”‚
â”‚ train_hpo_5b73a863   TERMINATED        6.09408       4.55539e-06       0.123031                      5        1            65.2246      1.49403     0.848921            0.7375      0         â”‚
â”‚ train_hpo_a944c0bb   TERMINATED        7.18321       7.98818e-05       0.251217                      3        1            21.5057      0.978395    0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_c92e5949   TERMINATED        7.43106       1.10121e-06       0.13345                       4        1            25.9862      2.5167      0.848921            0.7375      0         â”‚
â”‚ train_hpo_2789f075   TERMINATED        2.2031        4.03208e-05       0.243719                      5        1            31.0949      0.743503    0.850746            0.75        0.144385  â”‚
â”‚ train_hpo_62009dba   TERMINATED        4.0662        2.70039e-05       0.239866                      3        1            34.5959      0.934343    0.848921            0.7375      0         â”‚
â”‚ train_hpo_a57815fe   TERMINATED        7.57559       4.00602e-05       0.220208                      4        1            39.7         1.0622      0.848921            0.7375      0         â”‚
â”‚ train_hpo_82d855ae   TERMINATED        6.42755       2.7847e-06        0.185124                      2        1            16.519       3.30666     0.785714            0.7         0.290466  â”‚
â”‚ train_hpo_430f38b4   PENDING           3.50937       2.07214e-05       0.263741                      4                                                                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3778978)[0m STATE at ending of training  :  TrainerState(epoch=4.9411764705882355, global_step=24, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=438587802461016.0, log_history=[{'loss': 1.7468, 'grad_norm': 2.498021125793457, 'learning_rate': 2.5580274158205587e-05, 'epoch': 1.0, 'step': 5}, {'loss': 1.0115, 'grad_norm': 2.204223155975342, 'learning_rate': 1.8848623063940963e-05, 'epoch': 2.0, 'step': 10}, {'loss': 0.8654, 'grad_norm': 5.846888542175293, 'learning_rate': 1.2116971969676332e-05, 'epoch': 3.0, 'step': 15}, {'loss': 0.7529, 'grad_norm': 2.6567118167877197, 'learning_rate': 5.3853208754117024e-06, 'epoch': 4.0, 'step': 20}, {'loss': 0.8378, 'grad_norm': 6.61240291595459, 'learning_rate': 0.0, 'epoch': 4.9411764705882355, 'step': 24}, {'train_runtime': 32.3042, 'train_samples_per_second': 62.592, 'train_steps_per_second': 0.743, 'total_flos': 438587802461016.0, 'train_loss': 1.05142742395401, 'epoch': 4.9411764705882355, 'step': 24}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3778709)[0m {'eval_loss': 1.1734232902526855, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.8551587462425232, 'eval_AP': 0.7967528186366111, 'eval_MCC': 0.0, 'eval_NDCG': 0.9221113656939529, 'eval_runtime': 3.9237, 'eval_samples_per_second': 20.389, 'eval_steps_per_second': 1.019, 'epoch': 2.4705882352941178}[36m(train_hpo pid=3778709)[0m 2025-06-16 16:46:05,568 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3778709)[0m 2025-06-16 16:46:05,573 - INFO - eval_result: {'eval_loss': 1.1734232902526855, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.8551587462425232, 'eval_AP': 0.7967528186366111, 'eval_MCC': 0.0, 'eval_NDCG': 0.9221113656939529, 'eval_runtime': 3.9237, 'eval_samples_per_second': 20.389, 'eval_steps_per_second': 1.019, 'epoch': 2.4705882352941178}
2025-06-16 16:46:05,836 - INFO - Cleaning up trial 8ff6b637
2025-06-16 16:46:05,836 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_8ff6b637_10_learning_rate=0.0000,num_train_epochs=3,pos_weight=5.9044,weight_decay=0.2866_2025-06-16_16-45-11
2025-06-16 16:46:05,836 - INFO - Cleaning up trial 6f0497ae
2025-06-16 16:46:05,836 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_6f0497ae_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-43-01
2025-06-16 16:46:05,837 - INFO - Cleaning up trial 5b73a863
2025-06-16 16:46:05,837 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_5b73a863_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-43-08
2025-06-16 16:46:05,837 - INFO - Cleaning up trial a944c0bb
2025-06-16 16:46:05,838 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_a944c0bb_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-43-14
2025-06-16 16:46:05,838 - INFO - Cleaning up trial c92e5949
2025-06-16 16:46:05,838 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_c92e5949_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-43-21
2025-06-16 16:46:05,838 - INFO - Cleaning up trial 2789f075
2025-06-16 16:46:05,838 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_2789f075_5_learning_rate=0.0000,num_train_epochs=5,pos_weight=2.2031,weight_decay=0.2437_2025-06-16_16-43-49
2025-06-16 16:46:05,838 - INFO - Cleaning up trial 62009dba
2025-06-16 16:46:05,838 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_62009dba_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-44-22
2025-06-16 16:46:05,838 - INFO - Cleaning up trial a57815fe
2025-06-16 16:46:05,838 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_a57815fe_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.5756,weight_decay=0.2202_2025-06-16_16-44-29
2025-06-16 16:46:05,838 - INFO - Current best: 82d855ae with eval_kappa : 0.2904656319290466 at iteration 1
[36m(train_hpo pid=3778709)[0m 2025-06-16 16:46:05,816 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
2025-06-16 16:46:06,485 - INFO - Cleaning up trial 27611961
2025-06-16 16:46:06,485 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_27611961_11_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.7248,weight_decay=0.0011_2025-06-16_16-45-22
2025-06-16 16:46:06,486 - INFO - Cleaning up trial 6f0497ae
2025-06-16 16:46:06,486 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_6f0497ae_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-43-01
2025-06-16 16:46:06,486 - INFO - Cleaning up trial 5b73a863
2025-06-16 16:46:06,486 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_5b73a863_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-43-08
2025-06-16 16:46:06,486 - INFO - Cleaning up trial a944c0bb
2025-06-16 16:46:06,486 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_a944c0bb_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-43-14
2025-06-16 16:46:06,486 - INFO - Cleaning up trial c92e5949
2025-06-16 16:46:06,486 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_c92e5949_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-43-21
2025-06-16 16:46:06,486 - INFO - Cleaning up trial 2789f075
2025-06-16 16:46:06,486 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_2789f075_5_learning_rate=0.0000,num_train_epochs=5,pos_weight=2.2031,weight_decay=0.2437_2025-06-16_16-43-49
2025-06-16 16:46:06,486 - INFO - Cleaning up trial 62009dba
2025-06-16 16:46:06,486 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_62009dba_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-44-22
2025-06-16 16:46:06,487 - INFO - Cleaning up trial a57815fe
2025-06-16 16:46:06,487 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_a57815fe_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.5756,weight_decay=0.2202_2025-06-16_16-44-29
2025-06-16 16:46:06,487 - INFO - Current best: 82d855ae with eval_kappa : 0.2904656319290466 at iteration 1
2025-06-16 16:46:06,487 - INFO - Cleaning up trial 8ff6b637
2025-06-16 16:46:06,487 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_8ff6b637_10_learning_rate=0.0000,num_train_epochs=3,pos_weight=5.9044,weight_decay=0.2866_2025-06-16_16-45-11
[36m(train_hpo pid=3778401)[0m 2025-06-16 16:46:10,703 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3778401)[0m 2025-06-16 16:46:10,708 - INFO - eval_result: {'eval_loss': 0.9377471208572388, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9281598925590515, 'eval_AP': 0.885106563960883, 'eval_MCC': 0.0, 'eval_NDCG': 0.9714932776771181, 'eval_runtime': 3.321, 'eval_samples_per_second': 24.089, 'eval_steps_per_second': 1.204, 'epoch': 4.9411764705882355}[32m [repeated 2x across cluster][0m
2025-06-16 16:46:10,965 - INFO - Cleaning up trial 604674ce
2025-06-16 16:46:10,966 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_604674ce_9_learning_rate=0.0000,num_train_epochs=6,pos_weight=7.4401,weight_decay=0.1630_2025-06-16_16-45-01
2025-06-16 16:46:10,966 - INFO - Cleaning up trial 6f0497ae
2025-06-16 16:46:10,966 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_6f0497ae_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-43-01
2025-06-16 16:46:10,966 - INFO - Cleaning up trial 5b73a863
2025-06-16 16:46:10,966 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_5b73a863_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-43-08
2025-06-16 16:46:10,966 - INFO - Cleaning up trial a944c0bb
2025-06-16 16:46:10,966 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_a944c0bb_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-43-14
2025-06-16 16:46:10,966 - INFO - Cleaning up trial c92e5949
2025-06-16 16:46:10,966 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_c92e5949_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-43-21
2025-06-16 16:46:10,967 - INFO - Cleaning up trial 2789f075
2025-06-16 16:46:10,967 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_2789f075_5_learning_rate=0.0000,num_train_epochs=5,pos_weight=2.2031,weight_decay=0.2437_2025-06-16_16-43-49
2025-06-16 16:46:10,967 - INFO - Cleaning up trial 62009dba
2025-06-16 16:46:10,967 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_62009dba_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-44-22
2025-06-16 16:46:10,967 - INFO - Cleaning up trial a57815fe
2025-06-16 16:46:10,967 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_a57815fe_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.5756,weight_decay=0.2202_2025-06-16_16-44-29
2025-06-16 16:46:10,967 - INFO - Current best: 82d855ae with eval_kappa : 0.2904656319290466 at iteration 1
2025-06-16 16:46:10,967 - INFO - Cleaning up trial 8ff6b637
2025-06-16 16:46:10,967 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_8ff6b637_10_learning_rate=0.0000,num_train_epochs=3,pos_weight=5.9044,weight_decay=0.2866_2025-06-16_16-45-11
2025-06-16 16:46:10,967 - INFO - Cleaning up trial 27611961
2025-06-16 16:46:10,967 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_27611961_11_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.7248,weight_decay=0.0011_2025-06-16_16-45-22
[36m(train_hpo pid=3778401)[0m 2025-06-16 16:46:10,946 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3779959)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3779959)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3779959)[0m 2025-06-16 16:46:14,299 - INFO - pos_weight value in TrainingArguments : 3.5093706580135486
[36m(train_hpo pid=3779959)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3779959)[0m   super().__init__(*args, **kwargs)


Trial train_hpo_8ff6b637 finished iteration 1 at 2025-06-16 16:46:05. Total running time: 3min 4s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_8ff6b637 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    43.5927 â”‚
â”‚ time_total_s                        43.5927 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               2.47059 â”‚
â”‚ eval_AP                             0.79675 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.92211 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           1.17342 â”‚
â”‚ eval_optim_threshold                0.85516 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.9237 â”‚
â”‚ eval_samples_per_second              20.389 â”‚
â”‚ eval_steps_per_second                 1.019 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_8ff6b637 completed after 1 iterations at 2025-06-16 16:46:05. Total running time: 3min 4s

Trial train_hpo_27611961 finished iteration 1 at 2025-06-16 16:46:06. Total running time: 3min 4s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_27611961 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    37.6257 â”‚
â”‚ time_total_s                        37.6257 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               4.94118 â”‚
â”‚ eval_AP                             0.85512 â”‚
â”‚ eval_MCC                            0.18858 â”‚
â”‚ eval_NDCG                           0.96583 â”‚
â”‚ eval_accuracy                          0.75 â”‚
â”‚ eval_f1                             0.85507 â”‚
â”‚ eval_kappa                          0.06868 â”‚
â”‚ eval_loss                           1.03619 â”‚
â”‚ eval_optim_threshold                0.95602 â”‚
â”‚ eval_precision                      0.74684 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.4681 â”‚
â”‚ eval_samples_per_second              23.067 â”‚
â”‚ eval_steps_per_second                 1.153 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_27611961 completed after 1 iterations at 2025-06-16 16:46:06. Total running time: 3min 4s
[36m(train_hpo pid=3778401)[0m {'train_runtime': 54.6815, 'train_samples_per_second': 36.978, 'train_steps_per_second': 0.439, 'train_loss': 1.0683161516984303, 'epoch': 4.9411764705882355}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3778401)[0m {'loss': 0.8045, 'grad_norm': 8.968621253967285, 'learning_rate': 0.0, 'epoch': 4.9411764705882355}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3778401)[0m STATE at ending of training  :  TrainerState(epoch=4.9411764705882355, global_step=24, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=438587802461016.0, log_history=[{'loss': 1.7166, 'grad_norm': 1.4815199375152588, 'learning_rate': 3.748480305116433e-05, 'epoch': 1.0, 'step': 5}, {'loss': 1.1079, 'grad_norm': 2.5470998287200928, 'learning_rate': 2.7620381195594777e-05, 'epoch': 2.0, 'step': 10}, {'loss': 0.9115, 'grad_norm': 3.0726983547210693, 'learning_rate': 1.7755959340025214e-05, 'epoch': 3.0, 'step': 15}, {'loss': 0.7483, 'grad_norm': 1.739474892616272, 'learning_rate': 7.89153748445565e-06, 'epoch': 4.0, 'step': 20}, {'loss': 0.8045, 'grad_norm': 8.968621253967285, 'learning_rate': 0.0, 'epoch': 4.9411764705882355, 'step': 24}, {'train_runtime': 54.6815, 'train_samples_per_second': 36.978, 'train_steps_per_second': 0.439, 'total_flos': 438587802461016.0, 'train_loss': 1.0683161516984303, 'epoch': 4.9411764705882355, 'step': 24}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3778401)[0m {'eval_loss': 0.9377471208572388, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9281598925590515, 'eval_AP': 0.885106563960883, 'eval_MCC': 0.0, 'eval_NDCG': 0.9714932776771181, 'eval_runtime': 3.321, 'eval_samples_per_second': 24.089, 'eval_steps_per_second': 1.204, 'epoch': 4.9411764705882355}[32m [repeated 2x across cluster][0m

Trial train_hpo_604674ce finished iteration 1 at 2025-06-16 16:46:10. Total running time: 3min 9s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_604674ce result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                     59.727 â”‚
â”‚ time_total_s                         59.727 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               4.94118 â”‚
â”‚ eval_AP                             0.88511 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.97149 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           0.93775 â”‚
â”‚ eval_optim_threshold                0.92816 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                          3.321 â”‚
â”‚ eval_samples_per_second              24.089 â”‚
â”‚ eval_steps_per_second                 1.204 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_604674ce completed after 1 iterations at 2025-06-16 16:46:10. Total running time: 3min 9s

Trial train_hpo_430f38b4 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_430f38b4 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         2e-05 â”‚
â”‚ num_train_epochs                          4 â”‚
â”‚ pos_weight                          3.50937 â”‚
â”‚ weight_decay                        0.26374 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3779959)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})[36m(train_hpo pid=3779959)[0m 2025-06-16 16:46:40,077 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3779959)[0m 2025-06-16 16:46:40,082 - INFO - eval_result: {'eval_loss': 0.9146184921264648, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.7840188145637512, 'eval_AP': 0.8100322568917553, 'eval_MCC': 0.0, 'eval_NDCG': 0.9535484423461701, 'eval_runtime': 3.6565, 'eval_samples_per_second': 21.879, 'eval_steps_per_second': 1.094, 'epoch': 3.235294117647059}

[36m(train_hpo pid=3779959)[0m {'loss': 1.0908, 'grad_norm': 1.8101475238800049, 'learning_rate': 1.4245962766850404e-05, 'epoch': 1.0}
[36m(train_hpo pid=3779959)[0m {'loss': 0.8601, 'grad_norm': 2.1265032291412354, 'learning_rate': 7.770525145554766e-06, 'epoch': 2.0}

Trial status: 11 TERMINATED | 1 RUNNING
Current time: 2025-06-16 16:46:32. Total running time: 3min 30s
Logical resource usage: 10.0/32 CPUs, 1.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_430f38b4   RUNNING           3.50937       2.07214e-05       0.263741                      4                                                                                        â”‚
â”‚ train_hpo_6f0497ae   TERMINATED        6.82842       1.49561e-06       0.13641                       6        1            71.3551      1.61995     0.848921            0.7375      0         â”‚
â”‚ train_hpo_5b73a863   TERMINATED        6.09408       4.55539e-06       0.123031                      5        1            65.2246      1.49403     0.848921            0.7375      0         â”‚
â”‚ train_hpo_a944c0bb   TERMINATED        7.18321       7.98818e-05       0.251217                      3        1            21.5057      0.978395    0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_c92e5949   TERMINATED        7.43106       1.10121e-06       0.13345                       4        1            25.9862      2.5167      0.848921            0.7375      0         â”‚
â”‚ train_hpo_2789f075   TERMINATED        2.2031        4.03208e-05       0.243719                      5        1            31.0949      0.743503    0.850746            0.75        0.144385  â”‚
â”‚ train_hpo_62009dba   TERMINATED        4.0662        2.70039e-05       0.239866                      3        1            34.5959      0.934343    0.848921            0.7375      0         â”‚
â”‚ train_hpo_a57815fe   TERMINATED        7.57559       4.00602e-05       0.220208                      4        1            39.7         1.0622      0.848921            0.7375      0         â”‚
â”‚ train_hpo_82d855ae   TERMINATED        6.42755       2.7847e-06        0.185124                      2        1            16.519       3.30666     0.785714            0.7         0.290466  â”‚
â”‚ train_hpo_604674ce   TERMINATED        7.44006       4.73492e-05       0.163021                      6        1            59.727       0.937747    0.848921            0.7375      0         â”‚
â”‚ train_hpo_8ff6b637   TERMINATED        5.90435       6.78644e-06       0.286643                      3        1            43.5927      1.17342     0.848921            0.7375      0         â”‚
â”‚ train_hpo_27611961   TERMINATED        6.72481       3.23119e-05       0.00108909                    6        1            37.6257      1.03619     0.855072            0.75        0.0686845 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3779959)[0m {'loss': 0.7947, 'grad_norm': 2.353238582611084, 'learning_rate': 1.2950875242591277e-06, 'epoch': 3.0}
[36m(train_hpo pid=3779959)[0m {'loss': 0.9154, 'grad_norm': 4.152314186096191, 'learning_rate': 0.0, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3779959)[0m {'train_runtime': 21.5984, 'train_samples_per_second': 62.412, 'train_steps_per_second': 0.741, 'train_loss': 0.9152066856622696, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3779959)[0m STATE at ending of training  :  TrainerState(epoch=3.235294117647059, global_step=16, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=286774086604632.0, log_history=[{'loss': 1.0908, 'grad_norm': 1.8101475238800049, 'learning_rate': 1.4245962766850404e-05, 'epoch': 1.0, 'step': 5}, {'loss': 0.8601, 'grad_norm': 2.1265032291412354, 'learning_rate': 7.770525145554766e-06, 'epoch': 2.0, 'step': 10}, {'loss': 0.7947, 'grad_norm': 2.353238582611084, 'learning_rate': 1.2950875242591277e-06, 'epoch': 3.0, 'step': 15}, {'loss': 0.9154, 'grad_norm': 4.152314186096191, 'learning_rate': 0.0, 'epoch': 3.235294117647059, 'step': 16}, {'train_runtime': 21.5984, 'train_samples_per_second': 62.412, 'train_steps_per_second': 0.741, 'total_flos': 286774086604632.0, 'train_loss': 0.9152066856622696, 'epoch': 3.235294117647059, 'step': 16}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3779959)[0m {'eval_loss': 0.9146184921264648, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.7840188145637512, 'eval_AP': 0.8100322568917553, 'eval_MCC': 0.0, 'eval_NDCG': 0.9535484423461701, 'eval_runtime': 3.6565, 'eval_samples_per_second': 21.879, 'eval_steps_per_second': 1.094, 'epoch': 3.235294117647059}

Trial train_hpo_430f38b4 finished iteration 1 at 2025-06-16 16:46:40. Total running time: 3min 38s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_430f38b4 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    26.8884 â”‚
â”‚ time_total_s                        26.8884 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               3.23529 â”‚
â”‚ eval_AP                             0.81003 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.95355 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           0.91462 â”‚
â”‚ eval_optim_threshold                0.78402 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.6565 â”‚
â”‚ eval_samples_per_second              21.879 â”‚
â”‚ eval_steps_per_second                 1.094 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯2025-06-16 16:46:40,340 - INFO - Cleaning up trial 430f38b4
2025-06-16 16:46:40,340 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_430f38b4_12_learning_rate=0.0000,num_train_epochs=4,pos_weight=3.5094,weight_decay=0.2637_2025-06-16_16-45-28
2025-06-16 16:46:40,340 - INFO - Cleaning up trial 6f0497ae
2025-06-16 16:46:40,340 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_6f0497ae_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-43-01
2025-06-16 16:46:40,341 - INFO - Cleaning up trial 5b73a863
2025-06-16 16:46:40,341 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_5b73a863_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-43-08
2025-06-16 16:46:40,341 - INFO - Cleaning up trial a944c0bb
2025-06-16 16:46:40,341 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_a944c0bb_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-43-14
2025-06-16 16:46:40,341 - INFO - Cleaning up trial c92e5949
2025-06-16 16:46:40,341 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_c92e5949_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-43-21
2025-06-16 16:46:40,341 - INFO - Cleaning up trial 2789f075
2025-06-16 16:46:40,341 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_2789f075_5_learning_rate=0.0000,num_train_epochs=5,pos_weight=2.2031,weight_decay=0.2437_2025-06-16_16-43-49
2025-06-16 16:46:40,341 - INFO - Cleaning up trial 62009dba
2025-06-16 16:46:40,341 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_62009dba_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-44-22
2025-06-16 16:46:40,341 - INFO - Cleaning up trial a57815fe
2025-06-16 16:46:40,341 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_a57815fe_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.5756,weight_decay=0.2202_2025-06-16_16-44-29
2025-06-16 16:46:40,342 - INFO - Current best: 82d855ae with eval_kappa : 0.2904656319290466 at iteration 1
2025-06-16 16:46:40,342 - INFO - Cleaning up trial 604674ce
2025-06-16 16:46:40,342 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_604674ce_9_learning_rate=0.0000,num_train_epochs=6,pos_weight=7.4401,weight_decay=0.1630_2025-06-16_16-45-01
2025-06-16 16:46:40,342 - INFO - Cleaning up trial 8ff6b637
2025-06-16 16:46:40,342 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_8ff6b637_10_learning_rate=0.0000,num_train_epochs=3,pos_weight=5.9044,weight_decay=0.2866_2025-06-16_16-45-11
2025-06-16 16:46:40,342 - INFO - Cleaning up trial 27611961
2025-06-16 16:46:40,342 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00/train_hpo_27611961_11_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.7248,weight_decay=0.0011_2025-06-16_16-45-22
2025-06-16 16:46:40,350	INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-43-00' in 0.0068s.
2025-06-16 16:46:40,365 - INFO - Analysis results: <ray.tune.analysis.experiment_analysis.ExperimentAnalysis object at 0x7583a6ecf990>
2025-06-16 16:46:40,365 - INFO - Best trial : train_hpo_82d855ae
2025-06-16 16:46:40,365 - INFO - Best config : {'pos_weight': 6.427550651795176, 'learning_rate': 2.7847039865864467e-06, 'weight_decay': 0.18512380755069485, 'num_train_epochs': 2}
2025-06-16 16:46:40,365 - INFO - Best trial after optimization: {'eval_loss': 3.306662082672119, 'eval_f1': 0.7857142857142857, 'eval_accuracy': 0.7, 'eval_kappa': 0.2904656319290466, 'eval_precision': 0.8301886792452831, 'eval_recall': 0.7457627118644068, 'eval_optim_threshold': 0.5097194314002991, 'eval_AP': 0.7966556247165676, 'eval_MCC': 0.2951461213329829, 'eval_NDCG': 0.921807209750396, 'eval_runtime': 3.3256, 'eval_samples_per_second': 24.055, 'eval_steps_per_second': 1.203, 'epoch': 1.7058823529411766, 'timestamp': 1750085117, 'checkpoint_dir_name': None, 'done': True, 'training_iteration': 1, 'trial_id': '82d855ae', 'date': '2025-06-16_16-45-17', 'time_this_iter_s': 16.5189688205719, 'time_total_s': 16.5189688205719, 'pid': 3778101, 'hostname': 'lcatogni', 'node_ip': '172.30.120.56', 'config': {'pos_weight': 6.427550651795176, 'learning_rate': 2.7847039865864467e-06, 'weight_decay': 0.18512380755069485, 'num_train_epochs': 2}, 'time_since_restore': 16.5189688205719, 'iterations_since_restore': 1, 'experiment_tag': '8_learning_rate=0.0000,num_train_epochs=2,pos_weight=6.4276,weight_decay=0.1851'}
2025-06-16 16:46:40,388 - INFO - analysis dataframe :    eval_loss   eval_f1  ...  config/num_train_epochs    logdir
0   1.619947  0.848921  ...                        6  6f0497ae
1   1.494034  0.848921  ...                        5  5b73a863
2   0.978395  0.855072  ...                        3  a944c0bb
3   2.516695  0.848921  ...                        4  c92e5949
4   0.743503  0.850746  ...                        5  2789f075

[5 rows x 32 columns]
[36m(train_hpo pid=3779959)[0m 2025-06-16 16:46:40,320 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
2025-06-16 16:46:40,490 - INFO - Trial comparison plot saved
2025-06-16 16:46:40,490 - INFO - Final training...
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-06-16 16:46:41,110 - INFO - Positive weight parameter set to default (in TrainingArguments) -> pos_weight=5.0
/home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
  super().__init__(*args, **kwargs)
2025-06-16 16:46:41,348 - INFO - training size : 337
2025-06-16 16:46:41,348 - INFO - dev size : 80
2025-06-16 16:46:41,348 - INFO - test size : 80
/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:37: UserWarning: 
    There is an imbalance between your GPUs. You may want to exclude GPU 0 which
    has less than 75% of the memory or cores of GPU 2. You can do so by setting
    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES
    environment variable.
  warnings.warn(


Trial train_hpo_430f38b4 completed after 1 iterations at 2025-06-16 16:46:40. Total running time: 3min 38s

Trial status: 12 TERMINATED
Current time: 2025-06-16 16:46:40. Total running time: 3min 38s
Logical resource usage: 10.0/32 CPUs, 1.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_6f0497ae   TERMINATED        6.82842       1.49561e-06       0.13641                       6        1            71.3551      1.61995     0.848921            0.7375      0         â”‚
â”‚ train_hpo_5b73a863   TERMINATED        6.09408       4.55539e-06       0.123031                      5        1            65.2246      1.49403     0.848921            0.7375      0         â”‚
â”‚ train_hpo_a944c0bb   TERMINATED        7.18321       7.98818e-05       0.251217                      3        1            21.5057      0.978395    0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_c92e5949   TERMINATED        7.43106       1.10121e-06       0.13345                       4        1            25.9862      2.5167      0.848921            0.7375      0         â”‚
â”‚ train_hpo_2789f075   TERMINATED        2.2031        4.03208e-05       0.243719                      5        1            31.0949      0.743503    0.850746            0.75        0.144385  â”‚
â”‚ train_hpo_62009dba   TERMINATED        4.0662        2.70039e-05       0.239866                      3        1            34.5959      0.934343    0.848921            0.7375      0         â”‚
â”‚ train_hpo_a57815fe   TERMINATED        7.57559       4.00602e-05       0.220208                      4        1            39.7         1.0622      0.848921            0.7375      0         â”‚
â”‚ train_hpo_82d855ae   TERMINATED        6.42755       2.7847e-06        0.185124                      2        1            16.519       3.30666     0.785714            0.7         0.290466  â”‚
â”‚ train_hpo_604674ce   TERMINATED        7.44006       4.73492e-05       0.163021                      6        1            59.727       0.937747    0.848921            0.7375      0         â”‚
â”‚ train_hpo_8ff6b637   TERMINATED        5.90435       6.78644e-06       0.286643                      3        1            43.5927      1.17342     0.848921            0.7375      0         â”‚
â”‚ train_hpo_27611961   TERMINATED        6.72481       3.23119e-05       0.00108909                    6        1            37.6257      1.03619     0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_430f38b4   TERMINATED        3.50937       2.07214e-05       0.263741                      4        1            26.8884      0.914618    0.848921            0.7375      0         â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

  0%|          | 0/30 [00:00<?, ?it/s]  3%|â–Ž         | 1/30 [00:01<00:53,  1.84s/it]  7%|â–‹         | 2/30 [00:02<00:31,  1.12s/it] 10%|â–ˆ         | 3/30 [00:03<00:24,  1.12it/s] 13%|â–ˆâ–Ž        | 4/30 [00:03<00:20,  1.28it/s] 17%|â–ˆâ–‹        | 5/30 [00:04<00:18,  1.39it/s] 20%|â–ˆâ–ˆ        | 6/30 [00:04<00:16,  1.46it/s] 23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:05<00:15,  1.51it/s] 27%|â–ˆâ–ˆâ–‹       | 8/30 [00:06<00:14,  1.55it/s] 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:06<00:13,  1.57it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:07<00:12,  1.59it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:07<00:11,  1.60it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:08<00:11,  1.61it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:09<00:10,  1.62it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:09<00:09,  1.63it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:09<00:07,  2.14it/s]                                                50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:09<00:07,  2.14it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:10<00:07,  1.93it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:11<00:07,  1.83it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:11<00:06,  1.76it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:12<00:06,  1.72it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:13<00:05,  1.69it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:13<00:05,  1.67it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:14<00:04,  1.66it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:14<00:04,  1.65it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:15<00:03,  1.64it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:16<00:03,  1.64it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:16<00:02,  1.64it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:17<00:01,  1.64it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:17<00:01,  1.64it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:18<00:00,  1.65it/s]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:20<00:00,  1.65it/s]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:20<00:00,  1.65it/s]2025-06-16 16:47:02,117 - INFO - Early stopping triggered, but no best model checkpoint was saved.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:20<00:00,  1.47it/s]
/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:37: UserWarning: 
    There is an imbalance between your GPUs. You may want to exclude GPU 0 which
    has less than 75% of the memory or cores of GPU 2. You can do so by setting
    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES
    environment variable.
  warnings.warn(
{'loss': 2.1824, 'grad_norm': 43.96937561035156, 'learning_rate': 1.3923519932932234e-06, 'epoch': 1.0}
{'loss': 1.5279, 'grad_norm': 72.15292358398438, 'learning_rate': 0.0, 'epoch': 2.0}
{'train_runtime': 20.4805, 'train_samples_per_second': 32.909, 'train_steps_per_second': 1.465, 'train_loss': 1.855172856648763, 'epoch': 2.0}
  0%|          | 0/4 [00:00<?, ?it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.19it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.21it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.24it/s]2025-06-16 16:47:06,018 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.11it/s]
2025-06-16 16:47:06,023 - INFO - Training time : 25.53290565998759
/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:37: UserWarning: 
    There is an imbalance between your GPUs. You may want to exclude GPU 0 which
    has less than 75% of the memory or cores of GPU 2. You can do so by setting
    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES
    environment variable.
  warnings.warn(
  0%|          | 0/4 [00:00<?, ?it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.22it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.23it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.27it/s]2025-06-16 16:47:09,842 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.14it/s]
2025-06-16 16:47:09,846 - INFO - Evaluation time : 3.8230715800309554
2025-06-16 16:47:09,847 - INFO - Evaluation results on test set: {'eval_loss': 1.4753084182739258, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.7958899736404419, 'eval_AP': 0.7267951078853869, 'eval_MCC': 0.0, 'eval_NDCG': 0.8677774324343249, 'eval_runtime': 3.8191, 'eval_samples_per_second': 20.948, 'eval_steps_per_second': 1.047, 'epoch': 2.0}
2025-06-16 16:47:09,847 - INFO - Total updates (optimizer steps): 30
2025-06-16 16:47:09,847 - INFO - Avg time / step: 0.683s
2025-06-16 16:47:10,865 - INFO - Best model saved to /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/final_model/best_model_cross_val_BCEmicrosoft/BiomedNLP-BiomedBERT-base-uncased-abstract12trials_fold-1
2025-06-16 16:47:10,865 - INFO - On test Set (with threshold 0.5) : 
/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:37: UserWarning: 
    There is an imbalance between your GPUs. You may want to exclude GPU 0 which
    has less than 75% of the memory or cores of GPU 2. You can do so by setting
    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES
    environment variable.
  warnings.warn(
  0%|          | 0/4 [00:00<?, ?it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.17it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.22it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.27it/s]2025-06-16 16:47:15,036 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.03it/s]
2025-06-16 16:47:15,040 - INFO - Raw predictions shape: (80, 1)
2025-06-16 16:47:15,041 - INFO - Raw predictions: [[1.6136392 ]
 [1.4108245 ]
 [1.2195251 ]
 [1.8841364 ]
 [1.2968929 ]
 [1.465954  ]
 [1.5848578 ]
 [0.76513255]
 [1.6060526 ]
 [1.5498621 ]]
2025-06-16 16:47:15,041 - INFO - Scores shape: (80,)
2025-06-16 16:47:15,041 - INFO - Scores: [0.833916   0.803896   0.77198    0.8680855  0.7853116  0.81244165
 0.82989144 0.68246704 0.8328626  0.8248939 ]
2025-06-16 16:47:15,041 - INFO - Preds shape: (80,)
2025-06-16 16:47:15,041 - INFO - Preds: [1 1 1 1 1 1 1 1 1 1]
2025-06-16 16:47:15,042 - INFO - Test labels shape: (80,)
2025-06-16 16:47:15,043 - INFO - Test labels: [1, 1, 0, 0, 1, 1, 1, 1, 0, 0]
2025-06-16 16:47:15,043 - INFO - Test split: Dataset({
    features: ['title', 'abstract', 'Keywords', 'doi', 'labels'],
    num_rows: 80
})
2025-06-16 16:47:15,043 - INFO - Unique values in predictions: [1]
2025-06-16 16:47:15,043 - INFO - Unique values in labels: [0 1]
2025-06-16 16:47:15,045 - INFO - Confusion matrix:
[[ 0 21]
 [ 0 59]]
2025-06-16 16:47:15,046 - INFO - Confusion matrix: TN=0, FP=21, FN=0, TP=59
2025-06-16 16:47:17,767 - INFO - Metrics: {'f1': 0.8489208633093526, 'recall': 1.0, 'precision': 0.7375, 'accuracy': 0.7375, 'AP': 0.7267951078853869, 'MCC': 0.0, 'NDCG': 0.8677774324343249, 'kappa': 0.0, 'TN': 0, 'FP': 21, 'FN': 0, 'TP': 59}
2025-06-16 16:47:17,772 - INFO - Metrics stored successfully at /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/metrics/binary_metrics.csv
2025-06-16 16:47:17,892 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_test.png
2025-06-16 16:47:17,989 - INFO - Precision-Recall curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/precision_recall_curvetest.png
2025-06-16 16:47:17,989 - INFO - 
On test Set (optimal threshold of 0.8063271045684814 according to cross validation on the training set): 
2025-06-16 16:47:17,990 - INFO - Confusion matrix: TN=10, FP=11, FN=27, TP=32
2025-06-16 16:47:20,950 - INFO - Metrics: {'f1': 0.6274509803921569, 'recall': 0.5423728813559322, 'precision': 0.7441860465116279, 'accuracy': 0.525, 'AP': 0.7267951078853869, 'MCC': 0.016381629260440483, 'NDCG': 0.8677774324343249, 'kappa': 0.014906027219701912, 'TN': 10, 'FP': 11, 'FN': 27, 'TP': 32}
2025-06-16 16:47:21,045 - INFO - Precision-Recall curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/precision_recall_curvetest.png
2025-06-16 16:47:21,046 - INFO - Results for fold 1 : [{'f1': 0.6274509803921569, 'recall': 0.5423728813559322, 'precision': 0.7441860465116279, 'accuracy': 0.525, 'AP': 0.7267951078853869, 'MCC': 0.016381629260440483, 'NDCG': 0.8677774324343249, 'kappa': 0.014906027219701912, 'TN': 10, 'FP': 11, 'FN': 27, 'TP': 32}]
2025-06-16 16:47:21,428 - INFO - Cleared CUDA cache. Memory allocated: 1.37 GB, Memory reserved: 1.54 GB
2025-06-16 16:47:21,665 - INFO - Cleared CUDA cache. Memory allocated: 1.37 GB, Memory reserved: 1.54 GB
2025-06-16 16:47:21,665 - INFO - 
fold number 2 / 5
2025-06-16 16:47:21,671 - INFO - train split size : 337
2025-06-16 16:47:21,671 - INFO - dev split size : 80
2025-06-16 16:47:21,671 - INFO - test split size : 80
Map (num_proc=32):   0%|          | 0/337 [00:00<?, ? examples/s]Map (num_proc=32):   3%|â–Ž         | 11/337 [00:00<00:05, 59.06 examples/s]Map (num_proc=32):  20%|â–ˆâ–‰        | 66/337 [00:00<00:01, 258.34 examples/s]Map (num_proc=32):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 121/337 [00:00<00:00, 353.42 examples/s]Map (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 176/337 [00:00<00:00, 402.89 examples/s]Map (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 227/337 [00:00<00:00, 428.49 examples/s]Map (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 287/337 [00:00<00:00, 446.75 examples/s]Map (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 337/337 [00:00<00:00, 344.00 examples/s]
Map (num_proc=32):   0%|          | 0/80 [00:00<?, ? examples/s]Map (num_proc=32):   4%|â–         | 3/80 [00:00<00:04, 17.43 examples/s]Map (num_proc=32):  22%|â–ˆâ–ˆâ–Ž       | 18/80 [00:00<00:00, 77.48 examples/s]Map (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/80 [00:00<00:00, 111.70 examples/s]Map (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/80 [00:00<00:00, 125.90 examples/s]Map (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 66/80 [00:00<00:00, 119.42 examples/s]Map (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<00:00, 118.45 examples/s]Map (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<00:00, 91.27 examples/s] 
Map (num_proc=32):   0%|          | 0/80 [00:00<?, ? examples/s]Map (num_proc=32):   4%|â–         | 3/80 [00:00<00:04, 17.44 examples/s]Map (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 21/80 [00:00<00:00, 85.16 examples/s]Map (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/80 [00:00<00:00, 119.50 examples/s]Map (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/80 [00:00<00:00, 126.44 examples/s]Map (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 68/80 [00:00<00:00, 117.19 examples/s]Map (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<00:00, 93.87 examples/s] 
2025-06-16 16:47:29,279 - INFO - 3 datasets tokenized successfully
2025-06-16 16:47:29,345 - INFO - Fold 2 max seq len = 512
2025-06-16 16:47:29,345 - INFO - Starting hyperparameter search for BCE loss
[36m(train_hpo pid=3782243)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3782243)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3782243)[0m 2025-06-16 16:47:36,842 - INFO - pos_weight value in TrainingArguments : 6.828424226204718
[36m(train_hpo pid=3782243)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3782243)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3782438)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3782438)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3782438)[0m 2025-06-16 16:47:43,290 - INFO - pos_weight value in TrainingArguments : 6.094080202241274
[36m(train_hpo pid=3782438)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3782438)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3782634)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3782634)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3782634)[0m 2025-06-16 16:47:49,926 - INFO - pos_weight value in TrainingArguments : 7.183206941666034
[36m(train_hpo pid=3782634)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3782634)[0m   super().__init__(*args, **kwargs)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Configuration for experiment     train_hpo_2025-06-16_16-47-29   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Search algorithm                 SearchGenerator                 â”‚
â”‚ Scheduler                        AsyncHyperBandScheduler         â”‚
â”‚ Number of trials                 12                              â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

View detailed results here: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29
To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-06-16_16-42-25_595113_3771642/artifacts/2025-06-16_16-47-29/train_hpo_2025-06-16_16-47-29/driver_artifacts`

Trial status: 1 PENDING
Current time: 2025-06-16 16:47:29. Total running time: 0s
Logical resource usage: 10.0/32 CPUs, 1.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status       pos_weight     learning_rate     weight_decay     num_train_epochs â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_cd0231b6   PENDING         6.82842       1.49561e-06          0.13641                    6 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_cd0231b6 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_cd0231b6 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                             0 â”‚
â”‚ num_train_epochs                          6 â”‚
â”‚ pos_weight                          6.82842 â”‚
â”‚ weight_decay                        0.13641 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3782243)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})

Trial train_hpo_b583b0df started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_b583b0df config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                             0 â”‚
â”‚ num_train_epochs                          5 â”‚
â”‚ pos_weight                          6.09408 â”‚
â”‚ weight_decay                        0.12303 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3782438)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=20, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=5, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3782243)[0m {'loss': 1.8564, 'grad_norm': 7.676205635070801, 'learning_rate': 1.1840219327085947e-06, 'epoch': 1.0}

Trial train_hpo_46d963f5 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_46d963f5 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         8e-05 â”‚
â”‚ num_train_epochs                          3 â”‚
â”‚ pos_weight                          7.18321 â”‚
â”‚ weight_decay                        0.25122 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3782634)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3782634)[0m {'loss': 1.7672, 'grad_norm': 3.35884690284729, 'learning_rate': 4.6597713532890536e-05, 'epoch': 1.0}

Trial status: 3 RUNNING | 1 PENDING
Current time: 2025-06-16 16:47:59. Total running time: 30s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status       pos_weight     learning_rate     weight_decay     num_train_epochs â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_cd0231b6   RUNNING         6.82842       1.49561e-06         0.13641                     6 â”‚
â”‚ train_hpo_b583b0df   RUNNING         6.09408       4.55539e-06         0.123031                    5 â”‚
â”‚ train_hpo_46d963f5   RUNNING         7.18321       7.98818e-05         0.251217                    3 â”‚
â”‚ train_hpo_05fcc281   PENDING         7.43106       1.10121e-06         0.13345                     4 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[36m(train_hpo pid=3782634)[0m 2025-06-16 16:48:09,938 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3782634)[0m 2025-06-16 16:48:09,943 - INFO - eval_result: {'eval_loss': 1.0259745121002197, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9257099628448486, 'eval_AP': 0.8491455615444785, 'eval_MCC': 0.0, 'eval_NDCG': 0.965208436547993, 'eval_runtime': 3.2962, 'eval_samples_per_second': 24.27, 'eval_steps_per_second': 1.214, 'epoch': 2.4705882352941178}
2025-06-16 16:48:10,200 - INFO - Cleaning up trial 46d963f5
2025-06-16 16:48:10,200 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_46d963f5_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-47-42
[36m(train_hpo pid=3782634)[0m 2025-06-16 16:48:10,178 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
[36m(train_hpo pid=3783222)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3783222)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3783222)[0m 2025-06-16 16:48:17,984 - INFO - pos_weight value in TrainingArguments : 7.431057651685638
[36m(train_hpo pid=3783222)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3783222)[0m   super().__init__(*args, **kwargs)

[36m(train_hpo pid=3782634)[0m {'loss': 0.902, 'grad_norm': 4.324310302734375, 'learning_rate': 1.3313632437968722e-05, 'epoch': 2.0}[32m [repeated 3x across cluster][0m
[36m(train_hpo pid=3782634)[0m {'train_runtime': 16.2185, 'train_samples_per_second': 62.336, 'train_steps_per_second': 0.74, 'train_loss': 1.2584399382273357, 'epoch': 2.4705882352941178}
[36m(train_hpo pid=3782634)[0m STATE at ending of training  :  TrainerState(epoch=2.4705882352941178, global_step=12, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=219432649955328.0, log_history=[{'loss': 1.7672, 'grad_norm': 3.35884690284729, 'learning_rate': 4.6597713532890536e-05, 'epoch': 1.0, 'step': 5}, {'loss': 0.902, 'grad_norm': 4.324310302734375, 'learning_rate': 1.3313632437968722e-05, 'epoch': 2.0, 'step': 10}, {'loss': 0.8776, 'grad_norm': 5.953787803649902, 'learning_rate': 0.0, 'epoch': 2.4705882352941178, 'step': 12}, {'train_runtime': 16.2185, 'train_samples_per_second': 62.336, 'train_steps_per_second': 0.74, 'total_flos': 219432649955328.0, 'train_loss': 1.2584399382273357, 'epoch': 2.4705882352941178, 'step': 12}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3782634)[0m {'eval_loss': 1.0259745121002197, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9257099628448486, 'eval_AP': 0.8491455615444785, 'eval_MCC': 0.0, 'eval_NDCG': 0.965208436547993, 'eval_runtime': 3.2962, 'eval_samples_per_second': 24.27, 'eval_steps_per_second': 1.214, 'epoch': 2.4705882352941178}
[36m(train_hpo pid=3782634)[0m {'loss': 0.8776, 'grad_norm': 5.953787803649902, 'learning_rate': 0.0, 'epoch': 2.4705882352941178}

Trial train_hpo_46d963f5 finished iteration 1 at 2025-06-16 16:48:10. Total running time: 40s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_46d963f5 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    21.1124 â”‚
â”‚ time_total_s                        21.1124 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               2.47059 â”‚
â”‚ eval_AP                             0.84915 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.96521 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           1.02597 â”‚
â”‚ eval_optim_threshold                0.92571 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.2962 â”‚
â”‚ eval_samples_per_second               24.27 â”‚
â”‚ eval_steps_per_second                 1.214 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_46d963f5 completed after 1 iterations at 2025-06-16 16:48:10. Total running time: 40s
[36m(train_hpo pid=3782243)[0m {'loss': 1.5638, 'grad_norm': 2.907075881958008, 'learning_rate': 5.608524944409133e-07, 'epoch': 3.0}

Trial train_hpo_05fcc281 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_05fcc281 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                             0 â”‚
â”‚ num_train_epochs                          4 â”‚
â”‚ pos_weight                          7.43106 â”‚
â”‚ weight_decay                        0.13345 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3783222)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3783222)[0m {'loss': 1.8737, 'grad_norm': 8.839466094970703, 'learning_rate': 7.570838612609137e-07, 'epoch': 1.0}[32m [repeated 2x across cluster][0m

Trial status: 3 RUNNING | 1 TERMINATED | 1 PENDING
Current time: 2025-06-16 16:48:29. Total running time: 1min 0s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_cd0231b6   RUNNING           6.82842       1.49561e-06         0.13641                     6                                                                                        â”‚
â”‚ train_hpo_b583b0df   RUNNING           6.09408       4.55539e-06         0.123031                    5                                                                                        â”‚
â”‚ train_hpo_05fcc281   RUNNING           7.43106       1.10121e-06         0.13345                     4                                                                                        â”‚
â”‚ train_hpo_46d963f5   TERMINATED        7.18321       7.98818e-05         0.251217                    3        1            21.1124       1.02597    0.848921            0.7375              0 â”‚
â”‚ train_hpo_d0584f58   PENDING           2.2031        4.03208e-05         0.243719                    5                                                                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[36m(train_hpo pid=3782243)[0m 2025-06-16 16:48:48,032 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3782243)[0m 2025-06-16 16:48:48,038 - INFO - eval_result: {'eval_loss': 1.9033958911895752, 'eval_f1': 0.855072463768116, 'eval_accuracy': 0.75, 'eval_kappa': 0.06868451688009314, 'eval_precision': 0.7468354430379747, 'eval_recall': 1.0, 'eval_optim_threshold': 0.7252950072288513, 'eval_AP': 0.8107277101044295, 'eval_MCC': 0.18858311834736916, 'eval_NDCG': 0.9499052348235947, 'eval_runtime': 4.4974, 'eval_samples_per_second': 17.788, 'eval_steps_per_second': 0.889, 'epoch': 4.9411764705882355}
2025-06-16 16:48:48,310 - INFO - Cleaning up trial cd0231b6
[36m(train_hpo pid=3782243)[0m 2025-06-16 16:48:48,287 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
2025-06-16 16:48:48,310 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_cd0231b6_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-47-29
2025-06-16 16:48:48,311 - INFO - Cleaning up trial 46d963f5
2025-06-16 16:48:48,311 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_46d963f5_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-47-42

[36m(train_hpo pid=3783222)[0m {'loss': 1.7359, 'grad_norm': 7.176762580871582, 'learning_rate': 4.129548334150438e-07, 'epoch': 2.0}[32m [repeated 3x across cluster][0m
[36m(train_hpo pid=3783222)[0m {'loss': 1.6368, 'grad_norm': 3.2182672023773193, 'learning_rate': 6.882580556917397e-08, 'epoch': 3.0}
[36m(train_hpo pid=3783222)[0m {'loss': 1.9658, 'grad_norm': 28.592798233032227, 'learning_rate': 0.0, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3783222)[0m {'train_runtime': 21.2083, 'train_samples_per_second': 63.56, 'train_steps_per_second': 0.754, 'train_loss': 1.7623565942049026, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3783222)[0m STATE at ending of training  :  TrainerState(epoch=3.235294117647059, global_step=16, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=287051584054272.0, log_history=[{'loss': 1.8737, 'grad_norm': 8.839466094970703, 'learning_rate': 7.570838612609137e-07, 'epoch': 1.0, 'step': 5}, {'loss': 1.7359, 'grad_norm': 7.176762580871582, 'learning_rate': 4.129548334150438e-07, 'epoch': 2.0, 'step': 10}, {'loss': 1.6368, 'grad_norm': 3.2182672023773193, 'learning_rate': 6.882580556917397e-08, 'epoch': 3.0, 'step': 15}, {'loss': 1.9658, 'grad_norm': 28.592798233032227, 'learning_rate': 0.0, 'epoch': 3.235294117647059, 'step': 16}, {'train_runtime': 21.2083, 'train_samples_per_second': 63.56, 'train_steps_per_second': 0.754, 'total_flos': 287051584054272.0, 'train_loss': 1.7623565942049026, 'epoch': 3.235294117647059, 'step': 16}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3782243)[0m STATE at ending of training  :  TrainerState(epoch=4.9411764705882355, global_step=24, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=438865299910656.0, log_history=[{'loss': 1.8564, 'grad_norm': 7.676205635070801, 'learning_rate': 1.1840219327085947e-06, 'epoch': 1.0, 'step': 5}, {'loss': 1.658, 'grad_norm': 5.6063714027404785, 'learning_rate': 8.724372135747541e-07, 'epoch': 2.0, 'step': 10}, {'loss': 1.5638, 'grad_norm': 2.907075881958008, 'learning_rate': 5.608524944409133e-07, 'epoch': 3.0, 'step': 15}, {'loss': 1.5192, 'grad_norm': 5.326777935028076, 'learning_rate': 2.4926777530707256e-07, 'epoch': 4.0, 'step': 20}, {'loss': 1.7522, 'grad_norm': 19.221115112304688, 'learning_rate': 0.0, 'epoch': 4.9411764705882355, 'step': 24}, {'train_runtime': 66.1905, 'train_samples_per_second': 30.548, 'train_steps_per_second': 0.363, 'total_flos': 438865299910656.0, 'train_loss': 1.666458825270335, 'epoch': 4.9411764705882355, 'step': 24}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3782438)[0m {'loss': 1.1992, 'grad_norm': 2.4555561542510986, 'learning_rate': 0.0, 'epoch': 4.0}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3782438)[0m {'train_runtime': 60.7399, 'train_samples_per_second': 27.741, 'train_steps_per_second': 0.329, 'train_loss': 1.4692543506622315, 'epoch': 4.0}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3782438)[0m STATE at ending of training  :  TrainerState(epoch=4.0, global_step=20, max_steps=20, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=5, num_input_tokens_seen=0, total_flos=354670518153216.0, log_history=[{'loss': 1.9602, 'grad_norm': 8.135847091674805, 'learning_rate': 3.416543648145448e-06, 'epoch': 1.0, 'step': 5}, {'loss': 1.4428, 'grad_norm': 4.154327869415283, 'learning_rate': 2.2776957654302987e-06, 'epoch': 2.0, 'step': 10}, {'loss': 1.2748, 'grad_norm': 2.814453601837158, 'learning_rate': 1.1388478827151493e-06, 'epoch': 3.0, 'step': 15}, {'loss': 1.1992, 'grad_norm': 2.4555561542510986, 'learning_rate': 0.0, 'epoch': 4.0, 'step': 20}, {'train_runtime': 60.7399, 'train_samples_per_second': 27.741, 'train_steps_per_second': 0.329, 'total_flos': 354670518153216.0, 'train_loss': 1.4692543506622315, 'epoch': 4.0, 'step': 20}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3782243)[0m {'eval_loss': 1.9033958911895752, 'eval_f1': 0.855072463768116, 'eval_accuracy': 0.75, 'eval_kappa': 0.06868451688009314, 'eval_precision': 0.7468354430379747, 'eval_recall': 1.0, 'eval_optim_threshold': 0.7252950072288513, 'eval_AP': 0.8107277101044295, 'eval_MCC': 0.18858311834736916, 'eval_NDCG': 0.9499052348235947, 'eval_runtime': 4.4974, 'eval_samples_per_second': 17.788, 'eval_steps_per_second': 0.889, 'epoch': 4.9411764705882355}

Trial train_hpo_cd0231b6 finished iteration 1 at 2025-06-16 16:48:48. Total running time: 1min 18s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_cd0231b6 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    72.4779 â”‚
â”‚ time_total_s                        72.4779 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               4.94118 â”‚
â”‚ eval_AP                             0.81073 â”‚
â”‚ eval_MCC                            0.18858 â”‚
â”‚ eval_NDCG                           0.94991 â”‚
â”‚ eval_accuracy                          0.75 â”‚
â”‚ eval_f1                             0.85507 â”‚
â”‚ eval_kappa                          0.06868 â”‚
â”‚ eval_loss                            1.9034 â”‚
â”‚ eval_optim_threshold                 0.7253 â”‚
â”‚ eval_precision                      0.74684 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         4.4974 â”‚
â”‚ eval_samples_per_second              17.788 â”‚
â”‚ eval_steps_per_second                 0.889 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_cd0231b6 completed after 1 iterations at 2025-06-16 16:48:48. Total running time: 1min 18s

Trial train_hpo_05fcc281 finished iteration 1 at 2025-06-16 16:48:48. Total running time: 1min 18s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_05fcc281 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    31.1934 â”‚
â”‚ time_total_s                        31.1934 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               3.23529 â”‚
â”‚ eval_AP                             0.74111 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.91869 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           2.26309 â”‚
â”‚ eval_optim_threshold                0.68194 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         8.3958 â”‚
â”‚ eval_samples_per_second               9.529 â”‚
â”‚ eval_steps_per_second                 0.476 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯2025-06-16 16:48:48,362 - INFO - Cleaning up trial 05fcc281
2025-06-16 16:48:48,362 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_05fcc281_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-47-49
2025-06-16 16:48:48,362 - INFO - Current best: cd0231b6 with eval_kappa : 0.06868451688009314 at iteration 1
2025-06-16 16:48:48,362 - INFO - Cleaning up trial 46d963f5
2025-06-16 16:48:48,362 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_46d963f5_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-47-42
2025-06-16 16:48:48,626 - INFO - Cleaning up trial b583b0df
2025-06-16 16:48:48,627 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_b583b0df_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-47-35
2025-06-16 16:48:48,627 - INFO - Current best: cd0231b6 with eval_kappa : 0.06868451688009314 at iteration 1
2025-06-16 16:48:48,627 - INFO - Cleaning up trial 46d963f5
2025-06-16 16:48:48,627 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_46d963f5_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-47-42
2025-06-16 16:48:48,627 - INFO - Cleaning up trial 05fcc281
2025-06-16 16:48:48,627 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_05fcc281_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-47-49
[36m(train_hpo pid=3784008)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3784008)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3782438)[0m 2025-06-16 16:48:48,152 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3782438)[0m 2025-06-16 16:48:48,158 - INFO - eval_result: {'eval_loss': 1.3794231414794922, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.8186531662940979, 'eval_AP': 0.7836074381944631, 'eval_MCC': 0.0, 'eval_NDCG': 0.9350740670916274, 'eval_runtime': 3.3492, 'eval_samples_per_second': 23.887, 'eval_steps_per_second': 1.194, 'epoch': 4.0}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3782438)[0m 2025-06-16 16:48:48,601 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3784008)[0m 2025-06-16 16:48:56,206 - INFO - pos_weight value in TrainingArguments : 2.2031009297759248
[36m(train_hpo pid=3784008)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3784008)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3784202)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3784202)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3784202)[0m 2025-06-16 16:49:02,855 - INFO - pos_weight value in TrainingArguments : 4.066204305086463
[36m(train_hpo pid=3784202)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3784202)[0m   super().__init__(*args, **kwargs)


Trial train_hpo_05fcc281 completed after 1 iterations at 2025-06-16 16:48:48. Total running time: 1min 18s

Trial train_hpo_b583b0df finished iteration 1 at 2025-06-16 16:48:48. Total running time: 1min 19s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_b583b0df result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    66.1525 â”‚
â”‚ time_total_s                        66.1525 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                                     4 â”‚
â”‚ eval_AP                             0.78361 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.93507 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           1.37942 â”‚
â”‚ eval_optim_threshold                0.81865 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.3492 â”‚
â”‚ eval_samples_per_second              23.887 â”‚
â”‚ eval_steps_per_second                 1.194 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_b583b0df completed after 1 iterations at 2025-06-16 16:48:48. Total running time: 1min 19s

Trial train_hpo_d0584f58 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_d0584f58 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         4e-05 â”‚
â”‚ num_train_epochs                          5 â”‚
â”‚ pos_weight                           2.2031 â”‚
â”‚ weight_decay                        0.24372 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3784008)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=20, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=5, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3782438)[0m {'eval_loss': 1.3794231414794922, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.8186531662940979, 'eval_AP': 0.7836074381944631, 'eval_MCC': 0.0, 'eval_NDCG': 0.9350740670916274, 'eval_runtime': 3.3492, 'eval_samples_per_second': 23.887, 'eval_steps_per_second': 1.194, 'epoch': 4.0}[32m [repeated 2x across cluster][0m

Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2025-06-16 16:48:59. Total running time: 1min 30s
Logical resource usage: 20.0/32 CPUs, 2.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_d0584f58   RUNNING           2.2031        4.03208e-05         0.243719                    5                                                                                        â”‚
â”‚ train_hpo_cd0231b6   TERMINATED        6.82842       1.49561e-06         0.13641                     6        1            72.4779       1.9034     0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_b583b0df   TERMINATED        6.09408       4.55539e-06         0.123031                    5        1            66.1525       1.37942    0.848921            0.7375      0         â”‚
â”‚ train_hpo_46d963f5   TERMINATED        7.18321       7.98818e-05         0.251217                    3        1            21.1124       1.02597    0.848921            0.7375      0         â”‚
â”‚ train_hpo_05fcc281   TERMINATED        7.43106       1.10121e-06         0.13345                     4        1            31.1934       2.26309    0.848921            0.7375      0         â”‚
â”‚ train_hpo_d68e6c74   PENDING           4.0662        2.70039e-05         0.239866                    3                                                                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_d68e6c74 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_d68e6c74 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         3e-05 â”‚
â”‚ num_train_epochs                          3 â”‚
â”‚ pos_weight                           4.0662 â”‚
â”‚ weight_decay                        0.23987 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3784202)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})[36m(train_hpo pid=3784467)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3784467)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3784467)[0m 2025-06-16 16:49:09,221 - INFO - pos_weight value in TrainingArguments : 7.5755881632194
[36m(train_hpo pid=3784467)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3784467)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3784467)[0m 2025-06-16 16:49:34,236 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3784467)[0m 2025-06-16 16:49:34,241 - INFO - eval_result: {'eval_loss': 1.0049740076065063, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9432436227798462, 'eval_AP': 0.8914599437749544, 'eval_MCC': 0.0, 'eval_NDCG': 0.9575255931163987, 'eval_runtime': 3.2976, 'eval_samples_per_second': 24.26, 'eval_steps_per_second': 1.213, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3784467)[0m 2025-06-16 16:49:34,567 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB

[36m(train_hpo pid=3784008)[0m {'loss': 0.8728, 'grad_norm': 1.4696723222732544, 'learning_rate': 3.0240629384992103e-05, 'epoch': 1.0}

Trial train_hpo_1dbe6141 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_1dbe6141 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         4e-05 â”‚
â”‚ num_train_epochs                          4 â”‚
â”‚ pos_weight                          7.57559 â”‚
â”‚ weight_decay                        0.22021 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3784467)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3784467)[0m {'loss': 1.5487, 'grad_norm': 2.153195858001709, 'learning_rate': 2.7541361839643625e-05, 'epoch': 1.0}
[36m(train_hpo pid=3784467)[0m {'loss': 1.0647, 'grad_norm': 2.3761441707611084, 'learning_rate': 1.5022561003441977e-05, 'epoch': 2.0}[32m [repeated 3x across cluster][0m
[36m(train_hpo pid=3784467)[0m {'loss': 0.9284, 'grad_norm': 2.6627414226531982, 'learning_rate': 2.5037601672403296e-06, 'epoch': 3.0}

Trial status: 4 TERMINATED | 3 RUNNING | 1 PENDING
Current time: 2025-06-16 16:49:29. Total running time: 2min 0s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_d0584f58   RUNNING           2.2031        4.03208e-05         0.243719                    5                                                                                        â”‚
â”‚ train_hpo_d68e6c74   RUNNING           4.0662        2.70039e-05         0.239866                    3                                                                                        â”‚
â”‚ train_hpo_1dbe6141   RUNNING           7.57559       4.00602e-05         0.220208                    4                                                                                        â”‚
â”‚ train_hpo_cd0231b6   TERMINATED        6.82842       1.49561e-06         0.13641                     6        1            72.4779       1.9034     0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_b583b0df   TERMINATED        6.09408       4.55539e-06         0.123031                    5        1            66.1525       1.37942    0.848921            0.7375      0         â”‚
â”‚ train_hpo_46d963f5   TERMINATED        7.18321       7.98818e-05         0.251217                    3        1            21.1124       1.02597    0.848921            0.7375      0         â”‚
â”‚ train_hpo_05fcc281   TERMINATED        7.43106       1.10121e-06         0.13345                     4        1            31.1934       2.26309    0.848921            0.7375      0         â”‚
â”‚ train_hpo_4572b579   PENDING           6.42755       2.7847e-06          0.185124                    2                                                                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3784467)[0m {'loss': 1.0275, 'grad_norm': 6.282386302947998, 'learning_rate': 0.0, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3784467)[0m {'train_runtime': 21.2343, 'train_samples_per_second': 63.482, 'train_steps_per_second': 0.753, 'train_loss': 1.1710133105516434, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3784467)[0m STATE at ending of training  :  TrainerState(epoch=3.235294117647059, global_step=16, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=287051584054272.0, log_history=[{'loss': 1.5487, 'grad_norm': 2.153195858001709, 'learning_rate': 2.7541361839643625e-05, 'epoch': 1.0, 'step': 5}, {'loss': 1.0647, 'grad_norm': 2.3761441707611084, 'learning_rate': 1.5022561003441977e-05, 'epoch': 2.0, 'step': 10}, {'loss': 0.9284, 'grad_norm': 2.6627414226531982, 'learning_rate': 2.5037601672403296e-06, 'epoch': 3.0, 'step': 15}, {'loss': 1.0275, 'grad_norm': 6.282386302947998, 'learning_rate': 0.0, 'epoch': 3.235294117647059, 'step': 16}, {'train_runtime': 21.2343, 'train_samples_per_second': 63.482, 'train_steps_per_second': 0.753, 'total_flos': 287051584054272.0, 'train_loss': 1.1710133105516434, 'epoch': 3.235294117647059, 'step': 16}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3784467)[0m {'eval_loss': 1.0049740076065063, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9432436227798462, 'eval_AP': 0.8914599437749544, 'eval_MCC': 0.0, 'eval_NDCG': 0.9575255931163987, 'eval_runtime': 3.2976, 'eval_samples_per_second': 24.26, 'eval_steps_per_second': 1.213, 'epoch': 3.235294117647059}

Trial train_hpo_1dbe6141 finished iteration 1 at 2025-06-16 16:49:34. Total running time: 2min 5s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_1dbe6141 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    26.1998 â”‚
â”‚ time_total_s                        26.1998 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               3.23529 â”‚
â”‚ eval_AP                             0.89146 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.95753 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           1.00497 â”‚
â”‚ eval_optim_threshold                0.94324 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.2976 â”‚
â”‚ eval_samples_per_second               24.26 â”‚
â”‚ eval_steps_per_second                 1.213 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯2025-06-16 16:49:34,591 - INFO - Cleaning up trial 1dbe6141
2025-06-16 16:49:34,591 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_1dbe6141_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.5756,weight_decay=0.2202_2025-06-16_16-49-02
2025-06-16 16:49:34,591 - INFO - Current best: cd0231b6 with eval_kappa : 0.06868451688009314 at iteration 1
2025-06-16 16:49:34,591 - INFO - Cleaning up trial b583b0df
2025-06-16 16:49:34,591 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_b583b0df_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-47-35
2025-06-16 16:49:34,591 - INFO - Cleaning up trial 46d963f5
2025-06-16 16:49:34,592 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_46d963f5_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-47-42
2025-06-16 16:49:34,592 - INFO - Cleaning up trial 05fcc281
2025-06-16 16:49:34,592 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_05fcc281_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-47-49
[36m(train_hpo pid=3785136)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3785136)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3785136)[0m 2025-06-16 16:49:42,089 - INFO - pos_weight value in TrainingArguments : 6.427550651795176
[36m(train_hpo pid=3785136)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3785136)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3784202)[0m 2025-06-16 16:49:45,391 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3784202)[0m 2025-06-16 16:49:45,396 - INFO - eval_result: {'eval_loss': 0.9698201417922974, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.8447043895721436, 'eval_AP': 0.808382719631134, 'eval_MCC': 0.0, 'eval_NDCG': 0.9473944758500747, 'eval_runtime': 4.0196, 'eval_samples_per_second': 19.902, 'eval_steps_per_second': 0.995, 'epoch': 2.4705882352941178}
2025-06-16 16:49:45,656 - INFO - Cleaning up trial d68e6c74
2025-06-16 16:49:45,656 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_d68e6c74_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-48-55
2025-06-16 16:49:45,656 - INFO - Current best: cd0231b6 with eval_kappa : 0.06868451688009314 at iteration 1
2025-06-16 16:49:45,656 - INFO - Cleaning up trial b583b0df
2025-06-16 16:49:45,656 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_b583b0df_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-47-35
2025-06-16 16:49:45,656 - INFO - Cleaning up trial 46d963f5
2025-06-16 16:49:45,657 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_46d963f5_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-47-42
2025-06-16 16:49:45,657 - INFO - Cleaning up trial 05fcc281
2025-06-16 16:49:45,657 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_05fcc281_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-47-49
2025-06-16 16:49:45,657 - INFO - Cleaning up trial 1dbe6141
2025-06-16 16:49:45,657 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_1dbe6141_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.5756,weight_decay=0.2202_2025-06-16_16-49-02
[36m(train_hpo pid=3784202)[0m 2025-06-16 16:49:45,635 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB


Trial train_hpo_1dbe6141 completed after 1 iterations at 2025-06-16 16:49:34. Total running time: 2min 5s

Trial train_hpo_4572b579 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_4572b579 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                             0 â”‚
â”‚ num_train_epochs                          2 â”‚
â”‚ pos_weight                          6.42755 â”‚
â”‚ weight_decay                        0.18512 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3784202)[0m STATE at ending of training  :  TrainerState(epoch=2.4705882352941178, global_step=12, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=219432649955328.0, log_history=[{'loss': 1.3146, 'grad_norm': 1.4730949401855469, 'learning_rate': 1.5752276202747842e-05, 'epoch': 1.0, 'step': 5}, {'loss': 0.9615, 'grad_norm': 1.9000121355056763, 'learning_rate': 4.50065034364224e-06, 'epoch': 2.0, 'step': 10}, {'loss': 1.0777, 'grad_norm': 4.829284191131592, 'learning_rate': 0.0, 'epoch': 2.4705882352941178, 'step': 12}, {'train_runtime': 37.86, 'train_samples_per_second': 26.704, 'train_steps_per_second': 0.317, 'total_flos': 219432649955328.0, 'train_loss': 1.1279941995938618, 'epoch': 2.4705882352941178, 'step': 12}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3784202)[0m {'loss': 1.0777, 'grad_norm': 4.829284191131592, 'learning_rate': 0.0, 'epoch': 2.4705882352941178}[32m [repeated 3x across cluster][0m
[36m(train_hpo pid=3784202)[0m {'train_runtime': 37.86, 'train_samples_per_second': 26.704, 'train_steps_per_second': 0.317, 'train_loss': 1.1279941995938618, 'epoch': 2.4705882352941178}
[36m(train_hpo pid=3785136)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=8, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=2, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3784008)[0m {'train_runtime': 48.5692, 'train_samples_per_second': 34.693, 'train_steps_per_second': 0.412, 'train_loss': 0.6977070093154907, 'epoch': 4.0}
[36m(train_hpo pid=3784008)[0m STATE at ending of training  :  TrainerState(epoch=4.0, global_step=20, max_steps=20, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=5, num_input_tokens_seen=0, total_flos=354670518153216.0, log_history=[{'loss': 0.8728, 'grad_norm': 1.4696723222732544, 'learning_rate': 3.0240629384992103e-05, 'epoch': 1.0, 'step': 5}, {'loss': 0.7468, 'grad_norm': 1.5537675619125366, 'learning_rate': 2.0160419589994734e-05, 'epoch': 2.0, 'step': 10}, {'loss': 0.6351, 'grad_norm': 2.1091859340667725, 'learning_rate': 1.0080209794997367e-05, 'epoch': 3.0, 'step': 15}, {'loss': 0.5362, 'grad_norm': 1.6221263408660889, 'learning_rate': 0.0, 'epoch': 4.0, 'step': 20}, {'train_runtime': 48.5692, 'train_samples_per_second': 34.693, 'train_steps_per_second': 0.412, 'total_flos': 354670518153216.0, 'train_loss': 0.6977070093154907, 'epoch': 4.0, 'step': 20}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3784202)[0m {'eval_loss': 0.9698201417922974, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.8447043895721436, 'eval_AP': 0.808382719631134, 'eval_MCC': 0.0, 'eval_NDCG': 0.9473944758500747, 'eval_runtime': 4.0196, 'eval_samples_per_second': 19.902, 'eval_steps_per_second': 0.995, 'epoch': 2.4705882352941178}

Trial train_hpo_d68e6c74 finished iteration 1 at 2025-06-16 16:49:45. Total running time: 2min 16s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_d68e6c74 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    43.6421 â”‚
â”‚ time_total_s                        43.6421 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               2.47059 â”‚
â”‚ eval_AP                             0.80838 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.94739 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           0.96982 â”‚
â”‚ eval_optim_threshold                 0.8447 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         4.0196 â”‚
â”‚ eval_samples_per_second              19.902 â”‚
â”‚ eval_steps_per_second                 0.995 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_d68e6c74 completed after 1 iterations at 2025-06-16 16:49:45. Total running time: 2min 16s
[36m(train_hpo pid=3784008)[0m {'loss': 0.5362, 'grad_norm': 1.6221263408660889, 'learning_rate': 0.0, 'epoch': 4.0}

Trial train_hpo_d0584f58 finished iteration 1 at 2025-06-16 16:49:49. Total running time: 2min 19s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_d0584f58 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                     53.627 â”‚
â”‚ time_total_s                         53.627 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                                     4 â”‚
â”‚ eval_AP                             0.91511 â”‚
â”‚ eval_MCC                             0.2684 â”‚
â”‚ eval_NDCG                           0.98116 â”‚
â”‚ eval_accuracy                        0.7625 â”‚
â”‚ eval_f1                             0.86131 â”‚
â”‚ eval_kappa                           0.1344 â”‚
â”‚ eval_loss                           0.66772 â”‚
â”‚ eval_optim_threshold                0.84707 â”‚
â”‚ eval_precision                      0.75641 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.4697 â”‚
â”‚ eval_samples_per_second              23.057 â”‚
â”‚ eval_steps_per_second                 1.153 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯2025-06-16 16:49:49,010 - INFO - Cleaning up trial d0584f58
2025-06-16 16:49:49,010 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_d0584f58_5_learning_rate=0.0000,num_train_epochs=5,pos_weight=2.2031,weight_decay=0.2437_2025-06-16_16-48-17
2025-06-16 16:49:49,011 - INFO - Cleaning up trial cd0231b6
2025-06-16 16:49:49,011 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_cd0231b6_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-47-29
2025-06-16 16:49:49,011 - INFO - Cleaning up trial b583b0df
2025-06-16 16:49:49,011 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_b583b0df_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-47-35
2025-06-16 16:49:49,011 - INFO - Cleaning up trial 46d963f5
2025-06-16 16:49:49,011 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_46d963f5_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-47-42
2025-06-16 16:49:49,011 - INFO - Cleaning up trial 05fcc281
2025-06-16 16:49:49,011 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_05fcc281_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-47-49
2025-06-16 16:49:49,011 - INFO - Cleaning up trial d68e6c74
2025-06-16 16:49:49,011 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_d68e6c74_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-48-55
2025-06-16 16:49:49,011 - INFO - Cleaning up trial 1dbe6141
2025-06-16 16:49:49,011 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_1dbe6141_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.5756,weight_decay=0.2202_2025-06-16_16-49-02
[36m(train_hpo pid=3785442)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3785442)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3784008)[0m 2025-06-16 16:49:48,744 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3784008)[0m 2025-06-16 16:49:48,749 - INFO - eval_result: {'eval_loss': 0.6677157878875732, 'eval_f1': 0.8613138686131386, 'eval_accuracy': 0.7625, 'eval_kappa': 0.13439635535307526, 'eval_precision': 0.7564102564102564, 'eval_recall': 1.0, 'eval_optim_threshold': 0.8470657467842102, 'eval_AP': 0.9151102797131424, 'eval_MCC': 0.26840095387139007, 'eval_NDCG': 0.981157247548447, 'eval_runtime': 3.4697, 'eval_samples_per_second': 23.057, 'eval_steps_per_second': 1.153, 'epoch': 4.0}
[36m(train_hpo pid=3784008)[0m 2025-06-16 16:49:48,989 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
[36m(train_hpo pid=3785442)[0m 2025-06-16 16:49:53,154 - INFO - pos_weight value in TrainingArguments : 7.440064585061213
[36m(train_hpo pid=3785442)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3785442)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3785136)[0m 2025-06-16 16:49:57,340 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3785136)[0m 2025-06-16 16:49:57,345 - INFO - eval_result: {'eval_loss': 2.790830135345459, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.5765864253044128, 'eval_AP': 0.7283445715931727, 'eval_MCC': 0.0, 'eval_NDCG': 0.9132435181533816, 'eval_runtime': 3.3496, 'eval_samples_per_second': 23.883, 'eval_steps_per_second': 1.194, 'epoch': 1.7058823529411766}
2025-06-16 16:49:57,601 - INFO - Cleaning up trial 4572b579
2025-06-16 16:49:57,601 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_4572b579_8_learning_rate=0.0000,num_train_epochs=2,pos_weight=6.4276,weight_decay=0.1851_2025-06-16_16-49-08
2025-06-16 16:49:57,601 - INFO - Cleaning up trial cd0231b6
2025-06-16 16:49:57,602 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_cd0231b6_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-47-29
2025-06-16 16:49:57,602 - INFO - Cleaning up trial b583b0df
2025-06-16 16:49:57,602 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_b583b0df_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-47-35
2025-06-16 16:49:57,602 - INFO - Cleaning up trial 46d963f5
2025-06-16 16:49:57,602 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_46d963f5_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-47-42
2025-06-16 16:49:57,602 - INFO - Cleaning up trial 05fcc281
2025-06-16 16:49:57,602 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_05fcc281_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-47-49
2025-06-16 16:49:57,602 - INFO - Current best: d0584f58 with eval_kappa : 0.13439635535307526 at iteration 1
2025-06-16 16:49:57,602 - INFO - Cleaning up trial d68e6c74
2025-06-16 16:49:57,602 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_d68e6c74_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-48-55
2025-06-16 16:49:57,602 - INFO - Cleaning up trial 1dbe6141
2025-06-16 16:49:57,602 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_1dbe6141_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.5756,weight_decay=0.2202_2025-06-16_16-49-02
[36m(train_hpo pid=3785136)[0m 2025-06-16 16:49:57,580 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB


Trial train_hpo_d0584f58 completed after 1 iterations at 2025-06-16 16:49:49. Total running time: 2min 19s
[36m(train_hpo pid=3785136)[0m {'loss': 2.1692, 'grad_norm': 10.926676750183105, 'learning_rate': 1.0442639949699175e-06, 'epoch': 1.0}

Trial train_hpo_29d0318b started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_29d0318b config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         5e-05 â”‚
â”‚ num_train_epochs                          6 â”‚
â”‚ pos_weight                          7.44006 â”‚
â”‚ weight_decay                        0.16302 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3785442)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3784008)[0m {'eval_loss': 0.6677157878875732, 'eval_f1': 0.8613138686131386, 'eval_accuracy': 0.7625, 'eval_kappa': 0.13439635535307526, 'eval_precision': 0.7564102564102564, 'eval_recall': 1.0, 'eval_optim_threshold': 0.8470657467842102, 'eval_AP': 0.9151102797131424, 'eval_MCC': 0.26840095387139007, 'eval_NDCG': 0.981157247548447, 'eval_runtime': 3.4697, 'eval_samples_per_second': 23.057, 'eval_steps_per_second': 1.153, 'epoch': 4.0}
[36m(train_hpo pid=3785136)[0m {'loss': 2.3197, 'grad_norm': 45.757530212402344, 'learning_rate': 0.0, 'epoch': 1.7058823529411766}
[36m(train_hpo pid=3785136)[0m {'train_runtime': 11.4097, 'train_samples_per_second': 59.073, 'train_steps_per_second': 0.701, 'train_loss': 2.225647807121277, 'epoch': 1.7058823529411766}
[36m(train_hpo pid=3785136)[0m STATE at ending of training  :  TrainerState(epoch=1.7058823529411766, global_step=8, max_steps=8, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=2, num_input_tokens_seen=0, total_flos=151813715856384.0, log_history=[{'loss': 2.1692, 'grad_norm': 10.926676750183105, 'learning_rate': 1.0442639949699175e-06, 'epoch': 1.0, 'step': 5}, {'loss': 2.3197, 'grad_norm': 45.757530212402344, 'learning_rate': 0.0, 'epoch': 1.7058823529411766, 'step': 8}, {'train_runtime': 11.4097, 'train_samples_per_second': 59.073, 'train_steps_per_second': 0.701, 'total_flos': 151813715856384.0, 'train_loss': 2.225647807121277, 'epoch': 1.7058823529411766, 'step': 8}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3785136)[0m {'eval_loss': 2.790830135345459, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.5765864253044128, 'eval_AP': 0.7283445715931727, 'eval_MCC': 0.0, 'eval_NDCG': 0.9132435181533816, 'eval_runtime': 3.3496, 'eval_samples_per_second': 23.883, 'eval_steps_per_second': 1.194, 'epoch': 1.7058823529411766}

Trial train_hpo_4572b579 finished iteration 1 at 2025-06-16 16:49:57. Total running time: 2min 28s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_4572b579 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    16.3266 â”‚
â”‚ time_total_s                        16.3266 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               1.70588 â”‚
â”‚ eval_AP                             0.72834 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.91324 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           2.79083 â”‚
â”‚ eval_optim_threshold                0.57659 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.3496 â”‚
â”‚ eval_samples_per_second              23.883 â”‚
â”‚ eval_steps_per_second                 1.194 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_4572b579 completed after 1 iterations at 2025-06-16 16:49:57. Total running time: 2min 28s

Trial train_hpo_3cc999f6 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_3cc999f6 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         1e-05 â”‚
â”‚ num_train_epochs                          3 â”‚
â”‚ pos_weight                          5.90435 â”‚
â”‚ weight_decay                        0.28664 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 8 TERMINATED | 2 RUNNING | 1 PENDING
Current time: 2025-06-16 16:49:59. Total running time: 2min 30s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_29d0318b   RUNNING           7.44006       4.73492e-05       0.163021                      6                                                                                        â”‚
â”‚ train_hpo_3cc999f6   RUNNING           5.90435       6.78644e-06       0.286643                      3                                                                                        â”‚
â”‚ train_hpo_cd0231b6   TERMINATED        6.82842       1.49561e-06       0.13641                       6        1            72.4779      1.9034      0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_b583b0df   TERMINATED        6.09408       4.55539e-06       0.123031                      5        1            66.1525      1.37942     0.848921            0.7375      0         â”‚
â”‚ train_hpo_46d963f5   TERMINATED        7.18321       7.98818e-05       0.251217                      3        1            21.1124      1.02597     0.848921            0.7375      0         â”‚
â”‚ train_hpo_05fcc281   TERMINATED        7.43106       1.10121e-06       0.13345                       4        1            31.1934      2.26309     0.848921            0.7375      0         â”‚
â”‚ train_hpo_d0584f58   TERMINATED        2.2031        4.03208e-05       0.243719                      5        1            53.627       0.667716    0.861314            0.7625      0.134396  â”‚
â”‚ train_hpo_d68e6c74   TERMINATED        4.0662        2.70039e-05       0.239866                      3        1            43.6421      0.96982     0.848921            0.7375      0         â”‚
â”‚ train_hpo_1dbe6141   TERMINATED        7.57559       4.00602e-05       0.220208                      4        1            26.1998      1.00497     0.848921            0.7375      0         â”‚
â”‚ train_hpo_4572b579   TERMINATED        6.42755       2.7847e-06        0.185124                      2        1            16.3266      2.79083     0.848921            0.7375      0         â”‚
â”‚ train_hpo_e89e4d38   PENDING           6.72481       3.23119e-05       0.00108909                    6                                                                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[36m(train_hpo pid=3785648)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3785648)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3785648)[0m 2025-06-16 16:49:59,869 - INFO - pos_weight value in TrainingArguments : 5.904350112349562
[36m(train_hpo pid=3785648)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3785648)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3785923)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3785923)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3785923)[0m 2025-06-16 16:50:06,333 - INFO - pos_weight value in TrainingArguments : 6.7248101376462595
[36m(train_hpo pid=3785923)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3785923)[0m   super().__init__(*args, **kwargs)

[36m(train_hpo pid=3785648)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3785442)[0m {'loss': 2.023, 'grad_norm': 1.9079647064208984, 'learning_rate': 3.748480305116433e-05, 'epoch': 1.0}

Trial train_hpo_e89e4d38 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_e89e4d38 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         3e-05 â”‚
â”‚ num_train_epochs                          6 â”‚
â”‚ pos_weight                          6.72481 â”‚
â”‚ weight_decay                        0.00109 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3785923)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3785923)[0m {'loss': 1.6344, 'grad_norm': 1.3508137464523315, 'learning_rate': 2.5580274158205587e-05, 'epoch': 1.0}
[36m(train_hpo pid=3785923)[0m {'loss': 1.0674, 'grad_norm': 2.173391342163086, 'learning_rate': 1.8848623063940963e-05, 'epoch': 2.0}[32m [repeated 3x across cluster][0m
[36m(train_hpo pid=3785923)[0m {'loss': 0.9102, 'grad_norm': 2.5243773460388184, 'learning_rate': 1.2116971969676332e-05, 'epoch': 3.0}

Trial status: 8 TERMINATED | 3 RUNNING | 1 PENDING
Current time: 2025-06-16 16:50:29. Total running time: 3min 0s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_29d0318b   RUNNING           7.44006       4.73492e-05       0.163021                      6                                                                                        â”‚
â”‚ train_hpo_3cc999f6   RUNNING           5.90435       6.78644e-06       0.286643                      3                                                                                        â”‚
â”‚ train_hpo_e89e4d38   RUNNING           6.72481       3.23119e-05       0.00108909                    6                                                                                        â”‚
â”‚ train_hpo_cd0231b6   TERMINATED        6.82842       1.49561e-06       0.13641                       6        1            72.4779      1.9034      0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_b583b0df   TERMINATED        6.09408       4.55539e-06       0.123031                      5        1            66.1525      1.37942     0.848921            0.7375      0         â”‚
â”‚ train_hpo_46d963f5   TERMINATED        7.18321       7.98818e-05       0.251217                      3        1            21.1124      1.02597     0.848921            0.7375      0         â”‚
â”‚ train_hpo_05fcc281   TERMINATED        7.43106       1.10121e-06       0.13345                       4        1            31.1934      2.26309     0.848921            0.7375      0         â”‚
â”‚ train_hpo_d0584f58   TERMINATED        2.2031        4.03208e-05       0.243719                      5        1            53.627       0.667716    0.861314            0.7625      0.134396  â”‚
â”‚ train_hpo_d68e6c74   TERMINATED        4.0662        2.70039e-05       0.239866                      3        1            43.6421      0.96982     0.848921            0.7375      0         â”‚
â”‚ train_hpo_1dbe6141   TERMINATED        7.57559       4.00602e-05       0.220208                      4        1            26.1998      1.00497     0.848921            0.7375      0         â”‚
â”‚ train_hpo_4572b579   TERMINATED        6.42755       2.7847e-06        0.185124                      2        1            16.3266      2.79083     0.848921            0.7375      0         â”‚
â”‚ train_hpo_408df180   PENDING           3.50937       2.07214e-05       0.263741                      4                                                                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3785442)[0m {'loss': 0.8899, 'grad_norm': 2.0471348762512207, 'learning_rate': 1.7755959340025214e-05, 'epoch': 3.0}
[36m(train_hpo pid=3785648)[0m {'train_runtime': 37.8958, 'train_samples_per_second': 26.678, 'train_steps_per_second': 0.317, 'train_loss': 1.4691789944966633, 'epoch': 2.4705882352941178}
[36m(train_hpo pid=3785648)[0m STATE at ending of training  :  TrainerState(epoch=2.4705882352941178, global_step=12, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=219432649955328.0, log_history=[{'loss': 1.6954, 'grad_norm': 5.750371932983398, 'learning_rate': 3.958758137704503e-06, 'epoch': 1.0, 'step': 5}, {'loss': 1.2689, 'grad_norm': 2.4882616996765137, 'learning_rate': 1.131073753629858e-06, 'epoch': 2.0, 'step': 10}, {'loss': 1.4042, 'grad_norm': 5.687855243682861, 'learning_rate': 0.0, 'epoch': 2.4705882352941178, 'step': 12}, {'train_runtime': 37.8958, 'train_samples_per_second': 26.678, 'train_steps_per_second': 0.317, 'total_flos': 219432649955328.0, 'train_loss': 1.4691789944966633, 'epoch': 2.4705882352941178, 'step': 12}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})[36m(train_hpo pid=3785923)[0m 2025-06-16 16:50:42,469 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3785923)[0m 2025-06-16 16:50:42,474 - INFO - eval_result: {'eval_loss': 0.9557243585586548, 'eval_f1': 0.855072463768116, 'eval_accuracy': 0.75, 'eval_kappa': 0.06868451688009314, 'eval_precision': 0.7468354430379747, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9446767568588257, 'eval_AP': 0.8455161263208193, 'eval_MCC': 0.18858311834736916, 'eval_NDCG': 0.9489876325619322, 'eval_runtime': 3.2727, 'eval_samples_per_second': 24.445, 'eval_steps_per_second': 1.222, 'epoch': 4.9411764705882355}
2025-06-16 16:50:42,740 - INFO - Cleaning up trial e89e4d38
2025-06-16 16:50:42,740 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_e89e4d38_11_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.7248,weight_decay=0.0011_2025-06-16_16-49-59
2025-06-16 16:50:42,740 - INFO - Cleaning up trial cd0231b6
2025-06-16 16:50:42,741 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_cd0231b6_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-47-29
2025-06-16 16:50:42,741 - INFO - Cleaning up trial b583b0df
2025-06-16 16:50:42,741 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_b583b0df_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-47-35
2025-06-16 16:50:42,741 - INFO - Cleaning up trial 46d963f5
2025-06-16 16:50:42,741 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_46d963f5_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-47-42
2025-06-16 16:50:42,741 - INFO - Cleaning up trial 05fcc281
2025-06-16 16:50:42,741 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_05fcc281_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-47-49
2025-06-16 16:50:42,741 - INFO - Current best: d0584f58 with eval_kappa : 0.13439635535307526 at iteration 1
2025-06-16 16:50:42,741 - INFO - Cleaning up trial d68e6c74
2025-06-16 16:50:42,741 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_d68e6c74_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-48-55
2025-06-16 16:50:42,741 - INFO - Cleaning up trial 1dbe6141
2025-06-16 16:50:42,742 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_1dbe6141_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.5756,weight_decay=0.2202_2025-06-16_16-49-02
2025-06-16 16:50:42,742 - INFO - Cleaning up trial 4572b579
2025-06-16 16:50:42,742 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_4572b579_8_learning_rate=0.0000,num_train_epochs=2,pos_weight=6.4276,weight_decay=0.1851_2025-06-16_16-49-08
2025-06-16 16:50:42,774 - INFO - Cleaning up trial 3cc999f6
2025-06-16 16:50:42,774 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_3cc999f6_10_learning_rate=0.0000,num_train_epochs=3,pos_weight=5.9044,weight_decay=0.2866_2025-06-16_16-49-52
2025-06-16 16:50:42,774 - INFO - Cleaning up trial cd0231b6
2025-06-16 16:50:42,774 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_cd0231b6_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-47-29
2025-06-16 16:50:42,775 - INFO - Cleaning up trial b583b0df
2025-06-16 16:50:42,775 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_b583b0df_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-47-35
2025-06-16 16:50:42,775 - INFO - Cleaning up trial 46d963f5
2025-06-16 16:50:42,775 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_46d963f5_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-47-42
2025-06-16 16:50:42,775 - INFO - Cleaning up trial 05fcc281
2025-06-16 16:50:42,775 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_05fcc281_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-47-49
2025-06-16 16:50:42,775 - INFO - Current best: d0584f58 with eval_kappa : 0.13439635535307526 at iteration 1
2025-06-16 16:50:42,775 - INFO - Cleaning up trial d68e6c74
2025-06-16 16:50:42,775 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_d68e6c74_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-48-55
2025-06-16 16:50:42,775 - INFO - Cleaning up trial 1dbe6141
2025-06-16 16:50:42,775 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_1dbe6141_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.5756,weight_decay=0.2202_2025-06-16_16-49-02
2025-06-16 16:50:42,776 - INFO - Cleaning up trial 4572b579
2025-06-16 16:50:42,776 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_4572b579_8_learning_rate=0.0000,num_train_epochs=2,pos_weight=6.4276,weight_decay=0.1851_2025-06-16_16-49-08
2025-06-16 16:50:42,776 - INFO - Cleaning up trial e89e4d38
2025-06-16 16:50:42,776 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_e89e4d38_11_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.7248,weight_decay=0.0011_2025-06-16_16-49-59
[36m(train_hpo pid=3785648)[0m 2025-06-16 16:50:42,753 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB

[36m(train_hpo pid=3785648)[0m {'loss': 1.4042, 'grad_norm': 5.687855243682861, 'learning_rate': 0.0, 'epoch': 2.4705882352941178}[32m [repeated 3x across cluster][0m
[36m(train_hpo pid=3785923)[0m STATE at ending of training  :  TrainerState(epoch=4.9411764705882355, global_step=24, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=438865299910656.0, log_history=[{'loss': 1.6344, 'grad_norm': 1.3508137464523315, 'learning_rate': 2.5580274158205587e-05, 'epoch': 1.0, 'step': 5}, {'loss': 1.0674, 'grad_norm': 2.173391342163086, 'learning_rate': 1.8848623063940963e-05, 'epoch': 2.0, 'step': 10}, {'loss': 0.9102, 'grad_norm': 2.5243773460388184, 'learning_rate': 1.2116971969676332e-05, 'epoch': 3.0, 'step': 15}, {'loss': 0.7717, 'grad_norm': 2.0032336711883545, 'learning_rate': 5.3853208754117024e-06, 'epoch': 4.0, 'step': 20}, {'loss': 0.8216, 'grad_norm': 5.658943176269531, 'learning_rate': 0.0, 'epoch': 4.9411764705882355, 'step': 24}, {'train_runtime': 32.3738, 'train_samples_per_second': 62.458, 'train_steps_per_second': 0.741, 'total_flos': 438865299910656.0, 'train_loss': 1.0501622955004375, 'epoch': 4.9411764705882355, 'step': 24}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3785923)[0m {'eval_loss': 0.9557243585586548, 'eval_f1': 0.855072463768116, 'eval_accuracy': 0.75, 'eval_kappa': 0.06868451688009314, 'eval_precision': 0.7468354430379747, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9446767568588257, 'eval_AP': 0.8455161263208193, 'eval_MCC': 0.18858311834736916, 'eval_NDCG': 0.9489876325619322, 'eval_runtime': 3.2727, 'eval_samples_per_second': 24.445, 'eval_steps_per_second': 1.222, 'epoch': 4.9411764705882355}

Trial train_hpo_e89e4d38 finished iteration 1 at 2025-06-16 16:50:42. Total running time: 3min 13s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_e89e4d38 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    37.2118 â”‚
â”‚ time_total_s                        37.2118 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               4.94118 â”‚
â”‚ eval_AP                             0.84552 â”‚
â”‚ eval_MCC                            0.18858 â”‚
â”‚ eval_NDCG                           0.94899 â”‚
â”‚ eval_accuracy                          0.75 â”‚
â”‚ eval_f1                             0.85507 â”‚
â”‚ eval_kappa                          0.06868 â”‚
â”‚ eval_loss                           0.95572 â”‚
â”‚ eval_optim_threshold                0.94468 â”‚
â”‚ eval_precision                      0.74684 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.2727 â”‚
â”‚ eval_samples_per_second              24.445 â”‚
â”‚ eval_steps_per_second                 1.222 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_e89e4d38 completed after 1 iterations at 2025-06-16 16:50:42. Total running time: 3min 13s

Trial train_hpo_3cc999f6 finished iteration 1 at 2025-06-16 16:50:42. Total running time: 3min 13s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_3cc999f6 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    43.7224 â”‚
â”‚ time_total_s                        43.7224 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               2.47059 â”‚
â”‚ eval_AP                             0.82028 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.95447 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           1.35345 â”‚
â”‚ eval_optim_threshold                0.82239 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         4.0841 â”‚
â”‚ eval_samples_per_second              19.588 â”‚
â”‚ eval_steps_per_second                 0.979 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_3cc999f6 completed after 1 iterations at 2025-06-16 16:50:42. Total running time: 3min 13s
[36m(train_hpo pid=3785442)[0m {'train_runtime': 54.8618, 'train_samples_per_second': 36.856, 'train_steps_per_second': 0.437, 'train_loss': 1.1199739178021748, 'epoch': 4.9411764705882355}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3785442)[0m {'loss': 0.8159, 'grad_norm': 4.829774379730225, 'learning_rate': 0.0, 'epoch': 4.9411764705882355}[32m [repeated 3x across cluster][0m
[36m(train_hpo pid=3785442)[0m STATE at ending of training  :  TrainerState(epoch=4.9411764705882355, global_step=24, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=438865299910656.0, log_history=[{'loss': 2.023, 'grad_norm': 1.9079647064208984, 'learning_rate': 3.748480305116433e-05, 'epoch': 1.0, 'step': 5}, {'loss': 1.0608, 'grad_norm': 1.8744192123413086, 'learning_rate': 2.7620381195594777e-05, 'epoch': 2.0, 'step': 10}, {'loss': 0.8899, 'grad_norm': 2.0471348762512207, 'learning_rate': 1.7755959340025214e-05, 'epoch': 3.0, 'step': 15}, {'loss': 0.7494, 'grad_norm': 2.2895069122314453, 'learning_rate': 7.89153748445565e-06, 'epoch': 4.0, 'step': 20}, {'loss': 0.8159, 'grad_norm': 4.829774379730225, 'learning_rate': 0.0, 'epoch': 4.9411764705882355, 'step': 24}, {'train_runtime': 54.8618, 'train_samples_per_second': 36.856, 'train_steps_per_second': 0.437, 'total_flos': 438865299910656.0, 'train_loss': 1.1199739178021748, 'epoch': 4.9411764705882355, 'step': 24}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3785648)[0m {'eval_loss': 1.35344660282135, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.8223922252655029, 'eval_AP': 0.8202815107329703, 'eval_MCC': 0.0, 'eval_NDCG': 0.9544703422643914, 'eval_runtime': 4.0841, 'eval_samples_per_second': 19.588, 'eval_steps_per_second': 0.979, 'epoch': 2.4705882352941178}

Trial train_hpo_408df180 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_408df180 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         2e-05 â”‚
â”‚ num_train_epochs                          4 â”‚
â”‚ pos_weight                          3.50937 â”‚
â”‚ weight_decay                        0.26374 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[36m(train_hpo pid=3786814)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3786814)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3785648)[0m 2025-06-16 16:50:42,502 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3785648)[0m 2025-06-16 16:50:42,507 - INFO - eval_result: {'eval_loss': 1.35344660282135, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.8223922252655029, 'eval_AP': 0.8202815107329703, 'eval_MCC': 0.0, 'eval_NDCG': 0.9544703422643914, 'eval_runtime': 4.0841, 'eval_samples_per_second': 19.588, 'eval_steps_per_second': 0.979, 'epoch': 2.4705882352941178}
[36m(train_hpo pid=3785923)[0m 2025-06-16 16:50:42,718 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
[36m(train_hpo pid=3786814)[0m 2025-06-16 16:50:51,354 - INFO - pos_weight value in TrainingArguments : 3.5093706580135486
[36m(train_hpo pid=3786814)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3786814)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3785442)[0m 2025-06-16 16:50:51,831 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3785442)[0m 2025-06-16 16:50:51,837 - INFO - eval_result: {'eval_loss': 0.9351989030838013, 'eval_f1': 0.855072463768116, 'eval_accuracy': 0.75, 'eval_kappa': 0.06868451688009314, 'eval_precision': 0.7468354430379747, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9653297066688538, 'eval_AP': 0.926518332301052, 'eval_MCC': 0.18858311834736916, 'eval_NDCG': 0.9852819348681432, 'eval_runtime': 3.3039, 'eval_samples_per_second': 24.214, 'eval_steps_per_second': 1.211, 'epoch': 4.9411764705882355}
[36m(train_hpo pid=3785442)[0m 2025-06-16 16:50:52,079 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
2025-06-16 16:50:52,103 - INFO - Cleaning up trial 29d0318b
2025-06-16 16:50:52,103 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_29d0318b_9_learning_rate=0.0000,num_train_epochs=6,pos_weight=7.4401,weight_decay=0.1630_2025-06-16_16-49-41
2025-06-16 16:50:52,104 - INFO - Cleaning up trial cd0231b6
2025-06-16 16:50:52,104 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_cd0231b6_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-47-29
2025-06-16 16:50:52,104 - INFO - Cleaning up trial b583b0df
2025-06-16 16:50:52,104 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_b583b0df_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-47-35
2025-06-16 16:50:52,104 - INFO - Cleaning up trial 46d963f5
2025-06-16 16:50:52,104 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_46d963f5_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-47-42
2025-06-16 16:50:52,104 - INFO - Cleaning up trial 05fcc281
2025-06-16 16:50:52,104 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_05fcc281_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-47-49
2025-06-16 16:50:52,104 - INFO - Current best: d0584f58 with eval_kappa : 0.13439635535307526 at iteration 1
2025-06-16 16:50:52,104 - INFO - Cleaning up trial d68e6c74
2025-06-16 16:50:52,104 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_d68e6c74_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-48-55
2025-06-16 16:50:52,104 - INFO - Cleaning up trial 1dbe6141
2025-06-16 16:50:52,105 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_1dbe6141_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.5756,weight_decay=0.2202_2025-06-16_16-49-02
2025-06-16 16:50:52,105 - INFO - Cleaning up trial 4572b579
2025-06-16 16:50:52,105 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_4572b579_8_learning_rate=0.0000,num_train_epochs=2,pos_weight=6.4276,weight_decay=0.1851_2025-06-16_16-49-08
2025-06-16 16:50:52,105 - INFO - Cleaning up trial 3cc999f6
2025-06-16 16:50:52,105 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_3cc999f6_10_learning_rate=0.0000,num_train_epochs=3,pos_weight=5.9044,weight_decay=0.2866_2025-06-16_16-49-52
2025-06-16 16:50:52,105 - INFO - Cleaning up trial e89e4d38
2025-06-16 16:50:52,105 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_e89e4d38_11_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.7248,weight_decay=0.0011_2025-06-16_16-49-59

[36m(train_hpo pid=3785442)[0m {'eval_loss': 0.9351989030838013, 'eval_f1': 0.855072463768116, 'eval_accuracy': 0.75, 'eval_kappa': 0.06868451688009314, 'eval_precision': 0.7468354430379747, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9653297066688538, 'eval_AP': 0.926518332301052, 'eval_MCC': 0.18858311834736916, 'eval_NDCG': 0.9852819348681432, 'eval_runtime': 3.3039, 'eval_samples_per_second': 24.214, 'eval_steps_per_second': 1.211, 'epoch': 4.9411764705882355}
[36m(train_hpo pid=3786814)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})

Trial train_hpo_29d0318b finished iteration 1 at 2025-06-16 16:50:52. Total running time: 3min 22s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_29d0318b result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    59.7755 â”‚
â”‚ time_total_s                        59.7755 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               4.94118 â”‚
â”‚ eval_AP                             0.92652 â”‚
â”‚ eval_MCC                            0.18858 â”‚
â”‚ eval_NDCG                           0.98528 â”‚
â”‚ eval_accuracy                          0.75 â”‚
â”‚ eval_f1                             0.85507 â”‚
â”‚ eval_kappa                          0.06868 â”‚
â”‚ eval_loss                            0.9352 â”‚
â”‚ eval_optim_threshold                0.96533 â”‚
â”‚ eval_precision                      0.74684 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.3039 â”‚
â”‚ eval_samples_per_second              24.214 â”‚
â”‚ eval_steps_per_second                 1.211 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_29d0318b completed after 1 iterations at 2025-06-16 16:50:52. Total running time: 3min 22s
[36m(train_hpo pid=3786814)[0m {'loss': 1.2049, 'grad_norm': 1.6049590110778809, 'learning_rate': 1.4245962766850404e-05, 'epoch': 1.0}

Trial status: 11 TERMINATED | 1 RUNNING
Current time: 2025-06-16 16:50:59. Total running time: 3min 30s
Logical resource usage: 10.0/32 CPUs, 1.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_408df180   RUNNING           3.50937       2.07214e-05       0.263741                      4                                                                                        â”‚
â”‚ train_hpo_cd0231b6   TERMINATED        6.82842       1.49561e-06       0.13641                       6        1            72.4779      1.9034      0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_b583b0df   TERMINATED        6.09408       4.55539e-06       0.123031                      5        1            66.1525      1.37942     0.848921            0.7375      0         â”‚
â”‚ train_hpo_46d963f5   TERMINATED        7.18321       7.98818e-05       0.251217                      3        1            21.1124      1.02597     0.848921            0.7375      0         â”‚
â”‚ train_hpo_05fcc281   TERMINATED        7.43106       1.10121e-06       0.13345                       4        1            31.1934      2.26309     0.848921            0.7375      0         â”‚
â”‚ train_hpo_d0584f58   TERMINATED        2.2031        4.03208e-05       0.243719                      5        1            53.627       0.667716    0.861314            0.7625      0.134396  â”‚
â”‚ train_hpo_d68e6c74   TERMINATED        4.0662        2.70039e-05       0.239866                      3        1            43.6421      0.96982     0.848921            0.7375      0         â”‚
â”‚ train_hpo_1dbe6141   TERMINATED        7.57559       4.00602e-05       0.220208                      4        1            26.1998      1.00497     0.848921            0.7375      0         â”‚
â”‚ train_hpo_4572b579   TERMINATED        6.42755       2.7847e-06        0.185124                      2        1            16.3266      2.79083     0.848921            0.7375      0         â”‚
â”‚ train_hpo_29d0318b   TERMINATED        7.44006       4.73492e-05       0.163021                      6        1            59.7755      0.935199    0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_3cc999f6   TERMINATED        5.90435       6.78644e-06       0.286643                      3        1            43.7224      1.35345     0.848921            0.7375      0         â”‚
â”‚ train_hpo_e89e4d38   TERMINATED        6.72481       3.23119e-05       0.00108909                    6        1            37.2118      0.955724    0.855072            0.75        0.0686845 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3786814)[0m {'loss': 0.8904, 'grad_norm': 1.859084129333496, 'learning_rate': 7.770525145554766e-06, 'epoch': 2.0}
[36m(train_hpo pid=3786814)[0m {'loss': 0.8246, 'grad_norm': 2.4264628887176514, 'learning_rate': 1.2950875242591277e-06, 'epoch': 3.0}
[36m(train_hpo pid=3786814)[0m {'loss': 0.9157, 'grad_norm': 4.819613456726074, 'learning_rate': 0.0, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3786814)[0m {'train_runtime': 21.7257, 'train_samples_per_second': 62.046, 'train_steps_per_second': 0.736, 'train_loss': 0.9697132110595703, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3786814)[0m STATE at ending of training  :  TrainerState(epoch=3.235294117647059, global_step=16, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=287051584054272.0, log_history=[{'loss': 1.2049, 'grad_norm': 1.6049590110778809, 'learning_rate': 1.4245962766850404e-05, 'epoch': 1.0, 'step': 5}, {'loss': 0.8904, 'grad_norm': 1.859084129333496, 'learning_rate': 7.770525145554766e-06, 'epoch': 2.0, 'step': 10}, {'loss': 0.8246, 'grad_norm': 2.4264628887176514, 'learning_rate': 1.2950875242591277e-06, 'epoch': 3.0, 'step': 15}, {'loss': 0.9157, 'grad_norm': 4.819613456726074, 'learning_rate': 0.0, 'epoch': 3.235294117647059, 'step': 16}, {'train_runtime': 21.7257, 'train_samples_per_second': 62.046, 'train_steps_per_second': 0.736, 'total_flos': 287051584054272.0, 'train_loss': 0.9697132110595703, 'epoch': 3.235294117647059, 'step': 16}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})[36m(train_hpo pid=3786814)[0m 2025-06-16 16:51:17,178 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3786814)[0m 2025-06-16 16:51:17,183 - INFO - eval_result: {'eval_loss': 0.8731147646903992, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.7957147359848022, 'eval_AP': 0.8869220621355873, 'eval_MCC': 0.0, 'eval_NDCG': 0.9739950848554132, 'eval_runtime': 3.5653, 'eval_samples_per_second': 22.438, 'eval_steps_per_second': 1.122, 'epoch': 3.235294117647059}
2025-06-16 16:51:17,437 - INFO - Cleaning up trial 408df180
2025-06-16 16:51:17,437 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_408df180_12_learning_rate=0.0000,num_train_epochs=4,pos_weight=3.5094,weight_decay=0.2637_2025-06-16_16-50-05
2025-06-16 16:51:17,437 - INFO - Cleaning up trial cd0231b6
2025-06-16 16:51:17,438 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_cd0231b6_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-47-29
2025-06-16 16:51:17,438 - INFO - Cleaning up trial b583b0df
2025-06-16 16:51:17,438 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_b583b0df_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-47-35
2025-06-16 16:51:17,438 - INFO - Cleaning up trial 46d963f5
2025-06-16 16:51:17,438 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_46d963f5_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-47-42
2025-06-16 16:51:17,438 - INFO - Cleaning up trial 05fcc281
2025-06-16 16:51:17,438 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_05fcc281_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-47-49
2025-06-16 16:51:17,438 - INFO - Current best: d0584f58 with eval_kappa : 0.13439635535307526 at iteration 1
2025-06-16 16:51:17,438 - INFO - Cleaning up trial d68e6c74
2025-06-16 16:51:17,438 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_d68e6c74_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-48-55
2025-06-16 16:51:17,438 - INFO - Cleaning up trial 1dbe6141
2025-06-16 16:51:17,438 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_1dbe6141_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.5756,weight_decay=0.2202_2025-06-16_16-49-02
2025-06-16 16:51:17,439 - INFO - Cleaning up trial 4572b579
2025-06-16 16:51:17,439 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_4572b579_8_learning_rate=0.0000,num_train_epochs=2,pos_weight=6.4276,weight_decay=0.1851_2025-06-16_16-49-08
2025-06-16 16:51:17,439 - INFO - Cleaning up trial 29d0318b
2025-06-16 16:51:17,439 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_29d0318b_9_learning_rate=0.0000,num_train_epochs=6,pos_weight=7.4401,weight_decay=0.1630_2025-06-16_16-49-41
2025-06-16 16:51:17,439 - INFO - Cleaning up trial 3cc999f6
2025-06-16 16:51:17,439 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_3cc999f6_10_learning_rate=0.0000,num_train_epochs=3,pos_weight=5.9044,weight_decay=0.2866_2025-06-16_16-49-52
2025-06-16 16:51:17,439 - INFO - Cleaning up trial e89e4d38
2025-06-16 16:51:17,439 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29/train_hpo_e89e4d38_11_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.7248,weight_decay=0.0011_2025-06-16_16-49-59
2025-06-16 16:51:17,448	INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-47-29' in 0.0069s.
2025-06-16 16:51:17,463 - INFO - Analysis results: <ray.tune.analysis.experiment_analysis.ExperimentAnalysis object at 0x757b00042e50>
2025-06-16 16:51:17,464 - INFO - Best trial : train_hpo_d0584f58
2025-06-16 16:51:17,464 - INFO - Best config : {'pos_weight': 2.2031009297759248, 'learning_rate': 4.032083917998947e-05, 'weight_decay': 0.24371879650720893, 'num_train_epochs': 5}
2025-06-16 16:51:17,464 - INFO - Best trial after optimization: {'eval_loss': 0.6677157878875732, 'eval_f1': 0.8613138686131386, 'eval_accuracy': 0.7625, 'eval_kappa': 0.13439635535307526, 'eval_precision': 0.7564102564102564, 'eval_recall': 1.0, 'eval_optim_threshold': 0.8470657467842102, 'eval_AP': 0.9151102797131424, 'eval_MCC': 0.26840095387139007, 'eval_NDCG': 0.981157247548447, 'eval_runtime': 3.4697, 'eval_samples_per_second': 23.057, 'eval_steps_per_second': 1.153, 'epoch': 4.0, 'timestamp': 1750085389, 'checkpoint_dir_name': None, 'done': True, 'training_iteration': 1, 'trial_id': 'd0584f58', 'date': '2025-06-16_16-49-49', 'time_this_iter_s': 53.62704396247864, 'time_total_s': 53.62704396247864, 'pid': 3784008, 'hostname': 'lcatogni', 'node_ip': '172.30.120.56', 'config': {'pos_weight': 2.2031009297759248, 'learning_rate': 4.032083917998947e-05, 'weight_decay': 0.24371879650720893, 'num_train_epochs': 5}, 'time_since_restore': 53.62704396247864, 'iterations_since_restore': 1, 'experiment_tag': '5_learning_rate=0.0000,num_train_epochs=5,pos_weight=2.2031,weight_decay=0.2437'}
2025-06-16 16:51:17,484 - INFO - analysis dataframe :    eval_loss   eval_f1  ...  config/num_train_epochs    logdir
0   1.903396  0.855072  ...                        6  cd0231b6
1   1.379423  0.848921  ...                        5  b583b0df
2   1.025975  0.848921  ...                        3  46d963f5
3   2.263086  0.848921  ...                        4  05fcc281
4   0.667716  0.861314  ...                        5  d0584f58

[5 rows x 32 columns]
[36m(train_hpo pid=3786814)[0m 2025-06-16 16:51:17,417 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
2025-06-16 16:51:17,620 - INFO - Trial comparison plot saved
2025-06-16 16:51:17,621 - INFO - Final training...
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-06-16 16:51:18,470 - INFO - Positive weight parameter set to default (in TrainingArguments) -> pos_weight=5.0
/home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
  super().__init__(*args, **kwargs)
2025-06-16 16:51:18,597 - INFO - training size : 337
2025-06-16 16:51:18,598 - INFO - dev size : 80
2025-06-16 16:51:18,598 - INFO - test size : 80
/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:37: UserWarning: 
    There is an imbalance between your GPUs. You may want to exclude GPU 0 which
    has less than 75% of the memory or cores of GPU 2. You can do so by setting
    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES
    environment variable.
  warnings.warn(

[36m(train_hpo pid=3786814)[0m {'eval_loss': 0.8731147646903992, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.7957147359848022, 'eval_AP': 0.8869220621355873, 'eval_MCC': 0.0, 'eval_NDCG': 0.9739950848554132, 'eval_runtime': 3.5653, 'eval_samples_per_second': 22.438, 'eval_steps_per_second': 1.122, 'epoch': 3.235294117647059}

Trial train_hpo_408df180 finished iteration 1 at 2025-06-16 16:51:17. Total running time: 3min 48s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_408df180 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                     26.905 â”‚
â”‚ time_total_s                         26.905 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               3.23529 â”‚
â”‚ eval_AP                             0.88692 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                             0.974 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           0.87311 â”‚
â”‚ eval_optim_threshold                0.79571 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.5653 â”‚
â”‚ eval_samples_per_second              22.438 â”‚
â”‚ eval_steps_per_second                 1.122 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_408df180 completed after 1 iterations at 2025-06-16 16:51:17. Total running time: 3min 48s

Trial status: 12 TERMINATED
Current time: 2025-06-16 16:51:17. Total running time: 3min 48s
Logical resource usage: 10.0/32 CPUs, 1.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_cd0231b6   TERMINATED        6.82842       1.49561e-06       0.13641                       6        1            72.4779      1.9034      0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_b583b0df   TERMINATED        6.09408       4.55539e-06       0.123031                      5        1            66.1525      1.37942     0.848921            0.7375      0         â”‚
â”‚ train_hpo_46d963f5   TERMINATED        7.18321       7.98818e-05       0.251217                      3        1            21.1124      1.02597     0.848921            0.7375      0         â”‚
â”‚ train_hpo_05fcc281   TERMINATED        7.43106       1.10121e-06       0.13345                       4        1            31.1934      2.26309     0.848921            0.7375      0         â”‚
â”‚ train_hpo_d0584f58   TERMINATED        2.2031        4.03208e-05       0.243719                      5        1            53.627       0.667716    0.861314            0.7625      0.134396  â”‚
â”‚ train_hpo_d68e6c74   TERMINATED        4.0662        2.70039e-05       0.239866                      3        1            43.6421      0.96982     0.848921            0.7375      0         â”‚
â”‚ train_hpo_1dbe6141   TERMINATED        7.57559       4.00602e-05       0.220208                      4        1            26.1998      1.00497     0.848921            0.7375      0         â”‚
â”‚ train_hpo_4572b579   TERMINATED        6.42755       2.7847e-06        0.185124                      2        1            16.3266      2.79083     0.848921            0.7375      0         â”‚
â”‚ train_hpo_29d0318b   TERMINATED        7.44006       4.73492e-05       0.163021                      6        1            59.7755      0.935199    0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_3cc999f6   TERMINATED        5.90435       6.78644e-06       0.286643                      3        1            43.7224      1.35345     0.848921            0.7375      0         â”‚
â”‚ train_hpo_e89e4d38   TERMINATED        6.72481       3.23119e-05       0.00108909                    6        1            37.2118      0.955724    0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_408df180   TERMINATED        3.50937       2.07214e-05       0.263741                      4        1            26.905       0.873115    0.848921            0.7375      0         â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

  0%|          | 0/75 [00:00<?, ?it/s]  1%|â–         | 1/75 [00:00<00:48,  1.52it/s]  3%|â–Ž         | 2/75 [00:01<00:46,  1.57it/s]  4%|â–         | 3/75 [00:01<00:45,  1.59it/s]  5%|â–Œ         | 4/75 [00:02<00:44,  1.60it/s]  7%|â–‹         | 5/75 [00:03<00:43,  1.61it/s]  8%|â–Š         | 6/75 [00:03<00:42,  1.61it/s]  9%|â–‰         | 7/75 [00:04<00:42,  1.62it/s] 11%|â–ˆ         | 8/75 [00:04<00:41,  1.62it/s] 12%|â–ˆâ–        | 9/75 [00:05<00:40,  1.62it/s] 13%|â–ˆâ–Ž        | 10/75 [00:06<00:40,  1.62it/s] 15%|â–ˆâ–        | 11/75 [00:06<00:39,  1.62it/s] 16%|â–ˆâ–Œ        | 12/75 [00:07<00:38,  1.62it/s] 17%|â–ˆâ–‹        | 13/75 [00:08<00:38,  1.62it/s] 19%|â–ˆâ–Š        | 14/75 [00:08<00:37,  1.64it/s]                                                20%|â–ˆâ–ˆ        | 15/75 [00:08<00:36,  1.64it/s] 21%|â–ˆâ–ˆâ–       | 16/75 [00:09<00:28,  2.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 17/75 [00:09<00:30,  1.92it/s] 24%|â–ˆâ–ˆâ–       | 18/75 [00:10<00:31,  1.83it/s] 25%|â–ˆâ–ˆâ–Œ       | 19/75 [00:11<00:31,  1.77it/s] 27%|â–ˆâ–ˆâ–‹       | 20/75 [00:11<00:31,  1.73it/s] 28%|â–ˆâ–ˆâ–Š       | 21/75 [00:12<00:31,  1.69it/s] 29%|â–ˆâ–ˆâ–‰       | 22/75 [00:13<00:31,  1.67it/s] 31%|â–ˆâ–ˆâ–ˆ       | 23/75 [00:13<00:31,  1.65it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 24/75 [00:14<00:31,  1.64it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25/75 [00:14<00:30,  1.64it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 26/75 [00:15<00:29,  1.63it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27/75 [00:16<00:29,  1.63it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 28/75 [00:16<00:28,  1.63it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 29/75 [00:17<00:28,  1.64it/s]                                                40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30/75 [00:17<00:27,  1.64it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/75 [00:18<00:21,  2.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32/75 [00:18<00:22,  1.92it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/75 [00:19<00:22,  1.83it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34/75 [00:19<00:23,  1.77it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35/75 [00:20<00:23,  1.73it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36/75 [00:21<00:22,  1.70it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37/75 [00:21<00:22,  1.68it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38/75 [00:22<00:22,  1.66it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/75 [00:22<00:21,  1.65it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40/75 [00:23<00:21,  1.64it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/75 [00:24<00:20,  1.64it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42/75 [00:24<00:20,  1.63it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43/75 [00:25<00:19,  1.63it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44/75 [00:26<00:18,  1.65it/s]                                                60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45/75 [00:26<00:18,  1.65it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46/75 [00:26<00:14,  2.06it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47/75 [00:27<00:14,  1.93it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48/75 [00:27<00:14,  1.84it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49/75 [00:28<00:14,  1.77it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50/75 [00:29<00:14,  1.73it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51/75 [00:29<00:14,  1.70it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52/75 [00:30<00:13,  1.68it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53/75 [00:31<00:13,  1.66it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54/75 [00:31<00:12,  1.65it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55/75 [00:32<00:12,  1.64it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56/75 [00:32<00:11,  1.64it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57/75 [00:33<00:11,  1.63it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58/75 [00:34<00:10,  1.63it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59/75 [00:34<00:09,  1.64it/s]                                                80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60/75 [00:34<00:09,  1.64it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61/75 [00:35<00:06,  2.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62/75 [00:36<00:06,  1.93it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63/75 [00:36<00:06,  1.84it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64/75 [00:37<00:06,  1.77it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65/75 [00:37<00:05,  1.73it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66/75 [00:38<00:05,  1.70it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67/75 [00:39<00:04,  1.68it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68/75 [00:39<00:04,  1.66it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69/75 [00:40<00:03,  1.65it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70/75 [00:40<00:03,  1.62it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71/75 [00:41<00:02,  1.62it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72/75 [00:42<00:01,  1.62it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73/75 [00:42<00:01,  1.63it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74/75 [00:43<00:00,  1.64it/s]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:45<00:00,  1.64it/s]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:45<00:00,  1.64it/s]2025-06-16 16:52:04,659 - INFO - Early stopping triggered, but no best model checkpoint was saved.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:45<00:00,  1.64it/s]
/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:37: UserWarning: 
    There is an imbalance between your GPUs. You may want to exclude GPU 0 which
    has less than 75% of the memory or cores of GPU 2. You can do so by setting
    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES
    environment variable.
  warnings.warn(
{'loss': 0.9637, 'grad_norm': 15.998678207397461, 'learning_rate': 3.225667134399158e-05, 'epoch': 1.0}
{'loss': 0.6589, 'grad_norm': 8.611783027648926, 'learning_rate': 2.419250350799368e-05, 'epoch': 2.0}
{'loss': 0.4396, 'grad_norm': 7.88112211227417, 'learning_rate': 1.612833567199579e-05, 'epoch': 3.0}
{'loss': 0.2509, 'grad_norm': 6.912971019744873, 'learning_rate': 8.064167835997895e-06, 'epoch': 4.0}
{'loss': 0.155, 'grad_norm': 2.2031285762786865, 'learning_rate': 0.0, 'epoch': 5.0}
{'train_runtime': 45.6352, 'train_samples_per_second': 36.923, 'train_steps_per_second': 1.643, 'train_loss': 0.4936056995391846, 'epoch': 5.0}
  0%|          | 0/4 [00:00<?, ?it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.17it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.24it/s]2025-06-16 16:52:08,677 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.07it/s]
2025-06-16 16:52:08,683 - INFO - Training time : 51.06223640590906
/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:37: UserWarning: 
    There is an imbalance between your GPUs. You may want to exclude GPU 0 which
    has less than 75% of the memory or cores of GPU 2. You can do so by setting
    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES
    environment variable.
  warnings.warn(
  0%|          | 0/4 [00:00<?, ?it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.17it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.22it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.26it/s]2025-06-16 16:52:12,528 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.13it/s]
2025-06-16 16:52:12,532 - INFO - Evaluation time : 3.8490042680641636
2025-06-16 16:52:12,532 - INFO - Evaluation results on test set: {'eval_loss': 0.7530160546302795, 'eval_f1': 0.8833333333333333, 'eval_accuracy': 0.825, 'eval_kappa': 0.533721898417985, 'eval_precision': 0.8688524590163934, 'eval_recall': 0.8983050847457628, 'eval_optim_threshold': 0.9390515089035034, 'eval_AP': 0.9154119520665256, 'eval_MCC': 0.534909927772559, 'eval_NDCG': 0.979839601954689, 'eval_runtime': 3.8451, 'eval_samples_per_second': 20.806, 'eval_steps_per_second': 1.04, 'epoch': 5.0}
2025-06-16 16:52:12,532 - INFO - Total updates (optimizer steps): 75
2025-06-16 16:52:12,532 - INFO - Avg time / step: 0.609s
2025-06-16 16:52:13,544 - INFO - Best model saved to /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/final_model/best_model_cross_val_BCEmicrosoft/BiomedNLP-BiomedBERT-base-uncased-abstract12trials_fold-2
2025-06-16 16:52:13,544 - INFO - On test Set (with threshold 0.5) : 
/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:37: UserWarning: 
    There is an imbalance between your GPUs. You may want to exclude GPU 0 which
    has less than 75% of the memory or cores of GPU 2. You can do so by setting
    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES
    environment variable.
  warnings.warn(
  0%|          | 0/4 [00:00<?, ?it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.23it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.24it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.28it/s]2025-06-16 16:52:17,304 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.16it/s]
2025-06-16 16:52:17,308 - INFO - Raw predictions shape: (80, 1)
2025-06-16 16:52:17,308 - INFO - Raw predictions: [[ 2.8676898]
 [ 3.4457376]
 [ 3.5221863]
 [ 2.9224813]
 [ 2.7644393]
 [ 2.3579903]
 [ 3.746116 ]
 [ 3.2692335]
 [ 3.6488912]
 [-2.339773 ]]
2025-06-16 16:52:17,308 - INFO - Scores shape: (80,)
2025-06-16 16:52:17,308 - INFO - Scores: [0.94622594 0.9691038  0.97131246 0.94894665 0.94072366 0.9135672
 0.97693527 0.96335804 0.97463995 0.08788212]
2025-06-16 16:52:17,308 - INFO - Preds shape: (80,)
2025-06-16 16:52:17,308 - INFO - Preds: [1 1 1 1 1 1 1 1 1 0]
2025-06-16 16:52:17,309 - INFO - Test labels shape: (80,)
2025-06-16 16:52:17,310 - INFO - Test labels: [1, 1, 1, 1, 1, 1, 1, 0, 1, 0]
2025-06-16 16:52:17,310 - INFO - Test split: Dataset({
    features: ['title', 'abstract', 'Keywords', 'doi', 'labels'],
    num_rows: 80
})
2025-06-16 16:52:17,310 - INFO - Unique values in predictions: [0 1]
2025-06-16 16:52:17,310 - INFO - Unique values in labels: [0 1]
2025-06-16 16:52:17,312 - INFO - Confusion matrix:
[[13  8]
 [ 6 53]]
2025-06-16 16:52:17,313 - INFO - Confusion matrix: TN=13, FP=8, FN=6, TP=53
2025-06-16 16:52:20,095 - INFO - Metrics: {'f1': 0.8833333333333333, 'recall': 0.8983050847457628, 'precision': 0.8688524590163934, 'accuracy': 0.825, 'AP': 0.9154119520665256, 'MCC': 0.534909927772559, 'NDCG': 0.979839601954689, 'kappa': 0.533721898417985, 'TN': 13, 'FP': 8, 'FN': 6, 'TP': 53}
2025-06-16 16:52:20,099 - INFO - Metrics stored successfully at /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/metrics/binary_metrics.csv
2025-06-16 16:52:20,213 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_test.png
2025-06-16 16:52:20,309 - INFO - Precision-Recall curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/precision_recall_curvetest.png
2025-06-16 16:52:20,309 - INFO - 
On test Set (optimal threshold of 0.9492660164833069 according to cross validation on the training set): 
2025-06-16 16:52:20,311 - INFO - Confusion matrix: TN=17, FP=4, FN=23, TP=36
2025-06-16 16:52:23,113 - INFO - Metrics: {'f1': 0.7272727272727273, 'recall': 0.6101694915254238, 'precision': 0.9, 'accuracy': 0.6625, 'AP': 0.9154119520665256, 'MCC': 0.36932414332263847, 'NDCG': 0.979839601954689, 'kappa': 0.32499999999999996, 'TN': 17, 'FP': 4, 'FN': 23, 'TP': 36}
2025-06-16 16:52:23,209 - INFO - Precision-Recall curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/precision_recall_curvetest.png
2025-06-16 16:52:23,209 - INFO - Results for fold 2 : [{'f1': 0.7272727272727273, 'recall': 0.6101694915254238, 'precision': 0.9, 'accuracy': 0.6625, 'AP': 0.9154119520665256, 'MCC': 0.36932414332263847, 'NDCG': 0.979839601954689, 'kappa': 0.32499999999999996, 'TN': 17, 'FP': 4, 'FN': 23, 'TP': 36}]
2025-06-16 16:52:23,597 - INFO - Cleared CUDA cache. Memory allocated: 1.38 GB, Memory reserved: 1.57 GB
2025-06-16 16:52:23,831 - INFO - Cleared CUDA cache. Memory allocated: 1.38 GB, Memory reserved: 1.57 GB
2025-06-16 16:52:23,832 - INFO - 
fold number 3 / 5
2025-06-16 16:52:23,837 - INFO - train split size : 338
2025-06-16 16:52:23,837 - INFO - dev split size : 80
2025-06-16 16:52:23,837 - INFO - test split size : 79
Map (num_proc=32):   0%|          | 0/338 [00:00<?, ? examples/s]Map (num_proc=32):   3%|â–Ž         | 11/338 [00:00<00:07, 40.99 examples/s]Map (num_proc=32):  20%|â–ˆâ–‰        | 66/338 [00:00<00:01, 214.61 examples/s]Map (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 143/338 [00:00<00:00, 369.98 examples/s]Map (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 197/338 [00:00<00:00, 416.91 examples/s]Map (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 258/338 [00:00<00:00, 463.04 examples/s]Map (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 328/338 [00:00<00:00, 502.43 examples/s]Map (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:00<00:00, 339.56 examples/s]
Map (num_proc=32):   0%|          | 0/80 [00:00<?, ? examples/s]Map (num_proc=32):   4%|â–         | 3/80 [00:00<00:06, 12.50 examples/s]Map (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 21/80 [00:00<00:00, 72.97 examples/s]Map (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/80 [00:00<00:00, 97.76 examples/s]Map (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/80 [00:00<00:00, 115.23 examples/s]Map (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 66/80 [00:00<00:00, 111.60 examples/s]Map (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<00:00, 107.98 examples/s]Map (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<00:00, 82.59 examples/s] 
Map (num_proc=32):   0%|          | 0/79 [00:00<?, ? examples/s]Map (num_proc=32):   4%|â–         | 3/79 [00:00<00:06, 12.26 examples/s]Map (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 24/79 [00:00<00:00, 80.61 examples/s]Map (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 42/79 [00:00<00:00, 105.06 examples/s]Map (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/79 [00:00<00:00, 106.21 examples/s]Map (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/79 [00:00<00:00, 106.36 examples/s]Map (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:00<00:00, 106.43 examples/s]Map (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:00<00:00, 81.61 examples/s] 
2025-06-16 16:52:32,857 - INFO - 3 datasets tokenized successfully
2025-06-16 16:52:32,926 - INFO - Fold 3 max seq len = 512
2025-06-16 16:52:32,926 - INFO - Starting hyperparameter search for BCE loss
[36m(train_hpo pid=3789637)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3789637)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3789637)[0m 2025-06-16 16:52:40,155 - INFO - pos_weight value in TrainingArguments : 6.828424226204718
[36m(train_hpo pid=3789637)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3789637)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3789817)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3789817)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3789817)[0m 2025-06-16 16:52:46,392 - INFO - pos_weight value in TrainingArguments : 6.094080202241274
[36m(train_hpo pid=3789817)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3789817)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3790017)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3790017)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3790017)[0m 2025-06-16 16:52:52,537 - INFO - pos_weight value in TrainingArguments : 7.183206941666034
[36m(train_hpo pid=3790017)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3790017)[0m   super().__init__(*args, **kwargs)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Configuration for experiment     train_hpo_2025-06-16_16-52-32   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Search algorithm                 SearchGenerator                 â”‚
â”‚ Scheduler                        AsyncHyperBandScheduler         â”‚
â”‚ Number of trials                 12                              â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

View detailed results here: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32
To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-06-16_16-42-25_595113_3771642/artifacts/2025-06-16_16-52-32/train_hpo_2025-06-16_16-52-32/driver_artifacts`

Trial status: 1 PENDING
Current time: 2025-06-16 16:52:33. Total running time: 0s
Logical resource usage: 10.0/32 CPUs, 1.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status       pos_weight     learning_rate     weight_decay     num_train_epochs â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_e788a5b6   PENDING         6.82842       1.49561e-06          0.13641                    6 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_e788a5b6 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_e788a5b6 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                             0 â”‚
â”‚ num_train_epochs                          6 â”‚
â”‚ pos_weight                          6.82842 â”‚
â”‚ weight_decay                        0.13641 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3789637)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})

Trial train_hpo_a9d98af1 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_a9d98af1 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                             0 â”‚
â”‚ num_train_epochs                          5 â”‚
â”‚ pos_weight                          6.09408 â”‚
â”‚ weight_decay                        0.12303 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3789817)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=20, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=5, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3789637)[0m {'loss': 2.1117, 'grad_norm': 9.324933052062988, 'learning_rate': 1.1840219327085947e-06, 'epoch': 1.0}

Trial train_hpo_dbd08dac started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_dbd08dac config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         8e-05 â”‚
â”‚ num_train_epochs                          3 â”‚
â”‚ pos_weight                          7.18321 â”‚
â”‚ weight_decay                        0.25122 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3790017)[0m STATE at beggining of training :  
[36m(train_hpo pid=3790017)[0m TrainerState(epoch=0, global_step=0, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3790017)[0m {'loss': 1.464, 'grad_norm': 1.8270070552825928, 'learning_rate': 4.6597713532890536e-05, 'epoch': 1.0}

Trial status: 3 RUNNING | 1 PENDING
Current time: 2025-06-16 16:53:03. Total running time: 30s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status       pos_weight     learning_rate     weight_decay     num_train_epochs â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_e788a5b6   RUNNING         6.82842       1.49561e-06         0.13641                     6 â”‚
â”‚ train_hpo_a9d98af1   RUNNING         6.09408       4.55539e-06         0.123031                    5 â”‚
â”‚ train_hpo_dbd08dac   RUNNING         7.18321       7.98818e-05         0.251217                    3 â”‚
â”‚ train_hpo_812f70ad   PENDING         7.43106       1.10121e-06         0.13345                     4 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[36m(train_hpo pid=3790017)[0m 2025-06-16 16:53:12,632 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3790017)[0m 2025-06-16 16:53:12,637 - INFO - eval_result: {'eval_loss': 1.025914192199707, 'eval_f1': 0.855072463768116, 'eval_accuracy': 0.75, 'eval_kappa': 0.06868451688009314, 'eval_precision': 0.7468354430379747, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9517176747322083, 'eval_AP': 0.8828159108095337, 'eval_MCC': 0.18858311834736916, 'eval_NDCG': 0.9743753267657047, 'eval_runtime': 3.3425, 'eval_samples_per_second': 23.934, 'eval_steps_per_second': 1.197, 'epoch': 2.4705882352941178}
2025-06-16 16:53:12,891 - INFO - Cleaning up trial dbd08dac
2025-06-16 16:53:12,891 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_dbd08dac_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-52-45
[36m(train_hpo pid=3790017)[0m 2025-06-16 16:53:12,867 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
[36m(train_hpo pid=3790582)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3790582)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3790582)[0m 2025-06-16 16:53:20,869 - INFO - pos_weight value in TrainingArguments : 7.431057651685638
[36m(train_hpo pid=3790582)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3790582)[0m   super().__init__(*args, **kwargs)

[36m(train_hpo pid=3790017)[0m {'loss': 0.945, 'grad_norm': 1.8416889905929565, 'learning_rate': 1.3313632437968722e-05, 'epoch': 2.0}[32m [repeated 3x across cluster][0m
[36m(train_hpo pid=3790017)[0m {'train_runtime': 16.2812, 'train_samples_per_second': 62.28, 'train_steps_per_second': 0.737, 'train_loss': 1.1420152485370636, 'epoch': 2.4705882352941178}
[36m(train_hpo pid=3790017)[0m STATE at ending of training  :  TrainerState(epoch=2.4705882352941178, global_step=12, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=219958867341312.0, log_history=[{'loss': 1.464, 'grad_norm': 1.8270070552825928, 'learning_rate': 4.6597713532890536e-05, 'epoch': 1.0, 'step': 5}, {'loss': 0.945, 'grad_norm': 1.8416889905929565, 'learning_rate': 1.3313632437968722e-05, 'epoch': 2.0, 'step': 10}, {'loss': 0.8295, 'grad_norm': 5.218350887298584, 'learning_rate': 0.0, 'epoch': 2.4705882352941178, 'step': 12}, {'train_runtime': 16.2812, 'train_samples_per_second': 62.28, 'train_steps_per_second': 0.737, 'total_flos': 219958867341312.0, 'train_loss': 1.1420152485370636, 'epoch': 2.4705882352941178, 'step': 12}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3790017)[0m {'eval_loss': 1.025914192199707, 'eval_f1': 0.855072463768116, 'eval_accuracy': 0.75, 'eval_kappa': 0.06868451688009314, 'eval_precision': 0.7468354430379747, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9517176747322083, 'eval_AP': 0.8828159108095337, 'eval_MCC': 0.18858311834736916, 'eval_NDCG': 0.9743753267657047, 'eval_runtime': 3.3425, 'eval_samples_per_second': 23.934, 'eval_steps_per_second': 1.197, 'epoch': 2.4705882352941178}
[36m(train_hpo pid=3790017)[0m {'loss': 0.8295, 'grad_norm': 5.218350887298584, 'learning_rate': 0.0, 'epoch': 2.4705882352941178}

Trial train_hpo_dbd08dac finished iteration 1 at 2025-06-16 16:53:12. Total running time: 39s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_dbd08dac result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    21.1754 â”‚
â”‚ time_total_s                        21.1754 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               2.47059 â”‚
â”‚ eval_AP                             0.88282 â”‚
â”‚ eval_MCC                            0.18858 â”‚
â”‚ eval_NDCG                           0.97438 â”‚
â”‚ eval_accuracy                          0.75 â”‚
â”‚ eval_f1                             0.85507 â”‚
â”‚ eval_kappa                          0.06868 â”‚
â”‚ eval_loss                           1.02591 â”‚
â”‚ eval_optim_threshold                0.95172 â”‚
â”‚ eval_precision                      0.74684 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.3425 â”‚
â”‚ eval_samples_per_second              23.934 â”‚
â”‚ eval_steps_per_second                 1.197 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_dbd08dac completed after 1 iterations at 2025-06-16 16:53:12. Total running time: 39s
[36m(train_hpo pid=3789637)[0m {'loss': 1.7427, 'grad_norm': 7.407549858093262, 'learning_rate': 5.608524944409133e-07, 'epoch': 3.0}

Trial train_hpo_812f70ad started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_812f70ad config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                             0 â”‚
â”‚ num_train_epochs                          4 â”‚
â”‚ pos_weight                          7.43106 â”‚
â”‚ weight_decay                        0.13345 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3790582)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3790582)[0m {'loss': 2.1938, 'grad_norm': 9.030064582824707, 'learning_rate': 7.570838612609137e-07, 'epoch': 1.0}[32m [repeated 2x across cluster][0m

Trial status: 3 RUNNING | 1 TERMINATED | 1 PENDING
Current time: 2025-06-16 16:53:33. Total running time: 1min 0s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_e788a5b6   RUNNING           6.82842       1.49561e-06         0.13641                     6                                                                                        â”‚
â”‚ train_hpo_a9d98af1   RUNNING           6.09408       4.55539e-06         0.123031                    5                                                                                        â”‚
â”‚ train_hpo_812f70ad   RUNNING           7.43106       1.10121e-06         0.13345                     4                                                                                        â”‚
â”‚ train_hpo_dbd08dac   TERMINATED        7.18321       7.98818e-05         0.251217                    3        1            21.1754       1.02591    0.855072              0.75      0.0686845 â”‚
â”‚ train_hpo_147ca679   PENDING           2.2031        4.03208e-05         0.243719                    5                                                                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[36m(train_hpo pid=3790582)[0m 2025-06-16 16:53:46,133 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3790582)[0m 2025-06-16 16:53:46,139 - INFO - eval_result: {'eval_loss': 2.8392796516418457, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.6050437092781067, 'eval_AP': 0.7135914357755992, 'eval_MCC': 0.0, 'eval_NDCG': 0.861800955843417, 'eval_runtime': 3.3948, 'eval_samples_per_second': 23.566, 'eval_steps_per_second': 1.178, 'epoch': 3.235294117647059}
2025-06-16 16:53:46,398 - INFO - Cleaning up trial 812f70ad
2025-06-16 16:53:46,398 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_812f70ad_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-52-51
2025-06-16 16:53:46,398 - INFO - Current best: dbd08dac with eval_kappa : 0.06868451688009314 at iteration 1
[36m(train_hpo pid=3790582)[0m 2025-06-16 16:53:46,376 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
[36m(train_hpo pid=3789637)[0m 2025-06-16 16:53:51,913 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3789637)[0m 2025-06-16 16:53:51,919 - INFO - eval_result: {'eval_loss': 2.3107571601867676, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.6670791506767273, 'eval_AP': 0.7801633358101902, 'eval_MCC': 0.0, 'eval_NDCG': 0.9279386975223902, 'eval_runtime': 4.4089, 'eval_samples_per_second': 18.145, 'eval_steps_per_second': 0.907, 'epoch': 4.9411764705882355}

[36m(train_hpo pid=3789637)[0m {'loss': 1.6032, 'grad_norm': 10.19544792175293, 'learning_rate': 2.4926777530707256e-07, 'epoch': 4.0}
[36m(train_hpo pid=3789817)[0m {'loss': 1.3319, 'grad_norm': 3.6133759021759033, 'learning_rate': 1.1388478827151493e-06, 'epoch': 3.0}
[36m(train_hpo pid=3790582)[0m {'loss': 1.9586, 'grad_norm': 7.72540807723999, 'learning_rate': 6.882580556917397e-08, 'epoch': 3.0}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3790582)[0m {'train_runtime': 21.3757, 'train_samples_per_second': 63.249, 'train_steps_per_second': 0.749, 'train_loss': 2.0841261595487595, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3790582)[0m STATE at ending of training  :  TrainerState(epoch=3.235294117647059, global_step=16, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=287840910133248.0, log_history=[{'loss': 2.1938, 'grad_norm': 9.030064582824707, 'learning_rate': 7.570838612609137e-07, 'epoch': 1.0, 'step': 5}, {'loss': 2.0519, 'grad_norm': 10.12192440032959, 'learning_rate': 4.129548334150438e-07, 'epoch': 2.0, 'step': 10}, {'loss': 1.9586, 'grad_norm': 7.72540807723999, 'learning_rate': 6.882580556917397e-08, 'epoch': 3.0, 'step': 15}, {'loss': 2.3246, 'grad_norm': 36.252098083496094, 'learning_rate': 0.0, 'epoch': 3.235294117647059, 'step': 16}, {'train_runtime': 21.3757, 'train_samples_per_second': 63.249, 'train_steps_per_second': 0.749, 'total_flos': 287840910133248.0, 'train_loss': 2.0841261595487595, 'epoch': 3.235294117647059, 'step': 16}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3790582)[0m {'eval_loss': 2.8392796516418457, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.6050437092781067, 'eval_AP': 0.7135914357755992, 'eval_MCC': 0.0, 'eval_NDCG': 0.861800955843417, 'eval_runtime': 3.3948, 'eval_samples_per_second': 23.566, 'eval_steps_per_second': 1.178, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3790582)[0m {'loss': 2.3246, 'grad_norm': 36.252098083496094, 'learning_rate': 0.0, 'epoch': 3.235294117647059}

Trial train_hpo_812f70ad finished iteration 1 at 2025-06-16 16:53:46. Total running time: 1min 13s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_812f70ad result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    26.4054 â”‚
â”‚ time_total_s                        26.4054 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               3.23529 â”‚
â”‚ eval_AP                             0.71359 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                            0.8618 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           2.83928 â”‚
â”‚ eval_optim_threshold                0.60504 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.3948 â”‚
â”‚ eval_samples_per_second              23.566 â”‚
â”‚ eval_steps_per_second                 1.178 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_812f70ad completed after 1 iterations at 2025-06-16 16:53:46. Total running time: 1min 13s
[36m(train_hpo pid=3789637)[0m {'loss': 1.858, 'grad_norm': 31.226144790649414, 'learning_rate': 0.0, 'epoch': 4.9411764705882355}
[36m(train_hpo pid=3789637)[0m STATE at ending of training  :  TrainerState(epoch=4.9411764705882355, global_step=24, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=439917734682624.0, log_history=[{'loss': 2.1117, 'grad_norm': 9.324933052062988, 'learning_rate': 1.1840219327085947e-06, 'epoch': 1.0, 'step': 5}, {'loss': 1.8638, 'grad_norm': 11.332945823669434, 'learning_rate': 8.724372135747541e-07, 'epoch': 2.0, 'step': 10}, {'loss': 1.7427, 'grad_norm': 7.407549858093262, 'learning_rate': 5.608524944409133e-07, 'epoch': 3.0, 'step': 15}, {'loss': 1.6032, 'grad_norm': 10.19544792175293, 'learning_rate': 2.4926777530707256e-07, 'epoch': 4.0, 'step': 20}, {'loss': 1.858, 'grad_norm': 31.226144790649414, 'learning_rate': 0.0, 'epoch': 4.9411764705882355, 'step': 24}, {'train_runtime': 66.8575, 'train_samples_per_second': 30.333, 'train_steps_per_second': 0.359, 'total_flos': 439917734682624.0, 'train_loss': 1.834964632987976, 'epoch': 4.9411764705882355, 'step': 24}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3789817)[0m {'train_runtime': 61.3599, 'train_samples_per_second': 27.542, 'train_steps_per_second': 0.326, 'train_loss': 1.5938798666000367, 'epoch': 4.0}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3789817)[0m STATE at ending of training  :  TrainerState(epoch=4.0, global_step=20, max_steps=20, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=5, num_input_tokens_seen=0, total_flos=355722952925184.0, log_history=[{'loss': 2.2201, 'grad_norm': 8.15715217590332, 'learning_rate': 3.416543648145448e-06, 'epoch': 1.0, 'step': 5}, {'loss': 1.5766, 'grad_norm': 7.432426452636719, 'learning_rate': 2.2776957654302987e-06, 'epoch': 2.0, 'step': 10}, {'loss': 1.3319, 'grad_norm': 3.6133759021759033, 'learning_rate': 1.1388478827151493e-06, 'epoch': 3.0, 'step': 15}, {'loss': 1.2469, 'grad_norm': 3.975543260574341, 'learning_rate': 0.0, 'epoch': 4.0, 'step': 20}, {'train_runtime': 61.3599, 'train_samples_per_second': 27.542, 'train_steps_per_second': 0.326, 'total_flos': 355722952925184.0, 'train_loss': 1.5938798666000367, 'epoch': 4.0, 'step': 20}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3789637)[0m {'eval_loss': 2.3107571601867676, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.6670791506767273, 'eval_AP': 0.7801633358101902, 'eval_MCC': 0.0, 'eval_NDCG': 0.9279386975223902, 'eval_runtime': 4.4089, 'eval_samples_per_second': 18.145, 'eval_steps_per_second': 0.907, 'epoch': 4.9411764705882355}

Trial train_hpo_e788a5b6 finished iteration 1 at 2025-06-16 16:53:52. Total running time: 1min 19s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_e788a5b6 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    72.9518 â”‚
â”‚ time_total_s                        72.9518 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               4.94118 â”‚
â”‚ eval_AP                             0.78016 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.92794 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           2.31076 â”‚
â”‚ eval_optim_threshold                0.66708 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         4.4089 â”‚
â”‚ eval_samples_per_second              18.145 â”‚
â”‚ eval_steps_per_second                 0.907 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯2025-06-16 16:53:52,186 - INFO - Cleaning up trial e788a5b6
2025-06-16 16:53:52,187 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_e788a5b6_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-52-33
2025-06-16 16:53:52,187 - INFO - Current best: dbd08dac with eval_kappa : 0.06868451688009314 at iteration 1
2025-06-16 16:53:52,187 - INFO - Cleaning up trial 812f70ad
2025-06-16 16:53:52,187 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_812f70ad_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-52-51
[36m(train_hpo pid=3789637)[0m 2025-06-16 16:53:52,166 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
[36m(train_hpo pid=3789817)[0m 2025-06-16 16:53:52,291 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3789817)[0m 2025-06-16 16:53:52,297 - INFO - eval_result: {'eval_loss': 1.4538443088531494, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.8044859170913696, 'eval_AP': 0.7832467346432088, 'eval_MCC': 0.0, 'eval_NDCG': 0.9379344958838824, 'eval_runtime': 3.7709, 'eval_samples_per_second': 21.215, 'eval_steps_per_second': 1.061, 'epoch': 4.0}
2025-06-16 16:53:52,559 - INFO - Cleaning up trial a9d98af1
2025-06-16 16:53:52,559 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_a9d98af1_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-52-39
2025-06-16 16:53:52,560 - INFO - Cleaning up trial e788a5b6
2025-06-16 16:53:52,560 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_e788a5b6_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-52-33
2025-06-16 16:53:52,560 - INFO - Current best: dbd08dac with eval_kappa : 0.06868451688009314 at iteration 1
2025-06-16 16:53:52,560 - INFO - Cleaning up trial 812f70ad
2025-06-16 16:53:52,560 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_812f70ad_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-52-51
[36m(train_hpo pid=3791302)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3791302)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3791302)[0m 2025-06-16 16:53:53,985 - INFO - pos_weight value in TrainingArguments : 2.2031009297759248
[36m(train_hpo pid=3791302)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3791302)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3789817)[0m 2025-06-16 16:53:52,539 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
[36m(train_hpo pid=3791510)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3791510)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3791510)[0m 2025-06-16 16:54:00,249 - INFO - pos_weight value in TrainingArguments : 4.066204305086463
[36m(train_hpo pid=3791510)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3791510)[0m   super().__init__(*args, **kwargs)


Trial train_hpo_e788a5b6 completed after 1 iterations at 2025-06-16 16:53:52. Total running time: 1min 19s
[36m(train_hpo pid=3789817)[0m {'eval_loss': 1.4538443088531494, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.8044859170913696, 'eval_AP': 0.7832467346432088, 'eval_MCC': 0.0, 'eval_NDCG': 0.9379344958838824, 'eval_runtime': 3.7709, 'eval_samples_per_second': 21.215, 'eval_steps_per_second': 1.061, 'epoch': 4.0}

Trial train_hpo_a9d98af1 finished iteration 1 at 2025-06-16 16:53:52. Total running time: 1min 19s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_a9d98af1 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    67.0307 â”‚
â”‚ time_total_s                        67.0307 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                                     4 â”‚
â”‚ eval_AP                             0.78325 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.93793 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           1.45384 â”‚
â”‚ eval_optim_threshold                0.80449 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.7709 â”‚
â”‚ eval_samples_per_second              21.215 â”‚
â”‚ eval_steps_per_second                 1.061 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_a9d98af1 completed after 1 iterations at 2025-06-16 16:53:52. Total running time: 1min 19s

Trial train_hpo_147ca679 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_147ca679 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         4e-05 â”‚
â”‚ num_train_epochs                          5 â”‚
â”‚ pos_weight                           2.2031 â”‚
â”‚ weight_decay                        0.24372 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3791302)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=20, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=5, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3789817)[0m {'loss': 1.2469, 'grad_norm': 3.975543260574341, 'learning_rate': 0.0, 'epoch': 4.0}

Trial train_hpo_c7eef995 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_c7eef995 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         3e-05 â”‚
â”‚ num_train_epochs                          3 â”‚
â”‚ pos_weight                           4.0662 â”‚
â”‚ weight_decay                        0.23987 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3791510)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3791302)[0m {'loss': 0.8522, 'grad_norm': 1.6591923236846924, 'learning_rate': 3.0240629384992103e-05, 'epoch': 1.0}

Trial status: 4 TERMINATED | 2 RUNNING | 1 PENDING
Current time: 2025-06-16 16:54:03. Total running time: 1min 30s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_147ca679   RUNNING           2.2031        4.03208e-05         0.243719                    5                                                                                        â”‚
â”‚ train_hpo_c7eef995   RUNNING           4.0662        2.70039e-05         0.239866                    3                                                                                        â”‚
â”‚ train_hpo_e788a5b6   TERMINATED        6.82842       1.49561e-06         0.13641                     6        1            72.9518       2.31076    0.848921            0.7375      0         â”‚
â”‚ train_hpo_a9d98af1   TERMINATED        6.09408       4.55539e-06         0.123031                    5        1            67.0308       1.45384    0.848921            0.7375      0         â”‚
â”‚ train_hpo_dbd08dac   TERMINATED        7.18321       7.98818e-05         0.251217                    3        1            21.1754       1.02591    0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_812f70ad   TERMINATED        7.43106       1.10121e-06         0.13345                     4        1            26.4054       2.83928    0.848921            0.7375      0         â”‚
â”‚ train_hpo_5c8d44a2   PENDING           7.57559       4.00602e-05         0.220208                    4                                                                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[36m(train_hpo pid=3791696)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3791696)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3791696)[0m 2025-06-16 16:54:06,912 - INFO - pos_weight value in TrainingArguments : 7.5755881632194
[36m(train_hpo pid=3791696)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3791696)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3791302)[0m 2025-06-16 16:54:24,099 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3791302)[0m 2025-06-16 16:54:24,104 - INFO - eval_result: {'eval_loss': 0.7678008079528809, 'eval_f1': 0.8507462686567164, 'eval_accuracy': 0.75, 'eval_kappa': 0.14438502673796794, 'eval_precision': 0.76, 'eval_recall': 0.9661016949152542, 'eval_optim_threshold': 0.8029101490974426, 'eval_AP': 0.8256187873400547, 'eval_MCC': 0.1980534816610477, 'eval_NDCG': 0.949558843468599, 'eval_runtime': 3.3611, 'eval_samples_per_second': 23.802, 'eval_steps_per_second': 1.19, 'epoch': 4.0}
[36m(train_hpo pid=3791302)[0m 2025-06-16 16:54:24,345 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
2025-06-16 16:54:24,368 - INFO - Cleaning up trial 147ca679
2025-06-16 16:54:24,368 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_147ca679_5_learning_rate=0.0000,num_train_epochs=5,pos_weight=2.2031,weight_decay=0.2437_2025-06-16_16-53-19
2025-06-16 16:54:24,368 - INFO - Cleaning up trial e788a5b6
2025-06-16 16:54:24,368 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_e788a5b6_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-52-33
2025-06-16 16:54:24,368 - INFO - Cleaning up trial a9d98af1
2025-06-16 16:54:24,368 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_a9d98af1_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-52-39
2025-06-16 16:54:24,368 - INFO - Cleaning up trial dbd08dac
2025-06-16 16:54:24,368 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_dbd08dac_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-52-45
2025-06-16 16:54:24,368 - INFO - Cleaning up trial 812f70ad
2025-06-16 16:54:24,368 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_812f70ad_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-52-51
[36m(train_hpo pid=3792254)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3792254)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3792254)[0m 2025-06-16 16:54:31,903 - INFO - pos_weight value in TrainingArguments : 6.427550651795176
[36m(train_hpo pid=3792254)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3792254)[0m   super().__init__(*args, **kwargs)


Trial train_hpo_5c8d44a2 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_5c8d44a2 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         4e-05 â”‚
â”‚ num_train_epochs                          4 â”‚
â”‚ pos_weight                          7.57559 â”‚
â”‚ weight_decay                        0.22021 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3791696)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3791510)[0m {'loss': 1.1413, 'grad_norm': 2.675830364227295, 'learning_rate': 1.5752276202747842e-05, 'epoch': 1.0}
[36m(train_hpo pid=3791302)[0m {'loss': 0.5279, 'grad_norm': 1.741804599761963, 'learning_rate': 1.0080209794997367e-05, 'epoch': 3.0}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3791302)[0m {'train_runtime': 26.255, 'train_samples_per_second': 64.369, 'train_steps_per_second': 0.762, 'train_loss': 0.6216147065162658, 'epoch': 4.0}
[36m(train_hpo pid=3791302)[0m STATE at ending of training  :  TrainerState(epoch=4.0, global_step=20, max_steps=20, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=5, num_input_tokens_seen=0, total_flos=355722952925184.0, log_history=[{'loss': 0.8522, 'grad_norm': 1.6591923236846924, 'learning_rate': 3.0240629384992103e-05, 'epoch': 1.0, 'step': 5}, {'loss': 0.6381, 'grad_norm': 1.4527047872543335, 'learning_rate': 2.0160419589994734e-05, 'epoch': 2.0, 'step': 10}, {'loss': 0.5279, 'grad_norm': 1.741804599761963, 'learning_rate': 1.0080209794997367e-05, 'epoch': 3.0, 'step': 15}, {'loss': 0.4683, 'grad_norm': 2.207099437713623, 'learning_rate': 0.0, 'epoch': 4.0, 'step': 20}, {'train_runtime': 26.255, 'train_samples_per_second': 64.369, 'train_steps_per_second': 0.762, 'total_flos': 355722952925184.0, 'train_loss': 0.6216147065162658, 'epoch': 4.0, 'step': 20}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3791302)[0m {'loss': 0.4683, 'grad_norm': 2.207099437713623, 'learning_rate': 0.0, 'epoch': 4.0}
[36m(train_hpo pid=3791510)[0m {'loss': 0.8941, 'grad_norm': 1.5956529378890991, 'learning_rate': 4.50065034364224e-06, 'epoch': 2.0}
[36m(train_hpo pid=3791302)[0m {'eval_loss': 0.7678008079528809, 'eval_f1': 0.8507462686567164, 'eval_accuracy': 0.75, 'eval_kappa': 0.14438502673796794, 'eval_precision': 0.76, 'eval_recall': 0.9661016949152542, 'eval_optim_threshold': 0.8029101490974426, 'eval_AP': 0.8256187873400547, 'eval_MCC': 0.1980534816610477, 'eval_NDCG': 0.949558843468599, 'eval_runtime': 3.3611, 'eval_samples_per_second': 23.802, 'eval_steps_per_second': 1.19, 'epoch': 4.0}

Trial train_hpo_147ca679 finished iteration 1 at 2025-06-16 16:54:24. Total running time: 1min 51s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_147ca679 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    31.2336 â”‚
â”‚ time_total_s                        31.2336 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                                     4 â”‚
â”‚ eval_AP                             0.82562 â”‚
â”‚ eval_MCC                            0.19805 â”‚
â”‚ eval_NDCG                           0.94956 â”‚
â”‚ eval_accuracy                          0.75 â”‚
â”‚ eval_f1                             0.85075 â”‚
â”‚ eval_kappa                          0.14439 â”‚
â”‚ eval_loss                            0.7678 â”‚
â”‚ eval_optim_threshold                0.80291 â”‚
â”‚ eval_precision                         0.76 â”‚
â”‚ eval_recall                          0.9661 â”‚
â”‚ eval_runtime                         3.3611 â”‚
â”‚ eval_samples_per_second              23.802 â”‚
â”‚ eval_steps_per_second                  1.19 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_147ca679 completed after 1 iterations at 2025-06-16 16:54:24. Total running time: 1min 51s
[36m(train_hpo pid=3791510)[0m STATE at ending of training  :  TrainerState(epoch=2.4705882352941178, global_step=12, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=219958867341312.0, log_history=[{'loss': 1.1413, 'grad_norm': 2.675830364227295, 'learning_rate': 1.5752276202747842e-05, 'epoch': 1.0, 'step': 5}, {'loss': 0.8941, 'grad_norm': 1.5956529378890991, 'learning_rate': 4.50065034364224e-06, 'epoch': 2.0, 'step': 10}, {'loss': 0.9438, 'grad_norm': 4.577270984649658, 'learning_rate': 0.0, 'epoch': 2.4705882352941178, 'step': 12}, {'train_runtime': 28.9454, 'train_samples_per_second': 35.031, 'train_steps_per_second': 0.415, 'total_flos': 219958867341312.0, 'train_loss': 1.005397081375122, 'epoch': 2.4705882352941178, 'step': 12}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3791510)[0m {'train_runtime': 28.9454, 'train_samples_per_second': 35.031, 'train_steps_per_second': 0.415, 'train_loss': 1.005397081375122, 'epoch': 2.4705882352941178}
[36m(train_hpo pid=3791510)[0m {'loss': 0.9438, 'grad_norm': 4.577270984649658, 'learning_rate': 0.0, 'epoch': 2.4705882352941178}[32m [repeated 2x across cluster][0m

Trial train_hpo_7c63e957 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_7c63e957 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                             0 â”‚
â”‚ num_train_epochs                          2 â”‚
â”‚ pos_weight                          6.42755 â”‚
â”‚ weight_decay                        0.18512 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3792254)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=8, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=2, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})[36m(train_hpo pid=3791510)[0m 2025-06-16 16:54:33,596 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3791510)[0m 2025-06-16 16:54:33,602 - INFO - eval_result: {'eval_loss': 0.970959484577179, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.8273146152496338, 'eval_AP': 0.8460005303114667, 'eval_MCC': 0.0, 'eval_NDCG': 0.9647896611204494, 'eval_runtime': 3.9118, 'eval_samples_per_second': 20.451, 'eval_steps_per_second': 1.023, 'epoch': 2.4705882352941178}
2025-06-16 16:54:33,864 - INFO - Cleaning up trial c7eef995
2025-06-16 16:54:33,864 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_c7eef995_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-53-53
2025-06-16 16:54:33,864 - INFO - Cleaning up trial e788a5b6
2025-06-16 16:54:33,864 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_e788a5b6_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-52-33
2025-06-16 16:54:33,864 - INFO - Cleaning up trial a9d98af1
2025-06-16 16:54:33,865 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_a9d98af1_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-52-39
2025-06-16 16:54:33,865 - INFO - Cleaning up trial dbd08dac
2025-06-16 16:54:33,865 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_dbd08dac_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-52-45
2025-06-16 16:54:33,865 - INFO - Cleaning up trial 812f70ad
2025-06-16 16:54:33,865 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_812f70ad_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-52-51
2025-06-16 16:54:33,865 - INFO - Current best: 147ca679 with eval_kappa : 0.14438502673796794 at iteration 1
[36m(train_hpo pid=3791510)[0m 2025-06-16 16:54:33,842 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
[36m(train_hpo pid=3792542)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3792542)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3792542)[0m 2025-06-16 16:54:41,951 - INFO - pos_weight value in TrainingArguments : 7.440064585061213
[36m(train_hpo pid=3792542)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3792542)[0m   super().__init__(*args, **kwargs)


Trial status: 5 TERMINATED | 3 RUNNING | 1 PENDING
Current time: 2025-06-16 16:54:33. Total running time: 2min 0s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_c7eef995   RUNNING           4.0662        2.70039e-05         0.239866                    3                                                                                        â”‚
â”‚ train_hpo_5c8d44a2   RUNNING           7.57559       4.00602e-05         0.220208                    4                                                                                        â”‚
â”‚ train_hpo_7c63e957   RUNNING           6.42755       2.7847e-06          0.185124                    2                                                                                        â”‚
â”‚ train_hpo_e788a5b6   TERMINATED        6.82842       1.49561e-06         0.13641                     6        1            72.9518      2.31076     0.848921            0.7375      0         â”‚
â”‚ train_hpo_a9d98af1   TERMINATED        6.09408       4.55539e-06         0.123031                    5        1            67.0308      1.45384     0.848921            0.7375      0         â”‚
â”‚ train_hpo_dbd08dac   TERMINATED        7.18321       7.98818e-05         0.251217                    3        1            21.1754      1.02591     0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_812f70ad   TERMINATED        7.43106       1.10121e-06         0.13345                     4        1            26.4054      2.83928     0.848921            0.7375      0         â”‚
â”‚ train_hpo_147ca679   TERMINATED        2.2031        4.03208e-05         0.243719                    5        1            31.2336      0.767801    0.850746            0.75        0.144385  â”‚
â”‚ train_hpo_1ec1e75a   PENDING           7.44006       4.73492e-05         0.163021                    6                                                                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3791510)[0m {'eval_loss': 0.970959484577179, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.8273146152496338, 'eval_AP': 0.8460005303114667, 'eval_MCC': 0.0, 'eval_NDCG': 0.9647896611204494, 'eval_runtime': 3.9118, 'eval_samples_per_second': 20.451, 'eval_steps_per_second': 1.023, 'epoch': 2.4705882352941178}

Trial train_hpo_c7eef995 finished iteration 1 at 2025-06-16 16:54:33. Total running time: 2min 0s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_c7eef995 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    34.4588 â”‚
â”‚ time_total_s                        34.4588 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               2.47059 â”‚
â”‚ eval_AP                               0.846 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.96479 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           0.97096 â”‚
â”‚ eval_optim_threshold                0.82731 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.9118 â”‚
â”‚ eval_samples_per_second              20.451 â”‚
â”‚ eval_steps_per_second                 1.023 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_c7eef995 completed after 1 iterations at 2025-06-16 16:54:33. Total running time: 2min 0s
[36m(train_hpo pid=3792254)[0m {'loss': 1.9127, 'grad_norm': 7.110527515411377, 'learning_rate': 1.0442639949699175e-06, 'epoch': 1.0}[32m [repeated 2x across cluster][0m

Trial train_hpo_1ec1e75a started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_1ec1e75a config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         5e-05 â”‚
â”‚ num_train_epochs                          6 â”‚
â”‚ pos_weight                          7.44006 â”‚
â”‚ weight_decay                        0.16302 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3791696)[0m {'train_runtime': 34.6663, 'train_samples_per_second': 39.0, 'train_steps_per_second': 0.462, 'train_loss': 1.2608516216278076, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3791696)[0m STATE at ending of training  :  TrainerState(epoch=3.235294117647059, global_step=16, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=287840910133248.0, log_history=[{'loss': 1.7611, 'grad_norm': 3.1176297664642334, 'learning_rate': 2.7541361839643625e-05, 'epoch': 1.0, 'step': 5}, {'loss': 1.1301, 'grad_norm': 2.117783546447754, 'learning_rate': 1.5022561003441977e-05, 'epoch': 2.0, 'step': 10}, {'loss': 0.9412, 'grad_norm': 3.489762783050537, 'learning_rate': 2.5037601672403296e-06, 'epoch': 3.0, 'step': 15}, {'loss': 1.0119, 'grad_norm': 7.927828311920166, 'learning_rate': 0.0, 'epoch': 3.235294117647059, 'step': 16}, {'train_runtime': 34.6663, 'train_samples_per_second': 39.0, 'train_steps_per_second': 0.462, 'total_flos': 287840910133248.0, 'train_loss': 1.2608516216278076, 'epoch': 3.235294117647059, 'step': 16}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})[36m(train_hpo pid=3791696)[0m 2025-06-16 16:54:45,572 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3791696)[0m 2025-06-16 16:54:45,577 - INFO - eval_result: {'eval_loss': 1.1570006608963013, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9313079118728638, 'eval_AP': 0.8501683917281649, 'eval_MCC': 0.0, 'eval_NDCG': 0.9653289013071625, 'eval_runtime': 3.3283, 'eval_samples_per_second': 24.037, 'eval_steps_per_second': 1.202, 'epoch': 3.235294117647059}
2025-06-16 16:54:45,925 - INFO - Cleaning up trial 5c8d44a2
2025-06-16 16:54:45,926 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_5c8d44a2_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.5756,weight_decay=0.2202_2025-06-16_16-53-59
2025-06-16 16:54:45,926 - INFO - Cleaning up trial e788a5b6
2025-06-16 16:54:45,926 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_e788a5b6_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-52-33
2025-06-16 16:54:45,926 - INFO - Cleaning up trial a9d98af1
2025-06-16 16:54:45,926 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_a9d98af1_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-52-39
2025-06-16 16:54:45,926 - INFO - Cleaning up trial dbd08dac
2025-06-16 16:54:45,926 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_dbd08dac_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-52-45
2025-06-16 16:54:45,926 - INFO - Cleaning up trial 812f70ad
2025-06-16 16:54:45,926 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_812f70ad_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-52-51
2025-06-16 16:54:45,927 - INFO - Current best: 147ca679 with eval_kappa : 0.14438502673796794 at iteration 1
2025-06-16 16:54:45,927 - INFO - Cleaning up trial c7eef995
2025-06-16 16:54:45,927 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_c7eef995_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-53-53
[36m(train_hpo pid=3791696)[0m 2025-06-16 16:54:45,903 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
2025-06-16 16:54:47,600 - INFO - Cleaning up trial 7c63e957
2025-06-16 16:54:47,600 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_7c63e957_8_learning_rate=0.0000,num_train_epochs=2,pos_weight=6.4276,weight_decay=0.1851_2025-06-16_16-54-06
2025-06-16 16:54:47,600 - INFO - Cleaning up trial e788a5b6
2025-06-16 16:54:47,600 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_e788a5b6_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-52-33
2025-06-16 16:54:47,600 - INFO - Cleaning up trial a9d98af1
2025-06-16 16:54:47,600 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_a9d98af1_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-52-39
2025-06-16 16:54:47,600 - INFO - Cleaning up trial dbd08dac
2025-06-16 16:54:47,600 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_dbd08dac_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-52-45
2025-06-16 16:54:47,601 - INFO - Cleaning up trial 812f70ad
2025-06-16 16:54:47,601 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_812f70ad_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-52-51
2025-06-16 16:54:47,601 - INFO - Current best: 147ca679 with eval_kappa : 0.14438502673796794 at iteration 1
2025-06-16 16:54:47,601 - INFO - Cleaning up trial c7eef995
2025-06-16 16:54:47,601 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_c7eef995_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-53-53
2025-06-16 16:54:47,601 - INFO - Cleaning up trial 5c8d44a2
2025-06-16 16:54:47,601 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_5c8d44a2_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.5756,weight_decay=0.2202_2025-06-16_16-53-59
[36m(train_hpo pid=3792849)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3792849)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3792254)[0m 2025-06-16 16:54:47,331 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3792254)[0m 2025-06-16 16:54:47,336 - INFO - eval_result: {'eval_loss': 2.343144416809082, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.6074963212013245, 'eval_AP': 0.7575393017070796, 'eval_MCC': 0.0, 'eval_NDCG': 0.9119024052894353, 'eval_runtime': 3.4473, 'eval_samples_per_second': 23.206, 'eval_steps_per_second': 1.16, 'epoch': 1.7058823529411766}
[36m(train_hpo pid=3792254)[0m 2025-06-16 16:54:47,580 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
[36m(train_hpo pid=3792849)[0m 2025-06-16 16:54:53,995 - INFO - pos_weight value in TrainingArguments : 5.904350112349562
[36m(train_hpo pid=3792849)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3792849)[0m   super().__init__(*args, **kwargs)

[36m(train_hpo pid=3792542)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3792254)[0m STATE at ending of training  :  TrainerState(epoch=1.7058823529411766, global_step=8, max_steps=8, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=2, num_input_tokens_seen=0, total_flos=152076824549376.0, log_history=[{'loss': 1.9127, 'grad_norm': 7.110527515411377, 'learning_rate': 1.0442639949699175e-06, 'epoch': 1.0, 'step': 5}, {'loss': 1.9898, 'grad_norm': 38.06317901611328, 'learning_rate': 0.0, 'epoch': 1.7058823529411766, 'step': 8}, {'train_runtime': 11.4768, 'train_samples_per_second': 58.901, 'train_steps_per_second': 0.697, 'total_flos': 152076824549376.0, 'train_loss': 1.9416409730911255, 'epoch': 1.7058823529411766, 'step': 8}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3791696)[0m {'eval_loss': 1.1570006608963013, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9313079118728638, 'eval_AP': 0.8501683917281649, 'eval_MCC': 0.0, 'eval_NDCG': 0.9653289013071625, 'eval_runtime': 3.3283, 'eval_samples_per_second': 24.037, 'eval_steps_per_second': 1.202, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3792254)[0m {'loss': 1.9898, 'grad_norm': 38.06317901611328, 'learning_rate': 0.0, 'epoch': 1.7058823529411766}[32m [repeated 3x across cluster][0m

Trial train_hpo_5c8d44a2 finished iteration 1 at 2025-06-16 16:54:45. Total running time: 2min 12s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_5c8d44a2 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    39.8639 â”‚
â”‚ time_total_s                        39.8639 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               3.23529 â”‚
â”‚ eval_AP                             0.85017 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.96533 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                             1.157 â”‚
â”‚ eval_optim_threshold                0.93131 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.3283 â”‚
â”‚ eval_samples_per_second              24.037 â”‚
â”‚ eval_steps_per_second                 1.202 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_5c8d44a2 completed after 1 iterations at 2025-06-16 16:54:45. Total running time: 2min 12s
[36m(train_hpo pid=3792254)[0m {'train_runtime': 11.4768, 'train_samples_per_second': 58.901, 'train_steps_per_second': 0.697, 'train_loss': 1.9416409730911255, 'epoch': 1.7058823529411766}

Trial train_hpo_7c63e957 finished iteration 1 at 2025-06-16 16:54:47. Total running time: 2min 14s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_7c63e957 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    16.5204 â”‚
â”‚ time_total_s                        16.5204 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               1.70588 â”‚
â”‚ eval_AP                             0.75754 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                            0.9119 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           2.34314 â”‚
â”‚ eval_optim_threshold                 0.6075 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.4473 â”‚
â”‚ eval_samples_per_second              23.206 â”‚
â”‚ eval_steps_per_second                  1.16 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_7c63e957 completed after 1 iterations at 2025-06-16 16:54:47. Total running time: 2min 14s

Trial train_hpo_d131fceb started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_d131fceb config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         1e-05 â”‚
â”‚ num_train_epochs                          3 â”‚
â”‚ pos_weight                          5.90435 â”‚
â”‚ weight_decay                        0.28664 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3792849)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3792254)[0m {'eval_loss': 2.343144416809082, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.6074963212013245, 'eval_AP': 0.7575393017070796, 'eval_MCC': 0.0, 'eval_NDCG': 0.9119024052894353, 'eval_runtime': 3.4473, 'eval_samples_per_second': 23.206, 'eval_steps_per_second': 1.16, 'epoch': 1.7058823529411766}
[36m(train_hpo pid=3792542)[0m {'loss': 1.4235, 'grad_norm': 1.8847230672836304, 'learning_rate': 3.748480305116433e-05, 'epoch': 1.0}
[36m(train_hpo pid=3792542)[0m {'loss': 1.0235, 'grad_norm': 1.692272424697876, 'learning_rate': 2.7620381195594777e-05, 'epoch': 2.0}

Trial train_hpo_6d0ed2ad started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_6d0ed2ad config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         3e-05 â”‚
â”‚ num_train_epochs                          6 â”‚
â”‚ pos_weight                          6.72481 â”‚
â”‚ weight_decay                        0.00109 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[36m(train_hpo pid=3793037)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3793037)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3793037)[0m 2025-06-16 16:55:00,282 - INFO - pos_weight value in TrainingArguments : 6.7248101376462595
[36m(train_hpo pid=3793037)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3793037)[0m   super().__init__(*args, **kwargs)

[36m(train_hpo pid=3793037)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})

Trial status: 8 TERMINATED | 3 RUNNING | 1 PENDING
Current time: 2025-06-16 16:55:03. Total running time: 2min 30s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_1ec1e75a   RUNNING           7.44006       4.73492e-05       0.163021                      6                                                                                        â”‚
â”‚ train_hpo_d131fceb   RUNNING           5.90435       6.78644e-06       0.286643                      3                                                                                        â”‚
â”‚ train_hpo_6d0ed2ad   RUNNING           6.72481       3.23119e-05       0.00108909                    6                                                                                        â”‚
â”‚ train_hpo_e788a5b6   TERMINATED        6.82842       1.49561e-06       0.13641                       6        1            72.9518      2.31076     0.848921            0.7375      0         â”‚
â”‚ train_hpo_a9d98af1   TERMINATED        6.09408       4.55539e-06       0.123031                      5        1            67.0308      1.45384     0.848921            0.7375      0         â”‚
â”‚ train_hpo_dbd08dac   TERMINATED        7.18321       7.98818e-05       0.251217                      3        1            21.1754      1.02591     0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_812f70ad   TERMINATED        7.43106       1.10121e-06       0.13345                       4        1            26.4054      2.83928     0.848921            0.7375      0         â”‚
â”‚ train_hpo_147ca679   TERMINATED        2.2031        4.03208e-05       0.243719                      5        1            31.2336      0.767801    0.850746            0.75        0.144385  â”‚
â”‚ train_hpo_c7eef995   TERMINATED        4.0662        2.70039e-05       0.239866                      3        1            34.4588      0.970959    0.848921            0.7375      0         â”‚
â”‚ train_hpo_5c8d44a2   TERMINATED        7.57559       4.00602e-05       0.220208                      4        1            39.8639      1.157       0.848921            0.7375      0         â”‚
â”‚ train_hpo_7c63e957   TERMINATED        6.42755       2.7847e-06        0.185124                      2        1            16.5204      2.34314     0.848921            0.7375      0         â”‚
â”‚ train_hpo_49dc635c   PENDING           3.50937       2.07214e-05       0.263741                      4                                                                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3793037)[0m {'loss': 1.5392, 'grad_norm': 3.1772141456604004, 'learning_rate': 2.5580274158205587e-05, 'epoch': 1.0}
[36m(train_hpo pid=3792849)[0m {'loss': 1.9212, 'grad_norm': 5.029029846191406, 'learning_rate': 3.958758137704503e-06, 'epoch': 1.0}
[36m(train_hpo pid=3793037)[0m {'loss': 0.9268, 'grad_norm': 2.1159422397613525, 'learning_rate': 1.2116971969676332e-05, 'epoch': 3.0}[32m [repeated 3x across cluster][0m
[36m(train_hpo pid=3792849)[0m {'loss': 1.316, 'grad_norm': 4.409422397613525, 'learning_rate': 1.131073753629858e-06, 'epoch': 2.0}
[36m(train_hpo pid=3793037)[0m {'loss': 0.8004, 'grad_norm': 3.406628131866455, 'learning_rate': 5.3853208754117024e-06, 'epoch': 4.0}
[36m(train_hpo pid=3792849)[0m {'train_runtime': 38.0835, 'train_samples_per_second': 26.626, 'train_steps_per_second': 0.315, 'train_loss': 1.5920923948287964, 'epoch': 2.4705882352941178}
[36m(train_hpo pid=3792849)[0m STATE at ending of training  :  TrainerState(epoch=2.4705882352941178, global_step=12, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=219958867341312.0, log_history=[{'loss': 1.9212, 'grad_norm': 5.029029846191406, 'learning_rate': 3.958758137704503e-06, 'epoch': 1.0, 'step': 5}, {'loss': 1.316, 'grad_norm': 4.409422397613525, 'learning_rate': 1.131073753629858e-06, 'epoch': 2.0, 'step': 10}, {'loss': 1.4597, 'grad_norm': 11.718839645385742, 'learning_rate': 0.0, 'epoch': 2.4705882352941178, 'step': 12}, {'train_runtime': 38.0835, 'train_samples_per_second': 26.626, 'train_steps_per_second': 0.315, 'total_flos': 219958867341312.0, 'train_loss': 1.5920923948287964, 'epoch': 2.4705882352941178, 'step': 12}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3792849)[0m {'loss': 1.4597, 'grad_norm': 11.718839645385742, 'learning_rate': 0.0, 'epoch': 2.4705882352941178}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3793037)[0m STATE at ending of training  :  TrainerState(epoch=4.9411764705882355, global_step=24, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=439917734682624.0, log_history=[{'loss': 1.5392, 'grad_norm': 3.1772141456604004, 'learning_rate': 2.5580274158205587e-05, 'epoch': 1.0, 'step': 5}, {'loss': 1.0977, 'grad_norm': 1.9813477993011475, 'learning_rate': 1.8848623063940963e-05, 'epoch': 2.0, 'step': 10}, {'loss': 0.9268, 'grad_norm': 2.1159422397613525, 'learning_rate': 1.2116971969676332e-05, 'epoch': 3.0, 'step': 15}, {'loss': 0.8004, 'grad_norm': 3.406628131866455, 'learning_rate': 5.3853208754117024e-06, 'epoch': 4.0, 'step': 20}, {'loss': 0.855, 'grad_norm': 7.146231651306152, 'learning_rate': 0.0, 'epoch': 4.9411764705882355, 'step': 24}, {'train_runtime': 32.4184, 'train_samples_per_second': 62.557, 'train_steps_per_second': 0.74, 'total_flos': 439917734682624.0, 'train_loss': 1.0516946117083232, 'epoch': 4.9411764705882355, 'step': 24}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})[36m(train_hpo pid=3793037)[0m 2025-06-16 16:55:36,548 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3793037)[0m 2025-06-16 16:55:36,553 - INFO - eval_result: {'eval_loss': 1.1741068363189697, 'eval_f1': 0.855072463768116, 'eval_accuracy': 0.75, 'eval_kappa': 0.06868451688009314, 'eval_precision': 0.7468354430379747, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9288649559020996, 'eval_AP': 0.7897654974431645, 'eval_MCC': 0.18858311834736916, 'eval_NDCG': 0.9317766483745742, 'eval_runtime': 3.3765, 'eval_samples_per_second': 23.693, 'eval_steps_per_second': 1.185, 'epoch': 4.9411764705882355}
2025-06-16 16:55:36,815 - INFO - Cleaning up trial 6d0ed2ad
2025-06-16 16:55:36,815 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_6d0ed2ad_11_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.7248,weight_decay=0.0011_2025-06-16_16-54-53
2025-06-16 16:55:36,815 - INFO - Cleaning up trial e788a5b6
2025-06-16 16:55:36,815 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_e788a5b6_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-52-33
2025-06-16 16:55:36,815 - INFO - Cleaning up trial a9d98af1
2025-06-16 16:55:36,815 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_a9d98af1_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-52-39
2025-06-16 16:55:36,816 - INFO - Cleaning up trial dbd08dac
2025-06-16 16:55:36,816 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_dbd08dac_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-52-45
2025-06-16 16:55:36,816 - INFO - Cleaning up trial 812f70ad
2025-06-16 16:55:36,816 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_812f70ad_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-52-51
2025-06-16 16:55:36,816 - INFO - Current best: 147ca679 with eval_kappa : 0.14438502673796794 at iteration 1
2025-06-16 16:55:36,816 - INFO - Cleaning up trial c7eef995
2025-06-16 16:55:36,816 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_c7eef995_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-53-53
2025-06-16 16:55:36,816 - INFO - Cleaning up trial 5c8d44a2
2025-06-16 16:55:36,816 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_5c8d44a2_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.5756,weight_decay=0.2202_2025-06-16_16-53-59
2025-06-16 16:55:36,816 - INFO - Cleaning up trial 7c63e957
2025-06-16 16:55:36,816 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_7c63e957_8_learning_rate=0.0000,num_train_epochs=2,pos_weight=6.4276,weight_decay=0.1851_2025-06-16_16-54-06
[36m(train_hpo pid=3793037)[0m 2025-06-16 16:55:36,792 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
2025-06-16 16:55:37,026 - INFO - Cleaning up trial d131fceb
2025-06-16 16:55:37,027 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_d131fceb_10_learning_rate=0.0000,num_train_epochs=3,pos_weight=5.9044,weight_decay=0.2866_2025-06-16_16-54-41
2025-06-16 16:55:37,027 - INFO - Cleaning up trial e788a5b6
2025-06-16 16:55:37,027 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_e788a5b6_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-52-33
2025-06-16 16:55:37,027 - INFO - Cleaning up trial a9d98af1
2025-06-16 16:55:37,027 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_a9d98af1_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-52-39
2025-06-16 16:55:37,027 - INFO - Cleaning up trial dbd08dac
2025-06-16 16:55:37,028 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_dbd08dac_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-52-45
2025-06-16 16:55:37,028 - INFO - Cleaning up trial 812f70ad
2025-06-16 16:55:37,028 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_812f70ad_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-52-51
2025-06-16 16:55:37,028 - INFO - Current best: 147ca679 with eval_kappa : 0.14438502673796794 at iteration 1
2025-06-16 16:55:37,028 - INFO - Cleaning up trial c7eef995
2025-06-16 16:55:37,028 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_c7eef995_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-53-53
2025-06-16 16:55:37,028 - INFO - Cleaning up trial 5c8d44a2
2025-06-16 16:55:37,028 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_5c8d44a2_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.5756,weight_decay=0.2202_2025-06-16_16-53-59
2025-06-16 16:55:37,028 - INFO - Cleaning up trial 7c63e957
2025-06-16 16:55:37,028 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_7c63e957_8_learning_rate=0.0000,num_train_epochs=2,pos_weight=6.4276,weight_decay=0.1851_2025-06-16_16-54-06
2025-06-16 16:55:37,028 - INFO - Cleaning up trial 6d0ed2ad
2025-06-16 16:55:37,028 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_6d0ed2ad_11_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.7248,weight_decay=0.0011_2025-06-16_16-54-53

Trial status: 8 TERMINATED | 3 RUNNING | 1 PENDING
Current time: 2025-06-16 16:55:33. Total running time: 3min 0s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_1ec1e75a   RUNNING           7.44006       4.73492e-05       0.163021                      6                                                                                        â”‚
â”‚ train_hpo_d131fceb   RUNNING           5.90435       6.78644e-06       0.286643                      3                                                                                        â”‚
â”‚ train_hpo_6d0ed2ad   RUNNING           6.72481       3.23119e-05       0.00108909                    6                                                                                        â”‚
â”‚ train_hpo_e788a5b6   TERMINATED        6.82842       1.49561e-06       0.13641                       6        1            72.9518      2.31076     0.848921            0.7375      0         â”‚
â”‚ train_hpo_a9d98af1   TERMINATED        6.09408       4.55539e-06       0.123031                      5        1            67.0308      1.45384     0.848921            0.7375      0         â”‚
â”‚ train_hpo_dbd08dac   TERMINATED        7.18321       7.98818e-05       0.251217                      3        1            21.1754      1.02591     0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_812f70ad   TERMINATED        7.43106       1.10121e-06       0.13345                       4        1            26.4054      2.83928     0.848921            0.7375      0         â”‚
â”‚ train_hpo_147ca679   TERMINATED        2.2031        4.03208e-05       0.243719                      5        1            31.2336      0.767801    0.850746            0.75        0.144385  â”‚
â”‚ train_hpo_c7eef995   TERMINATED        4.0662        2.70039e-05       0.239866                      3        1            34.4588      0.970959    0.848921            0.7375      0         â”‚
â”‚ train_hpo_5c8d44a2   TERMINATED        7.57559       4.00602e-05       0.220208                      4        1            39.8639      1.157       0.848921            0.7375      0         â”‚
â”‚ train_hpo_7c63e957   TERMINATED        6.42755       2.7847e-06        0.185124                      2        1            16.5204      2.34314     0.848921            0.7375      0         â”‚
â”‚ train_hpo_49dc635c   PENDING           3.50937       2.07214e-05       0.263741                      4                                                                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3793037)[0m {'eval_loss': 1.1741068363189697, 'eval_f1': 0.855072463768116, 'eval_accuracy': 0.75, 'eval_kappa': 0.06868451688009314, 'eval_precision': 0.7468354430379747, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9288649559020996, 'eval_AP': 0.7897654974431645, 'eval_MCC': 0.18858311834736916, 'eval_NDCG': 0.9317766483745742, 'eval_runtime': 3.3765, 'eval_samples_per_second': 23.693, 'eval_steps_per_second': 1.185, 'epoch': 4.9411764705882355}

Trial train_hpo_6d0ed2ad finished iteration 1 at 2025-06-16 16:55:36. Total running time: 3min 3s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_6d0ed2ad result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    37.3698 â”‚
â”‚ time_total_s                        37.3698 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               4.94118 â”‚
â”‚ eval_AP                             0.78977 â”‚
â”‚ eval_MCC                            0.18858 â”‚
â”‚ eval_NDCG                           0.93178 â”‚
â”‚ eval_accuracy                          0.75 â”‚
â”‚ eval_f1                             0.85507 â”‚
â”‚ eval_kappa                          0.06868 â”‚
â”‚ eval_loss                           1.17411 â”‚
â”‚ eval_optim_threshold                0.92886 â”‚
â”‚ eval_precision                      0.74684 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.3765 â”‚
â”‚ eval_samples_per_second              23.693 â”‚
â”‚ eval_steps_per_second                 1.185 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_6d0ed2ad completed after 1 iterations at 2025-06-16 16:55:36. Total running time: 3min 3s

Trial train_hpo_d131fceb finished iteration 1 at 2025-06-16 16:55:37. Total running time: 3min 4s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_d131fceb result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    43.9088 â”‚
â”‚ time_total_s                        43.9088 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               2.47059 â”‚
â”‚ eval_AP                             0.78926 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.94225 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           1.50991 â”‚
â”‚ eval_optim_threshold                0.77565 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.9949 â”‚
â”‚ eval_samples_per_second              20.025 â”‚
â”‚ eval_steps_per_second                 1.001 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_d131fceb completed after 1 iterations at 2025-06-16 16:55:37. Total running time: 3min 4s2025-06-16 16:55:41,507 - INFO - Cleaning up trial 1ec1e75a
2025-06-16 16:55:41,507 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_1ec1e75a_9_learning_rate=0.0000,num_train_epochs=6,pos_weight=7.4401,weight_decay=0.1630_2025-06-16_16-54-31
2025-06-16 16:55:41,507 - INFO - Cleaning up trial e788a5b6
2025-06-16 16:55:41,507 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_e788a5b6_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-52-33
2025-06-16 16:55:41,507 - INFO - Cleaning up trial a9d98af1
2025-06-16 16:55:41,507 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_a9d98af1_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-52-39
2025-06-16 16:55:41,507 - INFO - Cleaning up trial dbd08dac
2025-06-16 16:55:41,507 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_dbd08dac_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-52-45
2025-06-16 16:55:41,507 - INFO - Cleaning up trial 812f70ad
2025-06-16 16:55:41,507 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_812f70ad_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-52-51
2025-06-16 16:55:41,508 - INFO - Current best: 147ca679 with eval_kappa : 0.14438502673796794 at iteration 1
2025-06-16 16:55:41,508 - INFO - Cleaning up trial c7eef995
2025-06-16 16:55:41,508 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_c7eef995_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-53-53
2025-06-16 16:55:41,508 - INFO - Cleaning up trial 5c8d44a2
2025-06-16 16:55:41,508 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_5c8d44a2_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.5756,weight_decay=0.2202_2025-06-16_16-53-59
2025-06-16 16:55:41,508 - INFO - Cleaning up trial 7c63e957
2025-06-16 16:55:41,508 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_7c63e957_8_learning_rate=0.0000,num_train_epochs=2,pos_weight=6.4276,weight_decay=0.1851_2025-06-16_16-54-06
2025-06-16 16:55:41,508 - INFO - Cleaning up trial d131fceb
2025-06-16 16:55:41,508 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_d131fceb_10_learning_rate=0.0000,num_train_epochs=3,pos_weight=5.9044,weight_decay=0.2866_2025-06-16_16-54-41
2025-06-16 16:55:41,508 - INFO - Cleaning up trial 6d0ed2ad
2025-06-16 16:55:41,508 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_6d0ed2ad_11_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.7248,weight_decay=0.0011_2025-06-16_16-54-53
[36m(train_hpo pid=3793932)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3793932)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3792542)[0m 2025-06-16 16:55:41,135 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3792542)[0m 2025-06-16 16:55:41,141 - INFO - eval_result: {'eval_loss': 1.0848153829574585, 'eval_f1': 0.855072463768116, 'eval_accuracy': 0.75, 'eval_kappa': 0.06868451688009314, 'eval_precision': 0.7468354430379747, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9590452909469604, 'eval_AP': 0.8074724877304582, 'eval_MCC': 0.18858311834736916, 'eval_NDCG': 0.909278484781057, 'eval_runtime': 3.3193, 'eval_samples_per_second': 24.102, 'eval_steps_per_second': 1.205, 'epoch': 4.9411764705882355}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3792542)[0m 2025-06-16 16:55:41,481 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3793932)[0m 2025-06-16 16:55:45,235 - INFO - pos_weight value in TrainingArguments : 3.5093706580135486
[36m(train_hpo pid=3793932)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3793932)[0m   super().__init__(*args, **kwargs)

[36m(train_hpo pid=3792542)[0m {'train_runtime': 55.165, 'train_samples_per_second': 36.762, 'train_steps_per_second': 0.435, 'train_loss': 0.9491449097792307, 'epoch': 4.9411764705882355}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3792542)[0m {'loss': 0.7554, 'grad_norm': 3.9320383071899414, 'learning_rate': 0.0, 'epoch': 4.9411764705882355}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3792542)[0m STATE at ending of training  :  TrainerState(epoch=4.9411764705882355, global_step=24, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=439917734682624.0, log_history=[{'loss': 1.4235, 'grad_norm': 1.8847230672836304, 'learning_rate': 3.748480305116433e-05, 'epoch': 1.0, 'step': 5}, {'loss': 1.0235, 'grad_norm': 1.692272424697876, 'learning_rate': 2.7620381195594777e-05, 'epoch': 2.0, 'step': 10}, {'loss': 0.8015, 'grad_norm': 4.43562650680542, 'learning_rate': 1.7755959340025214e-05, 'epoch': 3.0, 'step': 15}, {'loss': 0.7031, 'grad_norm': 3.6388370990753174, 'learning_rate': 7.89153748445565e-06, 'epoch': 4.0, 'step': 20}, {'loss': 0.7554, 'grad_norm': 3.9320383071899414, 'learning_rate': 0.0, 'epoch': 4.9411764705882355, 'step': 24}, {'train_runtime': 55.165, 'train_samples_per_second': 36.762, 'train_steps_per_second': 0.435, 'total_flos': 439917734682624.0, 'train_loss': 0.9491449097792307, 'epoch': 4.9411764705882355, 'step': 24}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})

Trial train_hpo_1ec1e75a finished iteration 1 at 2025-06-16 16:55:41. Total running time: 3min 8s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_1ec1e75a result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    60.4174 â”‚
â”‚ time_total_s                        60.4174 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               4.94118 â”‚
â”‚ eval_AP                             0.80747 â”‚
â”‚ eval_MCC                            0.18858 â”‚
â”‚ eval_NDCG                           0.90928 â”‚
â”‚ eval_accuracy                          0.75 â”‚
â”‚ eval_f1                             0.85507 â”‚
â”‚ eval_kappa                          0.06868 â”‚
â”‚ eval_loss                           1.08482 â”‚
â”‚ eval_optim_threshold                0.95905 â”‚
â”‚ eval_precision                      0.74684 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.3193 â”‚
â”‚ eval_samples_per_second              24.102 â”‚
â”‚ eval_steps_per_second                 1.205 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_1ec1e75a completed after 1 iterations at 2025-06-16 16:55:41. Total running time: 3min 8s

Trial train_hpo_49dc635c started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_49dc635c config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         2e-05 â”‚
â”‚ num_train_epochs                          4 â”‚
â”‚ pos_weight                          3.50937 â”‚
â”‚ weight_decay                        0.26374 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3793932)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3792542)[0m {'eval_loss': 1.0848153829574585, 'eval_f1': 0.855072463768116, 'eval_accuracy': 0.75, 'eval_kappa': 0.06868451688009314, 'eval_precision': 0.7468354430379747, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9590452909469604, 'eval_AP': 0.8074724877304582, 'eval_MCC': 0.18858311834736916, 'eval_NDCG': 0.909278484781057, 'eval_runtime': 3.3193, 'eval_samples_per_second': 24.102, 'eval_steps_per_second': 1.205, 'epoch': 4.9411764705882355}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3793932)[0m {'loss': 1.0109, 'grad_norm': 2.2702295780181885, 'learning_rate': 1.4245962766850404e-05, 'epoch': 1.0}
[36m(train_hpo pid=3793932)[0m {'loss': 0.8545, 'grad_norm': 1.581945538520813, 'learning_rate': 7.770525145554766e-06, 'epoch': 2.0}

Trial status: 11 TERMINATED | 1 RUNNING
Current time: 2025-06-16 16:56:03. Total running time: 3min 30s
Logical resource usage: 10.0/32 CPUs, 1.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_49dc635c   RUNNING           3.50937       2.07214e-05       0.263741                      4                                                                                        â”‚
â”‚ train_hpo_e788a5b6   TERMINATED        6.82842       1.49561e-06       0.13641                       6        1            72.9518      2.31076     0.848921            0.7375      0         â”‚
â”‚ train_hpo_a9d98af1   TERMINATED        6.09408       4.55539e-06       0.123031                      5        1            67.0308      1.45384     0.848921            0.7375      0         â”‚
â”‚ train_hpo_dbd08dac   TERMINATED        7.18321       7.98818e-05       0.251217                      3        1            21.1754      1.02591     0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_812f70ad   TERMINATED        7.43106       1.10121e-06       0.13345                       4        1            26.4054      2.83928     0.848921            0.7375      0         â”‚
â”‚ train_hpo_147ca679   TERMINATED        2.2031        4.03208e-05       0.243719                      5        1            31.2336      0.767801    0.850746            0.75        0.144385  â”‚
â”‚ train_hpo_c7eef995   TERMINATED        4.0662        2.70039e-05       0.239866                      3        1            34.4588      0.970959    0.848921            0.7375      0         â”‚
â”‚ train_hpo_5c8d44a2   TERMINATED        7.57559       4.00602e-05       0.220208                      4        1            39.8639      1.157       0.848921            0.7375      0         â”‚
â”‚ train_hpo_7c63e957   TERMINATED        6.42755       2.7847e-06        0.185124                      2        1            16.5204      2.34314     0.848921            0.7375      0         â”‚
â”‚ train_hpo_1ec1e75a   TERMINATED        7.44006       4.73492e-05       0.163021                      6        1            60.4174      1.08482     0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_d131fceb   TERMINATED        5.90435       6.78644e-06       0.286643                      3        1            43.9088      1.50991     0.848921            0.7375      0         â”‚
â”‚ train_hpo_6d0ed2ad   TERMINATED        6.72481       3.23119e-05       0.00108909                    6        1            37.3698      1.17411     0.855072            0.75        0.0686845 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[36m(train_hpo pid=3793932)[0m 2025-06-16 16:56:10,902 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3793932)[0m 2025-06-16 16:56:10,908 - INFO - eval_result: {'eval_loss': 0.9414029121398926, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.8661431670188904, 'eval_AP': 0.841970174695508, 'eval_MCC': 0.0, 'eval_NDCG': 0.9640374962826176, 'eval_runtime': 3.3605, 'eval_samples_per_second': 23.806, 'eval_steps_per_second': 1.19, 'epoch': 3.235294117647059}
2025-06-16 16:56:11,170 - INFO - Cleaning up trial 49dc635c
2025-06-16 16:56:11,170 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_49dc635c_12_learning_rate=0.0000,num_train_epochs=4,pos_weight=3.5094,weight_decay=0.2637_2025-06-16_16-54-59
2025-06-16 16:56:11,170 - INFO - Cleaning up trial e788a5b6
2025-06-16 16:56:11,170 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_e788a5b6_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-52-33
2025-06-16 16:56:11,171 - INFO - Cleaning up trial a9d98af1
2025-06-16 16:56:11,171 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_a9d98af1_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-52-39
2025-06-16 16:56:11,171 - INFO - Cleaning up trial dbd08dac
2025-06-16 16:56:11,171 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_dbd08dac_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-52-45
2025-06-16 16:56:11,171 - INFO - Cleaning up trial 812f70ad
2025-06-16 16:56:11,171 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_812f70ad_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-52-51
2025-06-16 16:56:11,171 - INFO - Current best: 147ca679 with eval_kappa : 0.14438502673796794 at iteration 1
2025-06-16 16:56:11,171 - INFO - Cleaning up trial c7eef995
2025-06-16 16:56:11,171 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_c7eef995_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-53-53
2025-06-16 16:56:11,171 - INFO - Cleaning up trial 5c8d44a2
2025-06-16 16:56:11,171 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_5c8d44a2_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.5756,weight_decay=0.2202_2025-06-16_16-53-59
2025-06-16 16:56:11,171 - INFO - Cleaning up trial 7c63e957
2025-06-16 16:56:11,171 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_7c63e957_8_learning_rate=0.0000,num_train_epochs=2,pos_weight=6.4276,weight_decay=0.1851_2025-06-16_16-54-06
2025-06-16 16:56:11,172 - INFO - Cleaning up trial 1ec1e75a
2025-06-16 16:56:11,172 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_1ec1e75a_9_learning_rate=0.0000,num_train_epochs=6,pos_weight=7.4401,weight_decay=0.1630_2025-06-16_16-54-31
2025-06-16 16:56:11,172 - INFO - Cleaning up trial d131fceb
2025-06-16 16:56:11,172 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_d131fceb_10_learning_rate=0.0000,num_train_epochs=3,pos_weight=5.9044,weight_decay=0.2866_2025-06-16_16-54-41
2025-06-16 16:56:11,172 - INFO - Cleaning up trial 6d0ed2ad
2025-06-16 16:56:11,172 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32/train_hpo_6d0ed2ad_11_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.7248,weight_decay=0.0011_2025-06-16_16-54-53
2025-06-16 16:56:11,181	INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-52-32' in 0.0075s.

[36m(train_hpo pid=3793932)[0m {'loss': 0.7746, 'grad_norm': 1.7785779237747192, 'learning_rate': 1.2950875242591277e-06, 'epoch': 3.0}
[36m(train_hpo pid=3793932)[0m {'loss': 0.8377, 'grad_norm': 4.31788969039917, 'learning_rate': 0.0, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3793932)[0m {'train_runtime': 21.6952, 'train_samples_per_second': 62.318, 'train_steps_per_second': 0.737, 'train_loss': 0.8773689493536949, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3793932)[0m STATE at ending of training  :  TrainerState(epoch=3.235294117647059, global_step=16, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=287840910133248.0, log_history=[{'loss': 1.0109, 'grad_norm': 2.2702295780181885, 'learning_rate': 1.4245962766850404e-05, 'epoch': 1.0, 'step': 5}, {'loss': 0.8545, 'grad_norm': 1.581945538520813, 'learning_rate': 7.770525145554766e-06, 'epoch': 2.0, 'step': 10}, {'loss': 0.7746, 'grad_norm': 1.7785779237747192, 'learning_rate': 1.2950875242591277e-06, 'epoch': 3.0, 'step': 15}, {'loss': 0.8377, 'grad_norm': 4.31788969039917, 'learning_rate': 0.0, 'epoch': 3.235294117647059, 'step': 16}, {'train_runtime': 21.6952, 'train_samples_per_second': 62.318, 'train_steps_per_second': 0.737, 'total_flos': 287840910133248.0, 'train_loss': 0.8773689493536949, 'epoch': 3.235294117647059, 'step': 16}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3793932)[0m {'eval_loss': 0.9414029121398926, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.8661431670188904, 'eval_AP': 0.841970174695508, 'eval_MCC': 0.0, 'eval_NDCG': 0.9640374962826176, 'eval_runtime': 3.3605, 'eval_samples_per_second': 23.806, 'eval_steps_per_second': 1.19, 'epoch': 3.235294117647059}

Trial train_hpo_49dc635c finished iteration 1 at 2025-06-16 16:56:11. Total running time: 3min 38s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_49dc635c result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    26.8153 â”‚
â”‚ time_total_s                        26.8153 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               3.23529 â”‚
â”‚ eval_AP                             0.84197 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.96404 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                            0.9414 â”‚
â”‚ eval_optim_threshold                0.86614 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.3605 â”‚
â”‚ eval_samples_per_second              23.806 â”‚
â”‚ eval_steps_per_second                  1.19 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_49dc635c completed after 1 iterations at 2025-06-16 16:56:11. Total running time: 3min 38s

Trial status: 12 TERMINATED
Current time: 2025-06-16 16:56:11. Total running time: 3min 38s
Logical resource usage: 10.0/32 CPUs, 1.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_e788a5b6   TERMINATED        6.82842       1.49561e-06       0.13641                       6        1            72.9518      2.31076     0.848921            0.7375      0         â”‚
â”‚ train_hpo_a9d98af1   TERMINATED        6.09408       4.55539e-06       0.123031                      5        1            67.0308      1.45384     0.848921            0.7375      0         â”‚
â”‚ train_hpo_dbd08dac   TERMINATED        7.18321       7.98818e-05       0.251217                      3        1            21.1754      1.02591     0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_812f70ad   TERMINATED        7.43106       1.10121e-06       0.13345                       4        1            26.4054      2.83928     0.848921            0.7375      0         â”‚
â”‚ train_hpo_147ca679   TERMINATED        2.2031        4.03208e-05       0.243719                      5        1            31.2336      0.767801    0.850746            0.75        0.144385  â”‚
â”‚ train_hpo_c7eef995   TERMINATED        4.0662        2.70039e-05       0.239866                      3        1            34.4588      0.970959    0.848921            0.7375      0         â”‚
â”‚ train_hpo_5c8d44a2   TERMINATED        7.57559       4.00602e-05       0.220208                      4        1            39.8639      1.157       0.848921            0.7375      0         â”‚
â”‚ train_hpo_7c63e957   TERMINATED        6.42755       2.7847e-06        0.185124                      2        1            16.5204      2.34314     0.848921            0.7375      0         â”‚
â”‚ train_hpo_1ec1e75a   TERMINATED        7.44006       4.73492e-05       0.163021                      6        1            60.4174      1.08482     0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_d131fceb   TERMINATED        5.90435       6.78644e-06       0.286643                      3        1            43.9088      1.50991     0.848921            0.7375      0         â”‚
â”‚ train_hpo_6d0ed2ad   TERMINATED        6.72481       3.23119e-05       0.00108909                    6        1            37.3698      1.17411     0.855072            0.75        0.0686845 â”‚
â”‚ train_hpo_49dc635c   TERMINATED        3.50937       2.07214e-05       0.263741                      4        1            26.8153      0.941403    0.848921            0.7375      0         â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯2025-06-16 16:56:11,199 - INFO - Analysis results: <ray.tune.analysis.experiment_analysis.ExperimentAnalysis object at 0x7583a4214550>
2025-06-16 16:56:11,199 - INFO - Best trial : train_hpo_147ca679
2025-06-16 16:56:11,199 - INFO - Best config : {'pos_weight': 2.2031009297759248, 'learning_rate': 4.032083917998947e-05, 'weight_decay': 0.24371879650720893, 'num_train_epochs': 5}
2025-06-16 16:56:11,199 - INFO - Best trial after optimization: {'eval_loss': 0.7678008079528809, 'eval_f1': 0.8507462686567164, 'eval_accuracy': 0.75, 'eval_kappa': 0.14438502673796794, 'eval_precision': 0.76, 'eval_recall': 0.9661016949152542, 'eval_optim_threshold': 0.8029101490974426, 'eval_AP': 0.8256187873400547, 'eval_MCC': 0.1980534816610477, 'eval_NDCG': 0.949558843468599, 'eval_runtime': 3.3611, 'eval_samples_per_second': 23.802, 'eval_steps_per_second': 1.19, 'epoch': 4.0, 'timestamp': 1750085664, 'checkpoint_dir_name': None, 'done': True, 'training_iteration': 1, 'trial_id': '147ca679', 'date': '2025-06-16_16-54-24', 'time_this_iter_s': 31.23357892036438, 'time_total_s': 31.23357892036438, 'pid': 3791302, 'hostname': 'lcatogni', 'node_ip': '172.30.120.56', 'config': {'pos_weight': 2.2031009297759248, 'learning_rate': 4.032083917998947e-05, 'weight_decay': 0.24371879650720893, 'num_train_epochs': 5}, 'time_since_restore': 31.23357892036438, 'iterations_since_restore': 1, 'experiment_tag': '5_learning_rate=0.0000,num_train_epochs=5,pos_weight=2.2031,weight_decay=0.2437'}
2025-06-16 16:56:11,220 - INFO - analysis dataframe :    eval_loss   eval_f1  ...  config/num_train_epochs    logdir
0   2.310757  0.848921  ...                        6  e788a5b6
1   1.453844  0.848921  ...                        5  a9d98af1
2   1.025914  0.855072  ...                        3  dbd08dac
3   2.839280  0.848921  ...                        4  812f70ad
4   0.767801  0.850746  ...                        5  147ca679

[5 rows x 32 columns]
[36m(train_hpo pid=3793932)[0m 2025-06-16 16:56:11,150 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
2025-06-16 16:56:11,398 - INFO - Trial comparison plot saved
2025-06-16 16:56:11,398 - INFO - Final training...
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-06-16 16:56:12,043 - INFO - Positive weight parameter set to default (in TrainingArguments) -> pos_weight=5.0
/home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
  super().__init__(*args, **kwargs)
2025-06-16 16:56:12,154 - INFO - training size : 338
2025-06-16 16:56:12,155 - INFO - dev size : 80
2025-06-16 16:56:12,155 - INFO - test size : 79
/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:37: UserWarning: 
    There is an imbalance between your GPUs. You may want to exclude GPU 0 which
    has less than 75% of the memory or cores of GPU 2. You can do so by setting
    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES
    environment variable.
  warnings.warn(


  0%|          | 0/75 [00:00<?, ?it/s]  1%|â–         | 1/75 [00:00<00:48,  1.52it/s]  3%|â–Ž         | 2/75 [00:01<00:46,  1.58it/s]  4%|â–         | 3/75 [00:01<00:45,  1.59it/s]  5%|â–Œ         | 4/75 [00:02<00:44,  1.60it/s]  7%|â–‹         | 5/75 [00:03<00:43,  1.61it/s]  8%|â–Š         | 6/75 [00:03<00:42,  1.61it/s]  9%|â–‰         | 7/75 [00:04<00:42,  1.62it/s] 11%|â–ˆ         | 8/75 [00:04<00:41,  1.62it/s] 12%|â–ˆâ–        | 9/75 [00:05<00:40,  1.62it/s] 13%|â–ˆâ–Ž        | 10/75 [00:06<00:40,  1.62it/s] 15%|â–ˆâ–        | 11/75 [00:06<00:39,  1.62it/s] 16%|â–ˆâ–Œ        | 12/75 [00:07<00:38,  1.62it/s] 17%|â–ˆâ–‹        | 13/75 [00:08<00:38,  1.62it/s] 19%|â–ˆâ–Š        | 14/75 [00:08<00:37,  1.64it/s] 20%|â–ˆâ–ˆ        | 15/75 [00:09<00:35,  1.69it/s]                                                20%|â–ˆâ–ˆ        | 15/75 [00:09<00:35,  1.69it/s] 21%|â–ˆâ–ˆâ–       | 16/75 [00:09<00:35,  1.65it/s] 23%|â–ˆâ–ˆâ–Ž       | 17/75 [00:10<00:35,  1.64it/s] 24%|â–ˆâ–ˆâ–       | 18/75 [00:11<00:34,  1.64it/s] 25%|â–ˆâ–ˆâ–Œ       | 19/75 [00:11<00:34,  1.63it/s] 27%|â–ˆâ–ˆâ–‹       | 20/75 [00:12<00:33,  1.63it/s] 28%|â–ˆâ–ˆâ–Š       | 21/75 [00:12<00:33,  1.63it/s] 29%|â–ˆâ–ˆâ–‰       | 22/75 [00:13<00:32,  1.62it/s] 31%|â–ˆâ–ˆâ–ˆ       | 23/75 [00:14<00:32,  1.62it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 24/75 [00:14<00:31,  1.62it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 25/75 [00:15<00:30,  1.62it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 26/75 [00:16<00:30,  1.62it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 27/75 [00:16<00:29,  1.62it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 28/75 [00:17<00:28,  1.62it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 29/75 [00:17<00:28,  1.64it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30/75 [00:18<00:23,  1.88it/s]                                                40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 30/75 [00:18<00:23,  1.88it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/75 [00:18<00:24,  1.77it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 32/75 [00:19<00:24,  1.73it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/75 [00:20<00:24,  1.70it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 34/75 [00:20<00:24,  1.67it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35/75 [00:21<00:24,  1.66it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 36/75 [00:21<00:23,  1.65it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 37/75 [00:22<00:23,  1.64it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 38/75 [00:23<00:22,  1.63it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/75 [00:23<00:22,  1.63it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 40/75 [00:24<00:21,  1.63it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/75 [00:24<00:20,  1.63it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 42/75 [00:25<00:20,  1.63it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 43/75 [00:26<00:19,  1.63it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 44/75 [00:26<00:18,  1.64it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45/75 [00:27<00:16,  1.87it/s]                                                60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 45/75 [00:27<00:16,  1.87it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46/75 [00:27<00:16,  1.77it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 47/75 [00:28<00:16,  1.73it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 48/75 [00:29<00:15,  1.70it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 49/75 [00:29<00:15,  1.67it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 50/75 [00:30<00:15,  1.66it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 51/75 [00:30<00:14,  1.65it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 52/75 [00:31<00:14,  1.64it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 53/75 [00:32<00:13,  1.64it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 54/75 [00:32<00:12,  1.63it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 55/75 [00:33<00:12,  1.63it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 56/75 [00:33<00:11,  1.63it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 57/75 [00:34<00:11,  1.63it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 58/75 [00:35<00:10,  1.63it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 59/75 [00:35<00:09,  1.64it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60/75 [00:36<00:07,  1.90it/s]                                                80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 60/75 [00:36<00:07,  1.90it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61/75 [00:36<00:07,  1.79it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 62/75 [00:37<00:07,  1.73it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 63/75 [00:37<00:07,  1.70it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 64/75 [00:38<00:06,  1.68it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 65/75 [00:39<00:06,  1.66it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 66/75 [00:39<00:05,  1.65it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 67/75 [00:40<00:04,  1.64it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 68/75 [00:41<00:04,  1.64it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 69/75 [00:41<00:03,  1.63it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 70/75 [00:42<00:03,  1.63it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 71/75 [00:42<00:02,  1.63it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 72/75 [00:43<00:01,  1.63it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 73/75 [00:44<00:01,  1.63it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 74/75 [00:44<00:00,  1.64it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:45<00:00,  1.88it/s]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:46<00:00,  1.88it/s]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:46<00:00,  1.88it/s]2025-06-16 16:56:59,459 - INFO - Early stopping triggered, but no best model checkpoint was saved.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:46<00:00,  1.60it/s]
/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:37: UserWarning: 
    There is an imbalance between your GPUs. You may want to exclude GPU 0 which
    has less than 75% of the memory or cores of GPU 2. You can do so by setting
    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES
    environment variable.
  warnings.warn(
{'loss': 0.9534, 'grad_norm': 22.963821411132812, 'learning_rate': 3.225667134399158e-05, 'epoch': 1.0}
{'loss': 0.5957, 'grad_norm': 24.600872039794922, 'learning_rate': 2.419250350799368e-05, 'epoch': 2.0}
{'loss': 0.4461, 'grad_norm': 29.87245750427246, 'learning_rate': 1.612833567199579e-05, 'epoch': 3.0}
{'loss': 0.2453, 'grad_norm': 1.9841185808181763, 'learning_rate': 8.064167835997895e-06, 'epoch': 4.0}
{'loss': 0.1829, 'grad_norm': 3.973621129989624, 'learning_rate': 0.0, 'epoch': 5.0}
{'train_runtime': 46.9908, 'train_samples_per_second': 35.964, 'train_steps_per_second': 1.596, 'train_loss': 0.4846692752838135, 'epoch': 5.0}
  0%|          | 0/4 [00:00<?, ?it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.21it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.23it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.26it/s]2025-06-16 16:57:03,238 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.15it/s]
2025-06-16 16:57:03,244 - INFO - Training time : 51.84566463693045
/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:37: UserWarning: 
    There is an imbalance between your GPUs. You may want to exclude GPU 0 which
    has less than 75% of the memory or cores of GPU 2. You can do so by setting
    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES
    environment variable.
  warnings.warn(
  0%|          | 0/4 [00:00<?, ?it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.19it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.24it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.28it/s]2025-06-16 16:57:07,413 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.03it/s]
2025-06-16 16:57:07,418 - INFO - Evaluation time : 4.173970894073136
2025-06-16 16:57:07,418 - INFO - Evaluation results on test set: {'eval_loss': 0.8915122151374817, 'eval_f1': 0.8429752066115702, 'eval_accuracy': 0.759493670886076, 'eval_kappa': 0.330806954971021, 'eval_precision': 0.8225806451612904, 'eval_recall': 0.864406779661017, 'eval_optim_threshold': 0.8906309604644775, 'eval_AP': 0.8642274713361964, 'eval_MCC': 0.3326692051444776, 'eval_NDCG': 0.9679725736871325, 'eval_runtime': 4.1698, 'eval_samples_per_second': 18.946, 'eval_steps_per_second': 0.959, 'epoch': 5.0}
2025-06-16 16:57:07,418 - INFO - Total updates (optimizer steps): 75
2025-06-16 16:57:07,418 - INFO - Avg time / step: 0.627s
2025-06-16 16:57:08,401 - INFO - Best model saved to /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/final_model/best_model_cross_val_BCEmicrosoft/BiomedNLP-BiomedBERT-base-uncased-abstract12trials_fold-3
2025-06-16 16:57:08,401 - INFO - On test Set (with threshold 0.5) : 
/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:37: UserWarning: 
    There is an imbalance between your GPUs. You may want to exclude GPU 0 which
    has less than 75% of the memory or cores of GPU 2. You can do so by setting
    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES
    environment variable.
  warnings.warn(
  0%|          | 0/4 [00:00<?, ?it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  7.20it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  5.24it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.28it/s]2025-06-16 16:57:12,383 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.09it/s]
2025-06-16 16:57:12,386 - INFO - Raw predictions shape: (79, 1)
2025-06-16 16:57:12,387 - INFO - Raw predictions: [[ 1.7884926]
 [ 3.2629948]
 [ 3.1780877]
 [-1.9316299]
 [ 3.420301 ]
 [ 3.6388984]
 [ 1.9438939]
 [ 2.5015993]
 [ 3.656559 ]
 [ 3.281132 ]]
2025-06-16 16:57:12,387 - INFO - Scores shape: (79,)
2025-06-16 16:57:12,387 - INFO - Scores: [0.8567424  0.96313727 0.96000123 0.12657027 0.968333   0.97439176
 0.87477934 0.92425394 0.9748287  0.96377575]
2025-06-16 16:57:12,387 - INFO - Preds shape: (79,)
2025-06-16 16:57:12,387 - INFO - Preds: [1 1 1 0 1 1 1 1 1 1]
2025-06-16 16:57:12,388 - INFO - Test labels shape: (79,)
2025-06-16 16:57:12,388 - INFO - Test labels: [0, 1, 1, 1, 1, 1, 0, 1, 1, 0]
2025-06-16 16:57:12,388 - INFO - Test split: Dataset({
    features: ['title', 'abstract', 'Keywords', 'doi', 'labels'],
    num_rows: 79
})
2025-06-16 16:57:12,388 - INFO - Unique values in predictions: [0 1]
2025-06-16 16:57:12,389 - INFO - Unique values in labels: [0 1]
2025-06-16 16:57:12,390 - INFO - Confusion matrix:
[[ 9 11]
 [ 8 51]]
2025-06-16 16:57:12,391 - INFO - Confusion matrix: TN=9, FP=11, FN=8, TP=51
2025-06-16 16:57:15,094 - INFO - Metrics: {'f1': 0.8429752066115702, 'recall': 0.864406779661017, 'precision': 0.8225806451612904, 'accuracy': 0.759493670886076, 'AP': 0.8642274713361964, 'MCC': 0.3326692051444776, 'NDCG': 0.9679725736871325, 'kappa': 0.330806954971021, 'TN': 9, 'FP': 11, 'FN': 8, 'TP': 51}
2025-06-16 16:57:15,098 - INFO - Metrics stored successfully at /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/metrics/binary_metrics.csv
2025-06-16 16:57:15,215 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_test.png
2025-06-16 16:57:15,316 - INFO - Precision-Recall curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/precision_recall_curvetest.png
2025-06-16 16:57:15,316 - INFO - 
On test Set (optimal threshold of 0.9629009366035461 according to cross validation on the training set): 
2025-06-16 16:57:15,317 - INFO - Confusion matrix: TN=15, FP=5, FN=36, TP=23
2025-06-16 16:57:18,007 - INFO - Metrics: {'f1': 0.5287356321839081, 'recall': 0.3898305084745763, 'precision': 0.8214285714285714, 'accuracy': 0.4810126582278481, 'AP': 0.8642274713361964, 'MCC': 0.12710974189025373, 'NDCG': 0.9679725736871325, 'kappa': 0.09246287475483339, 'TN': 15, 'FP': 5, 'FN': 36, 'TP': 23}
2025-06-16 16:57:18,106 - INFO - Precision-Recall curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/precision_recall_curvetest.png
2025-06-16 16:57:18,106 - INFO - Results for fold 3 : [{'f1': 0.5287356321839081, 'recall': 0.3898305084745763, 'precision': 0.8214285714285714, 'accuracy': 0.4810126582278481, 'AP': 0.8642274713361964, 'MCC': 0.12710974189025373, 'NDCG': 0.9679725736871325, 'kappa': 0.09246287475483339, 'TN': 15, 'FP': 5, 'FN': 36, 'TP': 23}]
2025-06-16 16:57:18,505 - INFO - Cleared CUDA cache. Memory allocated: 1.39 GB, Memory reserved: 1.53 GB
2025-06-16 16:57:18,743 - INFO - Cleared CUDA cache. Memory allocated: 1.39 GB, Memory reserved: 1.53 GB
2025-06-16 16:57:18,743 - INFO - 
fold number 4 / 5
2025-06-16 16:57:18,748 - INFO - train split size : 338
2025-06-16 16:57:18,748 - INFO - dev split size : 80
2025-06-16 16:57:18,748 - INFO - test split size : 79
Map (num_proc=32):   0%|          | 0/338 [00:00<?, ? examples/s]Map (num_proc=32):   3%|â–Ž         | 11/338 [00:00<00:09, 35.44 examples/s]Map (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 77/338 [00:00<00:01, 225.96 examples/s]Map (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 143/338 [00:00<00:00, 323.02 examples/s]Map (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 198/338 [00:00<00:00, 381.44 examples/s]Map (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 278/338 [00:00<00:00, 470.12 examples/s]Map (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:00<00:00, 499.51 examples/s]Map (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:01<00:00, 331.79 examples/s]
Map (num_proc=32):   0%|          | 0/80 [00:00<?, ? examples/s]Map (num_proc=32):   4%|â–         | 3/80 [00:00<00:07, 10.57 examples/s]Map (num_proc=32):  26%|â–ˆâ–ˆâ–‹       | 21/80 [00:00<00:00, 63.24 examples/s]Map (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/80 [00:00<00:00, 86.10 examples/s]Map (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/80 [00:00<00:00, 104.07 examples/s]Map (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 66/80 [00:00<00:00, 100.25 examples/s]Map (num_proc=32):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 78/80 [00:00<00:00, 101.95 examples/s]Map (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:01<00:00, 75.90 examples/s] 
Map (num_proc=32):   0%|          | 0/79 [00:00<?, ? examples/s]Map (num_proc=32):   4%|â–         | 3/79 [00:00<00:06, 11.22 examples/s]Map (num_proc=32):  19%|â–ˆâ–‰        | 15/79 [00:00<00:01, 43.93 examples/s]Map (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/79 [00:00<00:00, 73.65 examples/s]Map (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 47/79 [00:00<00:00, 100.41 examples/s]Map (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/79 [00:00<00:00, 98.51 examples/s] Map (num_proc=32):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 71/79 [00:00<00:00, 86.63 examples/s]Map (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:01<00:00, 69.95 examples/s]
2025-06-16 16:57:29,874 - INFO - 3 datasets tokenized successfully
2025-06-16 16:57:29,942 - INFO - Fold 4 max seq len = 512
2025-06-16 16:57:29,942 - INFO - Starting hyperparameter search for BCE loss
[36m(train_hpo pid=3797031)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3797031)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3797031)[0m 2025-06-16 16:57:37,595 - INFO - pos_weight value in TrainingArguments : 6.828424226204718
[36m(train_hpo pid=3797031)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3797031)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3797226)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3797226)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3797226)[0m 2025-06-16 16:57:44,112 - INFO - pos_weight value in TrainingArguments : 6.094080202241274
[36m(train_hpo pid=3797226)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3797226)[0m   super().__init__(*args, **kwargs)
2025-06-16 16:57:46,105	ERROR tune_controller.py:1331 -- Trial task failed for trial train_hpo_626b5182
Traceback (most recent call last):
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
             ^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/worker.py", line 2782, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/worker.py", line 929, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::ImplicitFunc.train()[39m (pid=3797031, ip=172.30.120.56, actor_id=e98f33ae778d2863d22a3e4b01000000, repr=train_hpo)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/trainable.py", line 330, in train
    raise skipped from exception_cause(skipped)
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/air/_internal/util.py", line 107, in run
    self._ret = self._target(*self._args, **self._kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py", line 45, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py", line 261, in _trainable_func
    output = fn()
             ^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/util.py", line 130, in inner
    return trainable(config, **fn_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/binary_pipeline.py", line 253, in train_hpo
    trainer.train()
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 2241, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 2550, in _inner_training_loop
    if (
RuntimeError: CUDA error: unspecified launch failure
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(train_hpo pid=3797417)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3797417)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3797417)[0m 2025-06-16 16:57:50,887 - INFO - pos_weight value in TrainingArguments : 7.183206941666034
[36m(train_hpo pid=3797417)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3797417)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3797611)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3797611)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3797611)[0m 2025-06-16 16:57:57,585 - INFO - pos_weight value in TrainingArguments : 7.431057651685638
[36m(train_hpo pid=3797611)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3797611)[0m   super().__init__(*args, **kwargs)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Configuration for experiment     train_hpo_2025-06-16_16-57-30   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Search algorithm                 SearchGenerator                 â”‚
â”‚ Scheduler                        AsyncHyperBandScheduler         â”‚
â”‚ Number of trials                 12                              â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

View detailed results here: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-57-30
To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-06-16_16-42-25_595113_3771642/artifacts/2025-06-16_16-57-30/train_hpo_2025-06-16_16-57-30/driver_artifacts`

Trial status: 1 PENDING
Current time: 2025-06-16 16:57:30. Total running time: 0s
Logical resource usage: 10.0/32 CPUs, 1.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status       pos_weight     learning_rate     weight_decay     num_train_epochs â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_626b5182   PENDING         6.82842       1.49561e-06          0.13641                    6 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_626b5182 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_626b5182 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                             0 â”‚
â”‚ num_train_epochs                          6 â”‚
â”‚ pos_weight                          6.82842 â”‚
â”‚ weight_decay                        0.13641 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3797031)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})

Trial train_hpo_ab09a3c7 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_ab09a3c7 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                             0 â”‚
â”‚ num_train_epochs                          5 â”‚
â”‚ pos_weight                          6.09408 â”‚
â”‚ weight_decay                        0.12303 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_626b5182 errored after 0 iterations at 2025-06-16 16:57:46. Total running time: 16s
Error file: /tmp/ray/session_2025-06-16_16-42-25_595113_3771642/artifacts/2025-06-16_16-57-30/train_hpo_2025-06-16_16-57-30/driver_artifacts/train_hpo_626b5182_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-57-30/error.txt
[36m(train_hpo pid=3797226)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=20, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=5, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})

Trial train_hpo_6cb74c18 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_6cb74c18 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         8e-05 â”‚
â”‚ num_train_epochs                          3 â”‚
â”‚ pos_weight                          7.18321 â”‚
â”‚ weight_decay                        0.25122 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3797417)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3797226)[0m {'loss': 2.1469, 'grad_norm': 7.476699352264404, 'learning_rate': 3.416543648145448e-06, 'epoch': 1.0}

Trial train_hpo_a4a6972c started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_a4a6972c config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                             0 â”‚
â”‚ num_train_epochs                          4 â”‚
â”‚ pos_weight                          7.43106 â”‚
â”‚ weight_decay                        0.13345 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3797611)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})2025-06-16 16:58:00,445	ERROR tune_controller.py:1331 -- Trial task failed for trial train_hpo_a4a6972c
Traceback (most recent call last):
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
             ^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/worker.py", line 2782, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/worker.py", line 929, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::ImplicitFunc.train()[39m (pid=3797611, ip=172.30.120.56, actor_id=3f4daa6bccd2e7a0df67b49801000000, repr=train_hpo)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/trainable.py", line 330, in train
    raise skipped from exception_cause(skipped)
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/air/_internal/util.py", line 107, in run
    self._ret = self._target(*self._args, **self._kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py", line 45, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py", line 261, in _trainable_func
    output = fn()
             ^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/util.py", line 130, in inner
    return trainable(config, **fn_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/binary_pipeline.py", line 253, in train_hpo
    trainer.train()
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 2241, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 2548, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 3698, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py", line 121, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py", line 1673, in forward
    outputs = self.bert(
              ^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py", line 1078, in forward
    embedding_output = self.embeddings(
                       ^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py", line 219, in forward
    embeddings = self.dropout(embeddings)
                 ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/dropout.py", line 70, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/functional.py", line 1425, in dropout
    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: unspecified launch failure
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(train_hpo pid=3797912)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3797912)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3797912)[0m 2025-06-16 16:58:08,404 - INFO - pos_weight value in TrainingArguments : 2.2031009297759248
[36m(train_hpo pid=3797912)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3797912)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3797417)[0m 2025-06-16 16:58:11,013 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3797417)[0m 2025-06-16 16:58:11,018 - INFO - eval_result: {'eval_loss': 1.0212053060531616, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9481384754180908, 'eval_AP': 0.9006516878887338, 'eval_MCC': 0.0, 'eval_NDCG': 0.9777518836602481, 'eval_runtime': 3.3203, 'eval_samples_per_second': 24.094, 'eval_steps_per_second': 1.205, 'epoch': 2.4705882352941178}
2025-06-16 16:58:11,235	ERROR tune_controller.py:1331 -- Trial task failed for trial train_hpo_70e050f9
Traceback (most recent call last):
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
             ^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/worker.py", line 2782, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/worker.py", line 929, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::ImplicitFunc.train()[39m (pid=3797912, ip=172.30.120.56, actor_id=d4cca75d6188fd9bab05d31501000000, repr=train_hpo)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/trainable.py", line 330, in train
    raise skipped from exception_cause(skipped)
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/air/_internal/util.py", line 107, in run
    self._ret = self._target(*self._args, **self._kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py", line 45, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py", line 261, in _trainable_func
    output = fn()
             ^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/util.py", line 130, in inner
    return trainable(config, **fn_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/binary_pipeline.py", line 253, in train_hpo
    trainer.train()
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 2241, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 2548, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 3698, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py", line 121, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py", line 1673, in forward
    outputs = self.bert(
              ^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py", line 1078, in forward
    embedding_output = self.embeddings(
                       ^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py", line 219, in forward
    embeddings = self.dropout(embeddings)
                 ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/dropout.py", line 70, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/functional.py", line 1425, in dropout
    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: unspecified launch failure
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
2025-06-16 16:58:11,277 - INFO - Cleaning up trial 6cb74c18
2025-06-16 16:58:11,278 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-57-30/train_hpo_6cb74c18_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=7.1832,weight_decay=0.2512_2025-06-16_16-57-43
[36m(train_hpo pid=3797417)[0m 2025-06-16 16:58:11,255 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB


Trial status: 1 ERROR | 3 RUNNING | 1 PENDING
Current time: 2025-06-16 16:58:00. Total running time: 30s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status       pos_weight     learning_rate     weight_decay     num_train_epochs â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_ab09a3c7   RUNNING         6.09408       4.55539e-06         0.123031                    5 â”‚
â”‚ train_hpo_6cb74c18   RUNNING         7.18321       7.98818e-05         0.251217                    3 â”‚
â”‚ train_hpo_a4a6972c   RUNNING         7.43106       1.10121e-06         0.13345                     4 â”‚
â”‚ train_hpo_70e050f9   PENDING         2.2031        4.03208e-05         0.243719                    5 â”‚
â”‚ train_hpo_626b5182   ERROR           6.82842       1.49561e-06         0.13641                     6 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_a4a6972c errored after 0 iterations at 2025-06-16 16:58:00. Total running time: 30s
Error file: /tmp/ray/session_2025-06-16_16-42-25_595113_3771642/artifacts/2025-06-16_16-57-30/train_hpo_2025-06-16_16-57-30/driver_artifacts/train_hpo_a4a6972c_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-57-49/error.txt
[36m(train_hpo pid=3797226)[0m {'loss': 1.5934, 'grad_norm': 7.019093990325928, 'learning_rate': 2.2776957654302987e-06, 'epoch': 2.0}[32m [repeated 2x across cluster][0m

Trial train_hpo_70e050f9 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_70e050f9 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         4e-05 â”‚
â”‚ num_train_epochs                          5 â”‚
â”‚ pos_weight                           2.2031 â”‚
â”‚ weight_decay                        0.24372 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3797417)[0m {'train_runtime': 16.32, 'train_samples_per_second': 62.132, 'train_steps_per_second': 0.735, 'train_loss': 1.2042451600233715, 'epoch': 2.4705882352941178}
[36m(train_hpo pid=3797417)[0m STATE at ending of training  :  TrainerState(epoch=2.4705882352941178, global_step=12, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=219958867341312.0, log_history=[{'loss': 1.4589, 'grad_norm': 1.917231798171997, 'learning_rate': 4.6597713532890536e-05, 'epoch': 1.0, 'step': 5}, {'loss': 1.0352, 'grad_norm': 1.7746318578720093, 'learning_rate': 1.3313632437968722e-05, 'epoch': 2.0, 'step': 10}, {'loss': 0.9903, 'grad_norm': 5.135232925415039, 'learning_rate': 0.0, 'epoch': 2.4705882352941178, 'step': 12}, {'train_runtime': 16.32, 'train_samples_per_second': 62.132, 'train_steps_per_second': 0.735, 'total_flos': 219958867341312.0, 'train_loss': 1.2042451600233715, 'epoch': 2.4705882352941178, 'step': 12}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3797417)[0m {'loss': 0.9903, 'grad_norm': 5.135232925415039, 'learning_rate': 0.0, 'epoch': 2.4705882352941178}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3797912)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=20, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=5, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3797417)[0m {'eval_loss': 1.0212053060531616, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9481384754180908, 'eval_AP': 0.9006516878887338, 'eval_MCC': 0.0, 'eval_NDCG': 0.9777518836602481, 'eval_runtime': 3.3203, 'eval_samples_per_second': 24.094, 'eval_steps_per_second': 1.205, 'epoch': 2.4705882352941178}

Trial train_hpo_70e050f9 errored after 0 iterations at 2025-06-16 16:58:11. Total running time: 41s
Error file: /tmp/ray/session_2025-06-16_16-42-25_595113_3771642/artifacts/2025-06-16_16-57-30/train_hpo_2025-06-16_16-57-30/driver_artifacts/train_hpo_70e050f9_5_learning_rate=0.0000,num_train_epochs=5,pos_weight=2.2031,weight_decay=0.2437_2025-06-16_16-57-56/error.txt

Trial train_hpo_6cb74c18 finished iteration 1 at 2025-06-16 16:58:11. Total running time: 41s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_6cb74c18 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    21.4078 â”‚
â”‚ time_total_s                        21.4078 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               2.47059 â”‚
â”‚ eval_AP                             0.90065 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.97775 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           1.02121 â”‚
â”‚ eval_optim_threshold                0.94814 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.3203 â”‚
â”‚ eval_samples_per_second              24.094 â”‚
â”‚ eval_steps_per_second                 1.205 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_6cb74c18 completed after 1 iterations at 2025-06-16 16:58:11. Total running time: 41s
[36m(train_hpo pid=3797226)[0m STATE at ending of training  :  TrainerState(epoch=4.0, global_step=20, max_steps=20, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=5, num_input_tokens_seen=0, total_flos=355722952925184.0, log_history=[{'loss': 2.1469, 'grad_norm': 7.476699352264404, 'learning_rate': 3.416543648145448e-06, 'epoch': 1.0, 'step': 5}, {'loss': 1.5934, 'grad_norm': 7.019093990325928, 'learning_rate': 2.2776957654302987e-06, 'epoch': 2.0, 'step': 10}, {'loss': 1.37, 'grad_norm': 2.994142770767212, 'learning_rate': 1.1388478827151493e-06, 'epoch': 3.0, 'step': 15}, {'loss': 1.2929, 'grad_norm': 4.571939945220947, 'learning_rate': 0.0, 'epoch': 4.0, 'step': 20}, {'train_runtime': 30.159, 'train_samples_per_second': 56.036, 'train_steps_per_second': 0.663, 'total_flos': 355722952925184.0, 'train_loss': 1.6008391380310059, 'epoch': 4.0, 'step': 20}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})[36m(train_hpo pid=3798219)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3798219)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3798219)[0m 2025-06-16 16:58:19,442 - INFO - pos_weight value in TrainingArguments : 4.066204305086463
[36m(train_hpo pid=3798219)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3798219)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3797226)[0m 2025-06-16 16:58:19,918 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3797226)[0m 2025-06-16 16:58:19,924 - INFO - eval_result: {'eval_loss': 1.605808973312378, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.796068012714386, 'eval_AP': 0.7037356281455439, 'eval_MCC': 0.0, 'eval_NDCG': 0.8783285240144083, 'eval_runtime': 3.3026, 'eval_samples_per_second': 24.223, 'eval_steps_per_second': 1.211, 'epoch': 4.0}
[36m(train_hpo pid=3797226)[0m 2025-06-16 16:58:20,166 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
2025-06-16 16:58:20,189 - INFO - Cleaning up trial ab09a3c7
2025-06-16 16:58:20,189 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-57-30/train_hpo_ab09a3c7_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=6.0941,weight_decay=0.1230_2025-06-16_16-57-36
2025-06-16 16:58:20,189 - INFO - Current best: 6cb74c18 with eval_kappa : 0.0 at iteration 1
[36m(train_hpo pid=3798472)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3798472)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3798472)[0m 2025-06-16 16:58:26,186 - INFO - pos_weight value in TrainingArguments : 7.5755881632194
[36m(train_hpo pid=3798472)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3798472)[0m   super().__init__(*args, **kwargs)

[36m(train_hpo pid=3797226)[0m {'train_runtime': 30.159, 'train_samples_per_second': 56.036, 'train_steps_per_second': 0.663, 'train_loss': 1.6008391380310059, 'epoch': 4.0}
[36m(train_hpo pid=3797226)[0m {'loss': 1.2929, 'grad_norm': 4.571939945220947, 'learning_rate': 0.0, 'epoch': 4.0}[32m [repeated 2x across cluster][0m

Trial train_hpo_2d5eb257 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_2d5eb257 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         3e-05 â”‚
â”‚ num_train_epochs                          3 â”‚
â”‚ pos_weight                           4.0662 â”‚
â”‚ weight_decay                        0.23987 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3797226)[0m {'eval_loss': 1.605808973312378, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.796068012714386, 'eval_AP': 0.7037356281455439, 'eval_MCC': 0.0, 'eval_NDCG': 0.8783285240144083, 'eval_runtime': 3.3026, 'eval_samples_per_second': 24.223, 'eval_steps_per_second': 1.211, 'epoch': 4.0}
[36m(train_hpo pid=3798219)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})

Trial train_hpo_ab09a3c7 finished iteration 1 at 2025-06-16 16:58:20. Total running time: 50s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_ab09a3c7 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    36.9113 â”‚
â”‚ time_total_s                        36.9113 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                                     4 â”‚
â”‚ eval_AP                             0.70374 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.87833 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           1.60581 â”‚
â”‚ eval_optim_threshold                0.79607 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.3026 â”‚
â”‚ eval_samples_per_second              24.223 â”‚
â”‚ eval_steps_per_second                 1.211 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_ab09a3c7 completed after 1 iterations at 2025-06-16 16:58:20. Total running time: 50s

Trial train_hpo_717a7ea8 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_717a7ea8 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         4e-05 â”‚
â”‚ num_train_epochs                          4 â”‚
â”‚ pos_weight                          7.57559 â”‚
â”‚ weight_decay                        0.22021 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3798472)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3798219)[0m {'loss': 1.1993, 'grad_norm': 2.572051763534546, 'learning_rate': 1.5752276202747842e-05, 'epoch': 1.0}

Trial status: 3 ERROR | 2 TERMINATED | 2 RUNNING | 1 PENDING
Current time: 2025-06-16 16:58:30. Total running time: 1min 0s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_2d5eb257   RUNNING           4.0662        2.70039e-05         0.239866                    3                                                                                        â”‚
â”‚ train_hpo_717a7ea8   RUNNING           7.57559       4.00602e-05         0.220208                    4                                                                                        â”‚
â”‚ train_hpo_ab09a3c7   TERMINATED        6.09408       4.55539e-06         0.123031                    5        1            36.9113       1.60581    0.848921            0.7375              0 â”‚
â”‚ train_hpo_6cb74c18   TERMINATED        7.18321       7.98818e-05         0.251217                    3        1            21.4078       1.02121    0.848921            0.7375              0 â”‚
â”‚ train_hpo_f530ffec   PENDING           6.42755       2.7847e-06          0.185124                    2                                                                                        â”‚
â”‚ train_hpo_626b5182   ERROR             6.82842       1.49561e-06         0.13641                     6                                                                                        â”‚
â”‚ train_hpo_a4a6972c   ERROR             7.43106       1.10121e-06         0.13345                     4                                                                                        â”‚
â”‚ train_hpo_70e050f9   ERROR             2.2031        4.03208e-05         0.243719                    5                                                                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[36m(train_hpo pid=3798679)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3798679)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3798679)[0m 2025-06-16 16:58:32,835 - INFO - pos_weight value in TrainingArguments : 6.427550651795176
[36m(train_hpo pid=3798679)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3798679)[0m   super().__init__(*args, **kwargs)
2025-06-16 16:58:34,930	ERROR tune_controller.py:1331 -- Trial task failed for trial train_hpo_2d5eb257
Traceback (most recent call last):
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
             ^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/worker.py", line 2782, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/worker.py", line 929, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::ImplicitFunc.train()[39m (pid=3798219, ip=172.30.120.56, actor_id=c495c313d7897a4bc667ef4c01000000, repr=train_hpo)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/trainable.py", line 330, in train
    raise skipped from exception_cause(skipped)
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/air/_internal/util.py", line 107, in run
    self._ret = self._target(*self._args, **self._kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py", line 45, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py", line 261, in _trainable_func
    output = fn()
             ^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/util.py", line 130, in inner
    return trainable(config, **fn_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/binary_pipeline.py", line 253, in train_hpo
    trainer.train()
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 2241, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 2550, in _inner_training_loop
    if (
RuntimeError: CUDA error: unspecified launch failure
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(train_hpo pid=3798979)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3798979)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3798979)[0m 2025-06-16 16:58:43,187 - INFO - pos_weight value in TrainingArguments : 7.440064585061213
[36m(train_hpo pid=3798979)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3798979)[0m   super().__init__(*args, **kwargs)
2025-06-16 16:58:46,154	ERROR tune_controller.py:1331 -- Trial task failed for trial train_hpo_ab313185
Traceback (most recent call last):
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
             ^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/worker.py", line 2782, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/worker.py", line 929, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::ImplicitFunc.train()[39m (pid=3798979, ip=172.30.120.56, actor_id=2465f4b525b8a983ec51fc4501000000, repr=train_hpo)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/trainable.py", line 330, in train
    raise skipped from exception_cause(skipped)
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/air/_internal/util.py", line 107, in run
    self._ret = self._target(*self._args, **self._kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py", line 45, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py", line 261, in _trainable_func
    output = fn()
             ^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/util.py", line 130, in inner
    return trainable(config, **fn_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/binary_pipeline.py", line 253, in train_hpo
    trainer.train()
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 2241, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 2548, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 3698, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py", line 121, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py", line 1673, in forward
    outputs = self.bert(
              ^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py", line 1078, in forward
    embedding_output = self.embeddings(
                       ^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py", line 219, in forward
    embeddings = self.dropout(embeddings)
                 ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/modules/dropout.py", line 70, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/torch/nn/functional.py", line 1425, in dropout
    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: unspecified launch failure
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(train_hpo pid=3798472)[0m 2025-06-16 16:58:51,250 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3798472)[0m 2025-06-16 16:58:51,256 - INFO - eval_result: {'eval_loss': 1.0565109252929688, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9333963990211487, 'eval_AP': 0.9135776406964697, 'eval_MCC': 0.0, 'eval_NDCG': 0.9822685624641742, 'eval_runtime': 3.3003, 'eval_samples_per_second': 24.24, 'eval_steps_per_second': 1.212, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3798472)[0m 2025-06-16 16:58:51,498 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB


Trial train_hpo_f530ffec started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_f530ffec config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                             0 â”‚
â”‚ num_train_epochs                          2 â”‚
â”‚ pos_weight                          6.42755 â”‚
â”‚ weight_decay                        0.18512 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3798472)[0m {'loss': 1.6446, 'grad_norm': 2.8070597648620605, 'learning_rate': 2.7541361839643625e-05, 'epoch': 1.0}

Trial train_hpo_2d5eb257 errored after 0 iterations at 2025-06-16 16:58:34. Total running time: 1min 4s
Error file: /tmp/ray/session_2025-06-16_16-42-25_595113_3771642/artifacts/2025-06-16_16-57-30/train_hpo_2025-06-16_16-57-30/driver_artifacts/train_hpo_2d5eb257_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-58-07/error.txt
[36m(train_hpo pid=3798679)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=8, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=2, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3798472)[0m {'loss': 1.1461, 'grad_norm': 1.8336951732635498, 'learning_rate': 1.5022561003441977e-05, 'epoch': 2.0}

Trial train_hpo_ab313185 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_ab313185 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         5e-05 â”‚
â”‚ num_train_epochs                          6 â”‚
â”‚ pos_weight                          7.44006 â”‚
â”‚ weight_decay                        0.16302 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3798979)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})

Trial train_hpo_ab313185 errored after 0 iterations at 2025-06-16 16:58:46. Total running time: 1min 16s
Error file: /tmp/ray/session_2025-06-16_16-42-25_595113_3771642/artifacts/2025-06-16_16-57-30/train_hpo_2025-06-16_16-57-30/driver_artifacts/train_hpo_ab313185_9_learning_rate=0.0000,num_train_epochs=6,pos_weight=7.4401,weight_decay=0.1630_2025-06-16_16-58-31/error.txt
[36m(train_hpo pid=3798472)[0m {'loss': 0.9807, 'grad_norm': 2.3817687034606934, 'learning_rate': 2.5037601672403296e-06, 'epoch': 3.0}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3798472)[0m {'train_runtime': 21.2443, 'train_samples_per_second': 63.641, 'train_steps_per_second': 0.753, 'train_loss': 1.2438958585262299, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3798472)[0m STATE at ending of training  :  TrainerState(epoch=3.235294117647059, global_step=16, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=287840910133248.0, log_history=[{'loss': 1.6446, 'grad_norm': 2.8070597648620605, 'learning_rate': 2.7541361839643625e-05, 'epoch': 1.0, 'step': 5}, {'loss': 1.1461, 'grad_norm': 1.8336951732635498, 'learning_rate': 1.5022561003441977e-05, 'epoch': 2.0, 'step': 10}, {'loss': 0.9807, 'grad_norm': 2.3817687034606934, 'learning_rate': 2.5037601672403296e-06, 'epoch': 3.0, 'step': 15}, {'loss': 1.0455, 'grad_norm': 5.139391899108887, 'learning_rate': 0.0, 'epoch': 3.235294117647059, 'step': 16}, {'train_runtime': 21.2443, 'train_samples_per_second': 63.641, 'train_steps_per_second': 0.753, 'total_flos': 287840910133248.0, 'train_loss': 1.2438958585262299, 'epoch': 3.235294117647059, 'step': 16}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3798679)[0m STATE at ending of training  :  TrainerState(epoch=1.7058823529411766, global_step=8, max_steps=8, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=2, num_input_tokens_seen=0, total_flos=152076824549376.0, log_history=[{'loss': 2.2027, 'grad_norm': 9.129045486450195, 'learning_rate': 1.0442639949699175e-06, 'epoch': 1.0, 'step': 5}, {'loss': 2.4088, 'grad_norm': 41.371456146240234, 'learning_rate': 0.0, 'epoch': 1.7058823529411766, 'step': 8}, {'train_runtime': 13.4842, 'train_samples_per_second': 50.133, 'train_steps_per_second': 0.593, 'total_flos': 152076824549376.0, 'train_loss': 2.2800355553627014, 'epoch': 1.7058823529411766, 'step': 8}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3798472)[0m {'eval_loss': 1.0565109252929688, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9333963990211487, 'eval_AP': 0.9135776406964697, 'eval_MCC': 0.0, 'eval_NDCG': 0.9822685624641742, 'eval_runtime': 3.3003, 'eval_samples_per_second': 24.24, 'eval_steps_per_second': 1.212, 'epoch': 3.235294117647059}

Trial train_hpo_717a7ea8 finished iteration 1 at 2025-06-16 16:58:51. Total running time: 1min 21s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_717a7ea8 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    26.1796 â”‚
â”‚ time_total_s                        26.1796 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               3.23529 â”‚
â”‚ eval_AP                             0.91358 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.98227 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           1.05651 â”‚
â”‚ eval_optim_threshold                 0.9334 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.3003 â”‚
â”‚ eval_samples_per_second               24.24 â”‚
â”‚ eval_steps_per_second                 1.212 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯2025-06-16 16:58:51,519 - INFO - Cleaning up trial 717a7ea8
2025-06-16 16:58:51,520 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-57-30/train_hpo_717a7ea8_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.5756,weight_decay=0.2202_2025-06-16_16-58-18
2025-06-16 16:58:51,520 - INFO - Current best: ab09a3c7 with eval_kappa : 0.0 at iteration 1
2025-06-16 16:58:51,520 - INFO - Current best: 6cb74c18 with eval_kappa : 0.0 at iteration 1
2025-06-16 16:58:52,451 - INFO - Cleaning up trial f530ffec
2025-06-16 16:58:52,452 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-57-30/train_hpo_f530ffec_8_learning_rate=0.0000,num_train_epochs=2,pos_weight=6.4276,weight_decay=0.1851_2025-06-16_16-58-25
2025-06-16 16:58:52,452 - INFO - Current best: ab09a3c7 with eval_kappa : 0.0 at iteration 1
2025-06-16 16:58:52,452 - INFO - Current best: 6cb74c18 with eval_kappa : 0.0 at iteration 1
2025-06-16 16:58:52,452 - INFO - Current best: 717a7ea8 with eval_kappa : 0.0 at iteration 1
[36m(train_hpo pid=3799265)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3799265)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3799265)[0m 2025-06-16 16:58:54,191 - INFO - pos_weight value in TrainingArguments : 5.904350112349562
[36m(train_hpo pid=3799265)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3799265)[0m   super().__init__(*args, **kwargs)


Trial train_hpo_717a7ea8 completed after 1 iterations at 2025-06-16 16:58:51. Total running time: 1min 21s
[36m(train_hpo pid=3798679)[0m {'loss': 2.4088, 'grad_norm': 41.371456146240234, 'learning_rate': 0.0, 'epoch': 1.7058823529411766}[32m [repeated 2x across cluster][0m

Trial train_hpo_f530ffec finished iteration 1 at 2025-06-16 16:58:52. Total running time: 1min 22s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_f530ffec result              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                          â”‚
â”‚ time_this_iter_s                     20.5524 â”‚
â”‚ time_total_s                         20.5524 â”‚
â”‚ training_iteration                         1 â”‚
â”‚ epoch                                1.70588 â”‚
â”‚ eval_AP                              0.75841 â”‚
â”‚ eval_MCC                            -0.06712 â”‚
â”‚ eval_NDCG                            0.89519 â”‚
â”‚ eval_accuracy                          0.725 â”‚
â”‚ eval_f1                              0.84058 â”‚
â”‚ eval_kappa                          -0.02445 â”‚
â”‚ eval_loss                            2.85918 â”‚
â”‚ eval_optim_threshold                 0.58815 â”‚
â”‚ eval_precision                       0.73418 â”‚
â”‚ eval_recall                          0.98305 â”‚
â”‚ eval_runtime                          3.3158 â”‚
â”‚ eval_samples_per_second               24.127 â”‚
â”‚ eval_steps_per_second                  1.206 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_f530ffec completed after 1 iterations at 2025-06-16 16:58:52. Total running time: 1min 22s

Trial train_hpo_f5e70b7f started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_f5e70b7f config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         1e-05 â”‚
â”‚ num_train_epochs                          3 â”‚
â”‚ pos_weight                          5.90435 â”‚
â”‚ weight_decay                        0.28664 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3799265)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=3, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3798679)[0m {'train_runtime': 13.4842, 'train_samples_per_second': 50.133, 'train_steps_per_second': 0.593, 'train_loss': 2.2800355553627014, 'epoch': 1.7058823529411766}

Trial train_hpo_bd9ce088 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_bd9ce088 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         3e-05 â”‚
â”‚ num_train_epochs                          6 â”‚
â”‚ pos_weight                          6.72481 â”‚
â”‚ weight_decay                        0.00109 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 5 ERROR | 4 TERMINATED | 2 RUNNING | 1 PENDING
Current time: 2025-06-16 16:59:00. Total running time: 1min 30s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_f5e70b7f   RUNNING           5.90435       6.78644e-06       0.286643                      3                                                                                        â”‚
â”‚ train_hpo_bd9ce088   RUNNING           6.72481       3.23119e-05       0.00108909                    6                                                                                        â”‚
â”‚ train_hpo_ab09a3c7   TERMINATED        6.09408       4.55539e-06       0.123031                      5        1            36.9113       1.60581    0.848921            0.7375       0        â”‚
â”‚ train_hpo_6cb74c18   TERMINATED        7.18321       7.98818e-05       0.251217                      3        1            21.4078       1.02121    0.848921            0.7375       0        â”‚
â”‚ train_hpo_717a7ea8   TERMINATED        7.57559       4.00602e-05       0.220208                      4        1            26.1796       1.05651    0.848921            0.7375       0        â”‚
â”‚ train_hpo_f530ffec   TERMINATED        6.42755       2.7847e-06        0.185124                      2        1            20.5524       2.85918    0.84058             0.725       -0.024447 â”‚
â”‚ train_hpo_bd333f33   PENDING           3.50937       2.07214e-05       0.263741                      4                                                                                        â”‚
â”‚ train_hpo_626b5182   ERROR             6.82842       1.49561e-06       0.13641                       6                                                                                        â”‚
â”‚ train_hpo_a4a6972c   ERROR             7.43106       1.10121e-06       0.13345                       4                                                                                        â”‚
â”‚ train_hpo_70e050f9   ERROR             2.2031        4.03208e-05       0.243719                      5                                                                                        â”‚
â”‚ train_hpo_2d5eb257   ERROR             4.0662        2.70039e-05       0.239866                      3                                                                                        â”‚
â”‚ train_hpo_ab313185   ERROR             7.44006       4.73492e-05       0.163021                      6                                                                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[36m(train_hpo pid=3798679)[0m 2025-06-16 16:58:52,076 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3798679)[0m 2025-06-16 16:58:52,082 - INFO - eval_result: {'eval_loss': 2.8591794967651367, 'eval_f1': 0.8405797101449275, 'eval_accuracy': 0.725, 'eval_kappa': -0.024447031431897415, 'eval_precision': 0.7341772151898734, 'eval_recall': 0.9830508474576272, 'eval_optim_threshold': 0.5881478786468506, 'eval_AP': 0.7584109289915963, 'eval_MCC': -0.06712280483550427, 'eval_NDCG': 0.8951938602438716, 'eval_runtime': 3.3158, 'eval_samples_per_second': 24.127, 'eval_steps_per_second': 1.206, 'epoch': 1.7058823529411766}
[36m(train_hpo pid=3798679)[0m 2025-06-16 16:58:52,428 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
[36m(train_hpo pid=3799478)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3799478)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3799478)[0m 2025-06-16 16:59:00,766 - INFO - pos_weight value in TrainingArguments : 6.7248101376462595
[36m(train_hpo pid=3799478)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3799478)[0m   super().__init__(*args, **kwargs)
2025-06-16 16:59:02,884	ERROR tune_controller.py:1331 -- Trial task failed for trial train_hpo_f5e70b7f
Traceback (most recent call last):
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
             ^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/worker.py", line 2782, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/worker.py", line 929, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::ImplicitFunc.train()[39m (pid=3799265, ip=172.30.120.56, actor_id=97f1cbeacc7a7cda9659c47801000000, repr=train_hpo)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/trainable.py", line 330, in train
    raise skipped from exception_cause(skipped)
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/air/_internal/util.py", line 107, in run
    self._ret = self._target(*self._args, **self._kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py", line 45, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py", line 261, in _trainable_func
    output = fn()
             ^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/util.py", line 130, in inner
    return trainable(config, **fn_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/binary_pipeline.py", line 253, in train_hpo
    trainer.train()
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 2241, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 2550, in _inner_training_loop
    if (
RuntimeError: CUDA error: unspecified launch failure
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(train_hpo pid=3799667)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3799667)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3799667)[0m 2025-06-16 16:59:07,041 - INFO - pos_weight value in TrainingArguments : 3.5093706580135486
[36m(train_hpo pid=3799667)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3799667)[0m   super().__init__(*args, **kwargs)


Trial train_hpo_f5e70b7f errored after 0 iterations at 2025-06-16 16:59:02. Total running time: 1min 32s
Error file: /tmp/ray/session_2025-06-16_16-42-25_595113_3771642/artifacts/2025-06-16_16-57-30/train_hpo_2025-06-16_16-57-30/driver_artifacts/train_hpo_f5e70b7f_10_learning_rate=0.0000,num_train_epochs=3,pos_weight=5.9044,weight_decay=0.2866_2025-06-16_16-58-42/error.txt
[36m(train_hpo pid=3798679)[0m {'eval_loss': 2.8591794967651367, 'eval_f1': 0.8405797101449275, 'eval_accuracy': 0.725, 'eval_kappa': -0.024447031431897415, 'eval_precision': 0.7341772151898734, 'eval_recall': 0.9830508474576272, 'eval_optim_threshold': 0.5881478786468506, 'eval_AP': 0.7584109289915963, 'eval_MCC': -0.06712280483550427, 'eval_NDCG': 0.8951938602438716, 'eval_runtime': 3.3158, 'eval_samples_per_second': 24.127, 'eval_steps_per_second': 1.206, 'epoch': 1.7058823529411766}
[36m(train_hpo pid=3799478)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})

Trial train_hpo_bd333f33 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_bd333f33 config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ learning_rate                         2e-05 â”‚
â”‚ num_train_epochs                          4 â”‚
â”‚ pos_weight                          3.50937 â”‚
â”‚ weight_decay                        0.26374 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(train_hpo pid=3799667)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3799478)[0m {'loss': 1.5619, 'grad_norm': 2.576082944869995, 'learning_rate': 2.5580274158205587e-05, 'epoch': 1.0}
[36m(train_hpo pid=3799478)[0m {'loss': 1.1015, 'grad_norm': 2.133225202560425, 'learning_rate': 1.8848623063940963e-05, 'epoch': 2.0}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3799478)[0m {'loss': 0.9103, 'grad_norm': 2.4483282566070557, 'learning_rate': 1.2116971969676332e-05, 'epoch': 3.0}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3799667)[0m {'train_runtime': 21.2793, 'train_samples_per_second': 63.536, 'train_steps_per_second': 0.752, 'train_loss': 0.9593570046126842, 'epoch': 3.235294117647059}
[36m(train_hpo pid=3799667)[0m STATE at ending of training  :  TrainerState(epoch=3.235294117647059, global_step=16, max_steps=16, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=4, num_input_tokens_seen=0, total_flos=287840910133248.0, log_history=[{'loss': 1.2402, 'grad_norm': 2.8739418983459473, 'learning_rate': 1.4245962766850404e-05, 'epoch': 1.0, 'step': 5}, {'loss': 0.8867, 'grad_norm': 1.862663984298706, 'learning_rate': 7.770525145554766e-06, 'epoch': 2.0, 'step': 10}, {'loss': 0.7712, 'grad_norm': 2.3751275539398193, 'learning_rate': 1.2950875242591277e-06, 'epoch': 3.0, 'step': 15}, {'loss': 0.8596, 'grad_norm': 5.450768947601318, 'learning_rate': 0.0, 'epoch': 3.235294117647059, 'step': 16}, {'train_runtime': 21.2793, 'train_samples_per_second': 63.536, 'train_steps_per_second': 0.752, 'total_flos': 287840910133248.0, 'train_loss': 0.9593570046126842, 'epoch': 3.235294117647059, 'step': 16}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3799667)[0m {'loss': 0.8596, 'grad_norm': 5.450768947601318, 'learning_rate': 0.0, 'epoch': 3.235294117647059}[32m [repeated 2x across cluster][0m

Trial status: 6 ERROR | 4 TERMINATED | 2 RUNNING
Current time: 2025-06-16 16:59:30. Total running time: 2min 0s
Logical resource usage: 20.0/32 CPUs, 2.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_bd9ce088   RUNNING           6.72481       3.23119e-05       0.00108909                    6                                                                                        â”‚
â”‚ train_hpo_bd333f33   RUNNING           3.50937       2.07214e-05       0.263741                      4                                                                                        â”‚
â”‚ train_hpo_ab09a3c7   TERMINATED        6.09408       4.55539e-06       0.123031                      5        1            36.9113       1.60581    0.848921            0.7375       0        â”‚
â”‚ train_hpo_6cb74c18   TERMINATED        7.18321       7.98818e-05       0.251217                      3        1            21.4078       1.02121    0.848921            0.7375       0        â”‚
â”‚ train_hpo_717a7ea8   TERMINATED        7.57559       4.00602e-05       0.220208                      4        1            26.1796       1.05651    0.848921            0.7375       0        â”‚
â”‚ train_hpo_f530ffec   TERMINATED        6.42755       2.7847e-06        0.185124                      2        1            20.5524       2.85918    0.84058             0.725       -0.024447 â”‚
â”‚ train_hpo_626b5182   ERROR             6.82842       1.49561e-06       0.13641                       6                                                                                        â”‚
â”‚ train_hpo_a4a6972c   ERROR             7.43106       1.10121e-06       0.13345                       4                                                                                        â”‚
â”‚ train_hpo_70e050f9   ERROR             2.2031        4.03208e-05       0.243719                      5                                                                                        â”‚
â”‚ train_hpo_2d5eb257   ERROR             4.0662        2.70039e-05       0.239866                      3                                                                                        â”‚
â”‚ train_hpo_ab313185   ERROR             7.44006       4.73492e-05       0.163021                      6                                                                                        â”‚
â”‚ train_hpo_f5e70b7f   ERROR             5.90435       6.78644e-06       0.286643                      3                                                                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[36m(train_hpo pid=3799667)[0m 2025-06-16 16:59:32,316 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3799667)[0m 2025-06-16 16:59:32,322 - INFO - eval_result: {'eval_loss': 0.915274441242218, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.811398446559906, 'eval_AP': 0.8074297382439064, 'eval_MCC': 0.0, 'eval_NDCG': 0.9447511923475987, 'eval_runtime': 3.4998, 'eval_samples_per_second': 22.859, 'eval_steps_per_second': 1.143, 'epoch': 3.235294117647059}
2025-06-16 16:59:32,581 - INFO - Cleaning up trial bd333f33
2025-06-16 16:59:32,581 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-57-30/train_hpo_bd333f33_12_learning_rate=0.0000,num_train_epochs=4,pos_weight=3.5094,weight_decay=0.2637_2025-06-16_16-58-59
2025-06-16 16:59:32,581 - INFO - Current best: ab09a3c7 with eval_kappa : 0.0 at iteration 1
2025-06-16 16:59:32,581 - INFO - Current best: 6cb74c18 with eval_kappa : 0.0 at iteration 1
2025-06-16 16:59:32,581 - INFO - Current best: 717a7ea8 with eval_kappa : 0.0 at iteration 1
2025-06-16 16:59:32,581 - INFO - Cleaning up trial f530ffec
2025-06-16 16:59:32,581 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-57-30/train_hpo_f530ffec_8_learning_rate=0.0000,num_train_epochs=2,pos_weight=6.4276,weight_decay=0.1851_2025-06-16_16-58-25
[36m(train_hpo pid=3799667)[0m 2025-06-16 16:59:32,560 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
[36m(train_hpo pid=3799478)[0m 2025-06-16 16:59:39,488 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3799478)[0m 2025-06-16 16:59:39,494 - INFO - eval_result: {'eval_loss': 1.0260967016220093, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9310833215713501, 'eval_AP': 0.8971313408820842, 'eval_MCC': 0.0, 'eval_NDCG': 0.977051659394494, 'eval_runtime': 3.545, 'eval_samples_per_second': 22.567, 'eval_steps_per_second': 1.128, 'epoch': 4.9411764705882355}
2025-06-16 16:59:39,843 - INFO - Cleaning up trial bd9ce088
2025-06-16 16:59:39,844 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-57-30/train_hpo_bd9ce088_11_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.7248,weight_decay=0.0011_2025-06-16_16-58-53
2025-06-16 16:59:39,844 - INFO - Current best: ab09a3c7 with eval_kappa : 0.0 at iteration 1
2025-06-16 16:59:39,844 - INFO - Current best: 6cb74c18 with eval_kappa : 0.0 at iteration 1
2025-06-16 16:59:39,844 - INFO - Current best: 717a7ea8 with eval_kappa : 0.0 at iteration 1
2025-06-16 16:59:39,844 - INFO - Cleaning up trial f530ffec
2025-06-16 16:59:39,844 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-57-30/train_hpo_f530ffec_8_learning_rate=0.0000,num_train_epochs=2,pos_weight=6.4276,weight_decay=0.1851_2025-06-16_16-58-25
2025-06-16 16:59:39,844 - INFO - Current best: bd333f33 with eval_kappa : 0.0 at iteration 1
2025-06-16 16:59:39,854	INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-16_16-57-30' in 0.0084s.

[36m(train_hpo pid=3799667)[0m {'eval_loss': 0.915274441242218, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.811398446559906, 'eval_AP': 0.8074297382439064, 'eval_MCC': 0.0, 'eval_NDCG': 0.9447511923475987, 'eval_runtime': 3.4998, 'eval_samples_per_second': 22.859, 'eval_steps_per_second': 1.143, 'epoch': 3.235294117647059}

Trial train_hpo_bd333f33 finished iteration 1 at 2025-06-16 16:59:32. Total running time: 2min 2s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_bd333f33 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    26.3651 â”‚
â”‚ time_total_s                        26.3651 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               3.23529 â”‚
â”‚ eval_AP                             0.80743 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.94475 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                           0.91527 â”‚
â”‚ eval_optim_threshold                 0.8114 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                         3.4998 â”‚
â”‚ eval_samples_per_second              22.859 â”‚
â”‚ eval_steps_per_second                 1.143 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_bd333f33 completed after 1 iterations at 2025-06-16 16:59:32. Total running time: 2min 2s
[36m(train_hpo pid=3799478)[0m STATE at ending of training  :  TrainerState(epoch=4.9411764705882355, global_step=24, max_steps=24, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=20, num_train_epochs=6, num_input_tokens_seen=0, total_flos=439917734682624.0, log_history=[{'loss': 1.5619, 'grad_norm': 2.576082944869995, 'learning_rate': 2.5580274158205587e-05, 'epoch': 1.0, 'step': 5}, {'loss': 1.1015, 'grad_norm': 2.133225202560425, 'learning_rate': 1.8848623063940963e-05, 'epoch': 2.0, 'step': 10}, {'loss': 0.9103, 'grad_norm': 2.4483282566070557, 'learning_rate': 1.2116971969676332e-05, 'epoch': 3.0, 'step': 15}, {'loss': 0.8122, 'grad_norm': 3.068593978881836, 'learning_rate': 5.3853208754117024e-06, 'epoch': 4.0, 'step': 20}, {'loss': 0.8831, 'grad_norm': 8.329331398010254, 'learning_rate': 0.0, 'epoch': 4.9411764705882355, 'step': 24}, {'train_runtime': 32.7517, 'train_samples_per_second': 61.92, 'train_steps_per_second': 0.733, 'total_flos': 439917734682624.0, 'train_loss': 1.0609290699164073, 'epoch': 4.9411764705882355, 'step': 24}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3799478)[0m {'train_runtime': 32.7517, 'train_samples_per_second': 61.92, 'train_steps_per_second': 0.733, 'train_loss': 1.0609290699164073, 'epoch': 4.9411764705882355}
[36m(train_hpo pid=3799478)[0m {'loss': 0.8831, 'grad_norm': 8.329331398010254, 'learning_rate': 0.0, 'epoch': 4.9411764705882355}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3799478)[0m {'eval_loss': 1.0260967016220093, 'eval_f1': 0.8489208633093526, 'eval_accuracy': 0.7375, 'eval_kappa': 0.0, 'eval_precision': 0.7375, 'eval_recall': 1.0, 'eval_optim_threshold': 0.9310833215713501, 'eval_AP': 0.8971313408820842, 'eval_MCC': 0.0, 'eval_NDCG': 0.977051659394494, 'eval_runtime': 3.545, 'eval_samples_per_second': 22.567, 'eval_steps_per_second': 1.128, 'epoch': 4.9411764705882355}

Trial train_hpo_bd9ce088 finished iteration 1 at 2025-06-16 16:59:39. Total running time: 2min 9s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_hpo_bd9ce088 result             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name                         â”‚
â”‚ time_this_iter_s                    39.8924 â”‚
â”‚ time_total_s                        39.8924 â”‚
â”‚ training_iteration                        1 â”‚
â”‚ epoch                               4.94118 â”‚
â”‚ eval_AP                             0.89713 â”‚
â”‚ eval_MCC                                  0 â”‚
â”‚ eval_NDCG                           0.97705 â”‚
â”‚ eval_accuracy                        0.7375 â”‚
â”‚ eval_f1                             0.84892 â”‚
â”‚ eval_kappa                                0 â”‚
â”‚ eval_loss                            1.0261 â”‚
â”‚ eval_optim_threshold                0.93108 â”‚
â”‚ eval_precision                       0.7375 â”‚
â”‚ eval_recall                               1 â”‚
â”‚ eval_runtime                          3.545 â”‚
â”‚ eval_samples_per_second              22.567 â”‚
â”‚ eval_steps_per_second                 1.128 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_hpo_bd9ce088 completed after 1 iterations at 2025-06-16 16:59:39. Total running time: 2min 9s

Trial status: 6 ERROR | 6 TERMINATED
Current time: 2025-06-16 16:59:39. Total running time: 2min 9s
Logical resource usage: 10.0/32 CPUs, 1.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_accuracy     eval_kappa â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_ab09a3c7   TERMINATED        6.09408       4.55539e-06       0.123031                      5        1            36.9113      1.60581     0.848921            0.7375       0        â”‚
â”‚ train_hpo_6cb74c18   TERMINATED        7.18321       7.98818e-05       0.251217                      3        1            21.4078      1.02121     0.848921            0.7375       0        â”‚
â”‚ train_hpo_717a7ea8   TERMINATED        7.57559       4.00602e-05       0.220208                      4        1            26.1796      1.05651     0.848921            0.7375       0        â”‚
â”‚ train_hpo_f530ffec   TERMINATED        6.42755       2.7847e-06        0.185124                      2        1            20.5524      2.85918     0.84058             0.725       -0.024447 â”‚
â”‚ train_hpo_bd9ce088   TERMINATED        6.72481       3.23119e-05       0.00108909                    6        1            39.8924      1.0261      0.848921            0.7375       0        â”‚
â”‚ train_hpo_bd333f33   TERMINATED        3.50937       2.07214e-05       0.263741                      4        1            26.3651      0.915274    0.848921            0.7375       0        â”‚
â”‚ train_hpo_626b5182   ERROR             6.82842       1.49561e-06       0.13641                       6                                                                                        â”‚
â”‚ train_hpo_a4a6972c   ERROR             7.43106       1.10121e-06       0.13345                       4                                                                                        â”‚
â”‚ train_hpo_70e050f9   ERROR             2.2031        4.03208e-05       0.243719                      5                                                                                        â”‚
â”‚ train_hpo_2d5eb257   ERROR             4.0662        2.70039e-05       0.239866                      3                                                                                        â”‚
â”‚ train_hpo_ab313185   ERROR             7.44006       4.73492e-05       0.163021                      6                                                                                        â”‚
â”‚ train_hpo_f5e70b7f   ERROR             5.90435       6.78644e-06       0.286643                      3                                                                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Number of errored trials: 6
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name             # failures   error file                                                                                                                                                                                                                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_hpo_626b5182              1   /tmp/ray/session_2025-06-16_16-42-25_595113_3771642/artifacts/2025-06-16_16-57-30/train_hpo_2025-06-16_16-57-30/driver_artifacts/train_hpo_626b5182_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=6.8284,weight_decay=0.1364_2025-06-16_16-57-30/error.txt  â”‚
â”‚ train_hpo_a4a6972c              1   /tmp/ray/session_2025-06-16_16-42-25_595113_3771642/artifacts/2025-06-16_16-57-30/train_hpo_2025-06-16_16-57-30/driver_artifacts/train_hpo_a4a6972c_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=7.4311,weight_decay=0.1334_2025-06-16_16-57-49/error.txt  â”‚
â”‚ train_hpo_70e050f9              1   /tmp/ray/session_2025-06-16_16-42-25_595113_3771642/artifacts/2025-06-16_16-57-30/train_hpo_2025-06-16_16-57-30/driver_artifacts/train_hpo_70e050f9_5_learning_rate=0.0000,num_train_epochs=5,pos_weight=2.2031,weight_decay=0.2437_2025-06-16_16-57-56/error.txt  â”‚
â”‚ train_hpo_2d5eb257              1   /tmp/ray/session_2025-06-16_16-42-25_595113_3771642/artifacts/2025-06-16_16-57-30/train_hpo_2025-06-16_16-57-30/driver_artifacts/train_hpo_2d5eb257_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.0662,weight_decay=0.2399_2025-06-16_16-58-07/error.txt  â”‚
â”‚ train_hpo_ab313185              1   /tmp/ray/session_2025-06-16_16-42-25_595113_3771642/artifacts/2025-06-16_16-57-30/train_hpo_2025-06-16_16-57-30/driver_artifacts/train_hpo_ab313185_9_learning_rate=0.0000,num_train_epochs=6,pos_weight=7.4401,weight_decay=0.1630_2025-06-16_16-58-31/error.txt  â”‚
â”‚ train_hpo_f5e70b7f              1   /tmp/ray/session_2025-06-16_16-42-25_595113_3771642/artifacts/2025-06-16_16-57-30/train_hpo_2025-06-16_16-57-30/driver_artifacts/train_hpo_f5e70b7f_10_learning_rate=0.0000,num_train_epochs=3,pos_weight=5.9044,weight_decay=0.2866_2025-06-16_16-58-42/error.txt â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Traceback (most recent call last):
  File "/home/leandre/Projects/BioMoQA_Playground/experiments/biomoqa.py", line 68, in <module>
    main()
  File "/home/leandre/Projects/BioMoQA_Playground/experiments/biomoqa.py", line 54, in main
    pipeline.whole_pipeline()
  File "/home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/binary_pipeline.py", line 631, in whole_pipeline
    avg_ens_metrics=self.run_pipeline()
                    ^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/binary_pipeline.py", line 555, in run_pipeline
    scores_by_fold = self.train(model_name=model_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/binary_pipeline.py", line 348, in train
    analysis = tune.run(
               ^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/tune.py", line 1035, in run
    raise TuneError("Trials did not complete", incomplete_trials)
ray.tune.error.TuneError: ('Trials did not complete', [train_hpo_626b5182, train_hpo_a4a6972c, train_hpo_70e050f9, train_hpo_2d5eb257, train_hpo_ab313185, train_hpo_f5e70b7f])
[36m(train_hpo pid=3799478)[0m 2025-06-16 16:59:39,819 - INFO - Cleared CUDA cache. Memory allocated: 1.35 GB, Memory reserved: 1.59 GB
