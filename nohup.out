2025-06-03 17:19:24,791	INFO worker.py:1843 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
2025-06-03 17:19:25,541 - INFO - Random seeds set to 42
2025-06-03 17:19:25,646 - INFO - Optional negatives loaded from CSV with 5000 entries.
2025-06-03 17:19:25,647 - INFO - Loading original negatives...
2025-06-03 17:19:25,656 - INFO - Negatives column names: ['Article ID', 'Title', 'Author', 'Publication year', 'Title secondary', 'URL', 'DOI', 'Abstract', 'Criteria for exclusion A', ' Criteria for exclusion B', ' Criteria for exclusion C', 'labels', 'Keywords']
2025-06-03 17:19:25,656 - INFO - Loading original positives...
2025-06-03 17:19:25,674 - INFO - Positives column names: ['Article ID', 'Title', 'Author', 'Secondary authors', 'Keywords', 'title of unpublished reference', 'primary date', 'publication year', 'notes', 'reprint status', 'start page number', 'ending page number', 'periodical full name', 'periodical standard abbreviation', 'periodical in which article was published', 'periodical name - user abbreviation 1', 'periodical name - user abbreviation 2', 'volume number', 'issue number', 'title secondary', 'city of publication', 'publisher', 'user definable 1', 'user definable 5', 'title series', 'Abstract', 'ISSN/ISBN', 'availability', 'Misc. 1', 'Misc. 2', 'address', 'Web/URL', 'link to PDF', 'link to full-text', 'related records', 'images', 'DOI', 'labels']
2025-06-03 17:19:25,680 - INFO - Class balance:
labels
1    326
0    123
Name: count, dtype: int64
2025-06-03 17:19:25,680 - INFO -    Article ID  ...  Criteria for exclusion C
0       12959  ...                       NaN
1       13470  ...                       NaN
2        4686  ...                       NaN
3        2503  ...                       NaN
4        2951  ...                       NaN

[5 rows x 44 columns]
2025-06-03 17:19:25,705 - INFO - Original dataset size: 449
2025-06-03 17:19:25,705 - INFO - Optional negatives size: 5000
2025-06-03 17:19:25,710 - INFO - Optional negatives:                                                title  ... labels
0  Towards evidence-based conservation of subterr...  ...     -1
1                  Marine biodiversity conservation.  ...     -1
2  Climate teleconnections modulate global burned...  ...     -1
3  Integrating carbon sequestration and biodivers...  ...     -1
4  Principle, technique and application of grassl...  ...     -1

[5 rows x 7 columns]
2025-06-03 17:19:25,714 - INFO - Combined dataset size: 449
2025-06-03 17:19:25,718 - INFO -                                                title  ... labels
0  Feral pig (Sus scrofa) disturbance facilitates...  ...      1
1  Effects of woody plant diversity on abovegroun...  ...      1
2  Scaling species richness and endemism of tropi...  ...      1
3  Not as the crow flies: Assessing effective iso...  ...      0
4  Species-group concepts and biogeography of the...  ...      1

[5 rows x 5 columns]
2025-06-03 17:19:25,719 - INFO - title        0
abstract     0
Keywords     8
doi         36
labels       0
dtype: int64
2025-06-03 17:19:25,721 - INFO - Total duplicate abstracts: 0
2025-06-03 17:19:25,723 - INFO - Empty DataFrame
Columns: [abstract, labels, Keywords]
Index: []
2025-06-03 17:19:25,725 - INFO - Abstracts appearing in both classes: 0
2025-06-03 17:19:25,725 - INFO - Empty DataFrame
Columns: [title, labels]
Index: []
2025-06-03 17:19:25,727 - INFO - Total duplicate abstracts: 0
2025-06-03 17:19:25,728 - INFO - Empty DataFrame
Columns: [abstract, labels, Keywords]
Index: []
2025-06-03 17:19:25,733 - INFO - Abstracts appearing in both classes: 0
2025-06-03 17:19:25,734 - INFO - Empty DataFrame
Columns: [abstract, labels]
Index: []
2025-06-03 17:19:25,735 - INFO - Total duplicate abstracts: 18
2025-06-03 17:19:25,740 - INFO -                                               abstract  ...                                           Keywords
147  1. How could identical species appear in widel...  ...                                                   
253  Aims\r\n Developing plant conservation strateg...  ...  AFLP; genetic diversity; Indian Ocean; limited...
206  Aims Developing plant conservation strategies ...  ...  AFLP; Genetic diversity; Indian Ocean; Limited...
217  Coastal lagoons are considered one of the most...  ...                                                   
213  Coastal lagoons are considered one of the most...  ...                                                   
21   Distribution patterns of indigenous non-volant...  ...  Australian islands; Extreme-value function; Is...
300  Distribution patterns of indigenous non-volant...  ...  island mammals; Australian islands; species-ar...
197  Invasive plant species pose serious threats to...  ...                                                   
35   Island bat species are disproportionately at r...  ...  Hawaiian hoary bat; Hawai?i; Population geneti...
157  Island bat species are disproportionately at r...  ...  Bats; Endangered species; Hawai<sup>‚Äò</sup>i; ...
126  Islands are hotspots of biodiversity and extin...  ...  Deforestation; Endemicity; Extinction; Island ...
276  Islands are hotspots of biodiversity and extin...  ...  Deforestation; Endemicity; Extinction; Island ...
364  KELLY, A. B. (Department of Environmental Scie...  ...                                                   
329  Summary o 1. How could identical species appea...  ...                                                   
278  The Galapagos Islands are recognized for their...  ...                                                   
149  The Gal√°pagos Islands are recognized for their...  ...                                                   
313  Working in the Galapagos Islands and surroundi...  ...                                                   
280  Working in the Gal√°pagos Islands and surroundi...  ...                                                   

[18 rows x 3 columns]
2025-06-03 17:19:25,741 - INFO - Abstracts appearing in both classes: 0
2025-06-03 17:19:25,742 - INFO - Empty DataFrame
Columns: [doi, labels]
Index: []
2025-06-03 17:19:26,044 - INFO - Cleaned dataset size: 397
2025-06-03 17:19:26,045 - INFO - Numnber of positives : 293
2025-06-03 17:19:26,045 - INFO - Numnber of negatives : 104
2025-06-03 17:19:26,046 - INFO - clean_og_df indices : RangeIndex(start=0, stop=397, step=1)
2025-06-03 17:19:26,046 - INFO - opt_neg_df indices : Index([], dtype='int64')
2025-06-03 17:19:26,052 - INFO - Fold 1:
2025-06-03 17:19:26,052 - INFO -   Train label distribution: {1: 0.7373737373737373, 0: 0.26262626262626265}
2025-06-03 17:19:26,052 - INFO -   Test label distribution: {1: 0.7368421052631579, 0: 0.2631578947368421}
2025-06-03 17:19:26,055 - INFO - Fold 2:
2025-06-03 17:19:26,055 - INFO -   Train label distribution: {1: 0.7373737373737373, 0: 0.26262626262626265}
2025-06-03 17:19:26,055 - INFO -   Test label distribution: {1: 0.7424242424242424, 0: 0.25757575757575757}
2025-06-03 17:19:26,058 - INFO - Fold 3:
2025-06-03 17:19:26,058 - INFO -   Train label distribution: {1: 0.7373737373737373, 0: 0.26262626262626265}
2025-06-03 17:19:26,058 - INFO -   Test label distribution: {1: 0.7348484848484849, 0: 0.26515151515151514}
2025-06-03 17:19:26,061 - INFO - Fold 1:
2025-06-03 17:19:26,061 - INFO -   Train label distribution: {1: 0.7373737373737373, 0: 0.26262626262626265}
2025-06-03 17:19:26,061 - INFO -   Test label distribution: {1: 0.7368421052631579, 0: 0.2631578947368421}
2025-06-03 17:19:26,064 - INFO - Fold 2:
2025-06-03 17:19:26,064 - INFO -   Train label distribution: {1: 0.7373737373737373, 0: 0.26262626262626265}
2025-06-03 17:19:26,064 - INFO -   Test label distribution: {1: 0.7424242424242424, 0: 0.25757575757575757}
2025-06-03 17:19:26,067 - INFO - Fold 3:
2025-06-03 17:19:26,067 - INFO -   Train label distribution: {1: 0.7373737373737373, 0: 0.26262626262626265}
2025-06-03 17:19:26,067 - INFO -   Test label distribution: {1: 0.7348484848484849, 0: 0.26515151515151514}
Stringifying the column:   0%|          | 0/397 [00:00<?, ? examples/s]Stringifying the column: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 397/397 [00:00<00:00, 71548.09 examples/s]
Casting to class labels:   0%|          | 0/397 [00:00<?, ? examples/s]Casting to class labels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 397/397 [00:00<00:00, 79198.04 examples/s]
2025-06-03 17:19:26,098 - INFO - Number of positives : 293
2025-06-03 17:19:26,098 - INFO - Number of negatives : 104
2025-06-03 17:19:26,103 - INFO - Confusion matrix: TN=0, FP=35, FN=0, TP=98
2025-06-03 17:19:29,614 - INFO - Metrics: {'f1': 0.8484848484848485, 'recall': 1.0, 'precision': 0.7368421052631579, 'accuracy': 0.7368421052631579, 'AP': 0.7368421052631579, 'MCC': 0.0, 'NDCG': 0.9189307109272616, 'kappa': 0.0, 'TN': 0, 'FP': 35, 'FN': 0, 'TP': 98}
2025-06-03 17:19:29,617 - INFO - Confusion matrix: TN=35, FP=0, FN=98, TP=0
/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-03 17:19:32,869 - INFO - Metrics: {'f1': 0.0, 'recall': 0.0, 'precision': 0.0, 'accuracy': 0.2631578947368421, 'AP': 0.7368421052631579, 'MCC': 0.0, 'NDCG': 0.9189307109272616, 'kappa': 0.0, 'TN': 35, 'FP': 0, 'FN': 98, 'TP': 0}
2025-06-03 17:19:32,874 - INFO - Confusion matrix: TN=0, FP=34, FN=0, TP=98
2025-06-03 17:19:35,647 - INFO - Metrics: {'f1': 0.8521739130434782, 'recall': 1.0, 'precision': 0.7424242424242424, 'accuracy': 0.7424242424242424, 'AP': 0.7424242424242424, 'MCC': 0.0, 'NDCG': 0.9208012714375936, 'kappa': 0.0, 'TN': 0, 'FP': 34, 'FN': 0, 'TP': 98}
2025-06-03 17:19:35,650 - INFO - Confusion matrix: TN=34, FP=0, FN=98, TP=0
/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-03 17:19:38,414 - INFO - Metrics: {'f1': 0.0, 'recall': 0.0, 'precision': 0.0, 'accuracy': 0.25757575757575757, 'AP': 0.7424242424242424, 'MCC': 0.0, 'NDCG': 0.9208012714375936, 'kappa': 0.0, 'TN': 34, 'FP': 0, 'FN': 98, 'TP': 0}
2025-06-03 17:19:38,418 - INFO - Confusion matrix: TN=0, FP=35, FN=0, TP=97
2025-06-03 17:19:41,304 - INFO - Metrics: {'f1': 0.8471615720524017, 'recall': 1.0, 'precision': 0.7348484848484849, 'accuracy': 0.7348484848484849, 'AP': 0.7348484848484849, 'MCC': 0.0, 'NDCG': 0.9181159076123374, 'kappa': 0.0, 'TN': 0, 'FP': 35, 'FN': 0, 'TP': 97}
2025-06-03 17:19:41,308 - INFO - Confusion matrix: TN=35, FP=0, FN=97, TP=0
/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
2025-06-03 17:19:44,260 - INFO - Metrics: {'f1': 0.0, 'recall': 0.0, 'precision': 0.0, 'accuracy': 0.26515151515151514, 'AP': 0.7348484848484849, 'MCC': 0.0, 'NDCG': 0.9181159076123374, 'kappa': 0.0, 'TN': 35, 'FP': 0, 'FN': 97, 'TP': 0}
2025-06-03 17:19:44,263 - INFO - Pipeline for loss type None and ensemble=True
2025-06-03 17:19:44,263 - INFO - with_title : True
2025-06-03 17:19:44,263 - INFO - with_keywords : True
2025-06-03 17:19:44,263 - INFO - fold indexes for run no.1: [[159, 206, 117, 82, 317, 330, 131, 380, 183, 158, 213, 260, 155, 332, 303, 269, 40, 232, 314, 244, 168, 218, 254, 100, 3, 235, 105, 243, 352, 394, 196, 223, 230, 307, 342, 289, 135, 7, 189, 134, 78, 133, 12, 375, 109, 46, 62, 393, 167, 151, 387, 374, 276, 323, 132, 319, 114, 176, 322, 263, 258, 266, 250, 329, 309, 367, 24, 229, 370, 211, 228, 346, 115, 392, 87, 88, 81, 343, 253, 278, 43, 333, 28, 80, 191, 10, 378, 388, 225, 363, 136, 104, 356, 8, 57, 162, 220, 391, 139, 386, 282, 70, 61, 170, 102, 296, 64, 35, 4, 251, 279, 44, 373, 129, 236, 327, 187, 68, 245, 215, 18, 42, 116, 212, 376, 148, 126, 27, 252, 173, 103, 336, 209, 199, 169, 283, 32, 246, 292, 210, 247, 141, 73, 194, 59, 385, 354, 51, 305, 200, 344, 179, 178, 355, 313, 112, 291, 23, 328, 130, 315, 181, 138, 94, 95, 121, 207, 175, 295, 321, 34, 300, 262, 33, 341, 54, 299, 48, 30, 204, 123, 331, 301, 150, 157, 265, 14, 53, 396, 242, 377, 366, 93, 214, 83, 52, 6, 188], [177, 268, 97, 248, 298, 320, 224, 137, 161, 145, 339, 98, 39, 66, 17, 325, 226, 91, 348, 67, 55, 237, 273, 353, 381, 261, 31, 2, 290, 107, 38, 113, 120, 1, 222, 84, 358, 202, 63, 337, 92, 99, 144, 256, 19, 171, 219, 285, 274, 174, 118, 233, 156, 324, 284, 190, 255, 357, 205, 111, 72, 384, 294, 71, 163, 217], array([  0,   5,   9,  11,  13,  15,  16,  20,  21,  22,  25,  26,  29,
        36,  37,  41,  45,  47,  49,  50,  56,  58,  60,  65,  69,  74,
        75,  76,  77,  79,  85,  86,  89,  90,  96, 101, 106, 108, 110,
       119, 122, 124, 125, 127, 128, 140, 142, 143, 146, 147, 149, 152,
       153, 154, 160, 164, 165, 166, 172, 180, 182, 184, 185, 186, 192,
       193, 195, 197, 198, 201, 203, 208, 216, 221, 227, 231, 234, 238,
       239, 240, 241, 249, 257, 259, 264, 267, 270, 271, 272, 275, 277,
       280, 281, 286, 287, 288, 293, 297, 302, 304, 306, 308, 310, 311,
       312, 316, 318, 326, 334, 335, 338, 340, 345, 347, 349, 350, 351,
       359, 360, 361, 362, 364, 365, 368, 369, 371, 372, 379, 382, 383,
       389, 390, 395])]
2025-06-03 17:19:44,263 - INFO - Run no 1/2
2025-06-03 17:19:44,263 - INFO - Loss Type : BCE
2025-06-03 17:19:44,263 - INFO - Ensemble learning pipeline
2025-06-03 17:19:44,263 - INFO - Training model 1/2: dmis-lab/biobert-v1.1
2025-06-03 17:19:44,644 - INFO - 
fold number 1 / 3
2025-06-03 17:19:44,650 - INFO - train split size : 198
2025-06-03 17:19:44,650 - INFO - dev split size : 66
2025-06-03 17:19:44,650 - INFO - test split size : 133
Map (num_proc=32):   0%|          | 0/198 [00:00<?, ? examples/s]Map (num_proc=32):   4%|‚ñé         | 7/198 [00:00<00:03, 48.26 examples/s]Map (num_proc=32):  18%|‚ñà‚ñä        | 35/198 [00:00<00:01, 151.76 examples/s]Map (num_proc=32):  30%|‚ñà‚ñà‚ñà       | 60/198 [00:00<00:00, 186.86 examples/s]Map (num_proc=32):  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/198 [00:00<00:00, 223.35 examples/s]Map (num_proc=32):  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/198 [00:00<00:00, 239.55 examples/s]Map (num_proc=32):  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/198 [00:00<00:00, 256.99 examples/s]Map (num_proc=32):  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 186/198 [00:00<00:00, 276.99 examples/s]Map (num_proc=32): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:00<00:00, 213.01 examples/s]
Map (num_proc=32):   0%|          | 0/66 [00:00<?, ? examples/s]Map (num_proc=32):   5%|‚ñç         | 3/66 [00:00<00:02, 25.27 examples/s]Map (num_proc=32):  18%|‚ñà‚ñä        | 12/66 [00:00<00:00, 55.83 examples/s]Map (num_proc=32):  30%|‚ñà‚ñà‚ñà       | 20/66 [00:00<00:00, 64.88 examples/s]Map (num_proc=32):  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 28/66 [00:00<00:00, 67.56 examples/s]Map (num_proc=32):  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 36/66 [00:00<00:00, 70.21 examples/s]Map (num_proc=32):  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 44/66 [00:00<00:00, 72.90 examples/s]Map (num_proc=32):  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 52/66 [00:00<00:00, 73.18 examples/s]Map (num_proc=32):  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 60/66 [00:00<00:00, 72.56 examples/s]Map (num_proc=32): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:01<00:00, 63.32 examples/s]
Map (num_proc=32):   0%|          | 0/133 [00:00<?, ? examples/s]Map (num_proc=32):   4%|‚ñç         | 5/133 [00:00<00:03, 37.24 examples/s]Map (num_proc=32):  15%|‚ñà‚ñå        | 20/133 [00:00<00:01, 93.30 examples/s]Map (num_proc=32):  31%|‚ñà‚ñà‚ñà       | 41/133 [00:00<00:00, 136.56 examples/s]Map (num_proc=32):  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 65/133 [00:00<00:00, 162.54 examples/s]Map (num_proc=32):  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 85/133 [00:00<00:00, 170.05 examples/s]Map (num_proc=32):  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 105/133 [00:00<00:00, 163.92 examples/s]Map (num_proc=32):  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 125/133 [00:00<00:00, 172.02 examples/s]Map (num_proc=32): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 133/133 [00:00<00:00, 141.55 examples/s]
2025-06-03 17:19:49,879 - INFO - 3 datasets tokenized successfully
2025-06-03 17:19:49,882 - INFO - Starting hyperparameter search for BCE loss
[36m(train_hpo pid=3197549)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3197549)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3197549)[0m 2025-06-03 17:19:59,540 - INFO - pos_weight value in TrainingArguments : 8.493688290834637
[36m(train_hpo pid=3197549)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:106: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3197549)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3197549)[0m /home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2708: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
[36m(train_hpo pid=3197549)[0m   warnings.warn(
[36m(train_hpo pid=3197713)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3197713)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3197713)[0m 2025-06-03 17:20:06,876 - INFO - pos_weight value in TrainingArguments : 7.549531688595925
[36m(train_hpo pid=3197713)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:106: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3197713)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3197713)[0m /home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2708: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
[36m(train_hpo pid=3197713)[0m   warnings.warn(
[36m(train_hpo pid=3197969)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3197969)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3197969)[0m 2025-06-03 17:20:14,364 - INFO - pos_weight value in TrainingArguments : 8.949837496427758
[36m(train_hpo pid=3197969)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:106: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3197969)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3197969)[0m /home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2708: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
[36m(train_hpo pid=3197969)[0m   warnings.warn(
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Configuration for experiment     train_hpo_2025-06-03_17-19-50   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Search algorithm                 SearchGenerator                 ‚îÇ
‚îÇ Scheduler                        AsyncHyperBandScheduler         ‚îÇ
‚îÇ Number of trials                 12                              ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

View detailed results here: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-03_17-19-50
To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-06-03_17-19-23_431813_3194092/artifacts/2025-06-03_17-19-50/train_hpo_2025-06-03_17-19-50/driver_artifacts`

Trial status: 1 PENDING
Current time: 2025-06-03 17:19:51. Total running time: 0s
Logical resource usage: 0/32 CPUs, 0/3 GPUs (0.0/1.0 accelerator_type:A100D)
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial name           status       pos_weight     learning_rate     weight_decay     num_train_epochs ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ train_hpo_dfc200b7   PENDING         8.49369       1.49561e-06          0.13641                    6 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

Trial train_hpo_dfc200b7 started with configuration:
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_dfc200b7 config             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ learning_rate                             0 ‚îÇ
‚îÇ num_train_epochs                          6 ‚îÇ
‚îÇ pos_weight                          8.49369 ‚îÇ
‚îÇ weight_decay                        0.13641 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
[36m(train_hpo pid=3197549)[0m [2025-06-03 17:19:59,824] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(train_hpo pid=3197549)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=6, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})

Trial train_hpo_cdf89bf1 started with configuration:
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_cdf89bf1 config             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ learning_rate                             0 ‚îÇ
‚îÇ num_train_epochs                          5 ‚îÇ
‚îÇ pos_weight                          7.54953 ‚îÇ
‚îÇ weight_decay                        0.12303 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
[36m(train_hpo pid=3197713)[0m [2025-06-03 17:20:07,275] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(train_hpo pid=3197549)[0m {'loss': 4.1515, 'grad_norm': 46.98078536987305, 'learning_rate': 1.246338876535363e-06, 'epoch': 0.7272727272727273}
[36m(train_hpo pid=3197713)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=10, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=5, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3197549)[0m {'loss': 4.0073, 'grad_norm': 43.4157600402832, 'learning_rate': 9.970711012282902e-07, 'epoch': 1.7272727272727273}

Trial train_hpo_362470e0 started with configuration:
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_362470e0 config             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ learning_rate                         8e-05 ‚îÇ
‚îÇ num_train_epochs                          3 ‚îÇ
‚îÇ pos_weight                          8.94984 ‚îÇ
‚îÇ weight_decay                        0.25122 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
[36m(train_hpo pid=3197969)[0m [2025-06-03 17:20:14,604] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(train_hpo pid=3197969)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=6, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=3, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3197713)[0m {'loss': 4.8644, 'grad_norm': 52.7984504699707, 'learning_rate': 3.6443132246884782e-06, 'epoch': 0.7272727272727273}

Trial status: 3 RUNNING | 1 PENDING
Current time: 2025-06-03 17:20:21. Total running time: 30s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial name           status       pos_weight     learning_rate     weight_decay     num_train_epochs ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ train_hpo_dfc200b7   RUNNING         8.49369       1.49561e-06         0.13641                     6 ‚îÇ
‚îÇ train_hpo_cdf89bf1   RUNNING         7.54953       4.55539e-06         0.123031                    5 ‚îÇ
‚îÇ train_hpo_362470e0   RUNNING         8.94984       7.98818e-05         0.251217                    3 ‚îÇ
‚îÇ train_hpo_4e37bbde   PENDING         9.2685        1.10121e-06         0.13345                     4 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ[36m(train_hpo pid=3197969)[0m /home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2708: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
[36m(train_hpo pid=3197969)[0m   warnings.warn(
[36m(train_hpo pid=3197969)[0m 2025-06-03 17:20:34,240 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3197969)[0m 2025-06-03 17:20:34,242 - INFO - eval_result: {'eval_loss': 1.0736280679702759, 'eval_f1': 0.8521739130434782, 'eval_recall': 1.0, 'eval_accuracy': 0.7424242424242424, 'eval_precision': 0.7424242424242424, 'eval_optim_threshold': 0.9349640607833862, 'eval_runtime': 3.3443, 'eval_samples_per_second': 19.735, 'eval_steps_per_second': 1.196, 'epoch': 2.7272727272727275}
[36m(train_hpo pid=3197969)[0m 2025-06-03 17:20:34,277 - INFO - Cleared CUDA cache. Memory allocated: 1.33 GB, Memory reserved: 1.58 GB
2025-06-03 17:20:34,303 - INFO - Cleaning up trial 362470e0
2025-06-03 17:20:34,303 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-03_17-19-50/train_hpo_362470e0_3_learning_rate=0.0001,num_train_epochs=3,pos_weight=8.9498,weight_decay=0.2512_2025-06-03_17-20-05
[36m(train_hpo pid=3198804)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3198804)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3198804)[0m 2025-06-03 17:20:42,577 - INFO - pos_weight value in TrainingArguments : 9.268502695024392
[36m(train_hpo pid=3198804)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:106: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3198804)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3198804)[0m /home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2708: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
[36m(train_hpo pid=3198804)[0m   warnings.warn(

[36m(train_hpo pid=3197969)[0m {'loss': 1.7514, 'grad_norm': 11.635847091674805, 'learning_rate': 2.6627264875937445e-05, 'epoch': 1.7272727272727273}[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(train_hpo pid=3197969)[0m {'train_runtime': 12.9869, 'train_samples_per_second': 45.738, 'train_steps_per_second': 0.462, 'train_loss': 2.0894586642583213, 'epoch': 2.7272727272727275}
[36m(train_hpo pid=3197969)[0m STATE at ending of training  :  TrainerState(epoch=2.7272727272727275, global_step=6, max_steps=6, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=3, num_input_tokens_seen=0, total_flos=139973824671744.0, log_history=[{'loss': 3.2642, 'grad_norm': 31.188371658325195, 'learning_rate': 5.325452975187489e-05, 'epoch': 0.7272727272727273, 'step': 2}, {'loss': 1.7514, 'grad_norm': 11.635847091674805, 'learning_rate': 2.6627264875937445e-05, 'epoch': 1.7272727272727273, 'step': 4}, {'loss': 1.2528, 'grad_norm': 1.9327415227890015, 'learning_rate': 0.0, 'epoch': 2.7272727272727275, 'step': 6}, {'train_runtime': 12.9869, 'train_samples_per_second': 45.738, 'train_steps_per_second': 0.462, 'total_flos': 139973824671744.0, 'train_loss': 2.0894586642583213, 'epoch': 2.7272727272727275, 'step': 6}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': True, 'should_epoch_stop': False, 'should_save': True, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3197969)[0m {'loss': 1.2528, 'grad_norm': 1.9327415227890015, 'learning_rate': 0.0, 'epoch': 2.7272727272727275}[32m [repeated 3x across cluster][0m
[36m(train_hpo pid=3197969)[0m {'eval_loss': 1.0736280679702759, 'eval_f1': 0.8521739130434782, 'eval_recall': 1.0, 'eval_accuracy': 0.7424242424242424, 'eval_precision': 0.7424242424242424, 'eval_optim_threshold': 0.9349640607833862, 'eval_runtime': 3.3443, 'eval_samples_per_second': 19.735, 'eval_steps_per_second': 1.196, 'epoch': 2.7272727272727275}

Trial train_hpo_362470e0 finished iteration 1 at 2025-06-03 17:20:34. Total running time: 43s
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_362470e0 result             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ checkpoint_dir_name                         ‚îÇ
‚îÇ time_this_iter_s                    20.9872 ‚îÇ
‚îÇ time_total_s                        20.9872 ‚îÇ
‚îÇ training_iteration                        1 ‚îÇ
‚îÇ epoch                               2.72727 ‚îÇ
‚îÇ eval_accuracy                       0.74242 ‚îÇ
‚îÇ eval_f1                             0.85217 ‚îÇ
‚îÇ eval_loss                           1.07363 ‚îÇ
‚îÇ eval_optim_threshold                0.93496 ‚îÇ
‚îÇ eval_precision                      0.74242 ‚îÇ
‚îÇ eval_recall                               1 ‚îÇ
‚îÇ eval_runtime                         3.3443 ‚îÇ
‚îÇ eval_samples_per_second              19.735 ‚îÇ
‚îÇ eval_steps_per_second                 1.196 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

Trial train_hpo_362470e0 completed after 1 iterations at 2025-06-03 17:20:34. Total running time: 43s
[36m(train_hpo pid=3197713)[0m {'loss': 4.3061, 'grad_norm': 37.91750717163086, 'learning_rate': 1.8221566123442391e-06, 'epoch': 2.7272727272727275}
[36m(train_hpo pid=3197549)[0m {'loss': 3.8707, 'grad_norm': 37.42695999145508, 'learning_rate': 2.4926777530707256e-07, 'epoch': 4.7272727272727275}

Trial train_hpo_4e37bbde started with configuration:
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_4e37bbde config             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ learning_rate                             0 ‚îÇ
‚îÇ num_train_epochs                          4 ‚îÇ
‚îÇ pos_weight                           9.2685 ‚îÇ
‚îÇ weight_decay                        0.13345 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
[36m(train_hpo pid=3198804)[0m [2025-06-03 17:20:42,850] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(train_hpo pid=3197713)[0m {'loss': 4.215, 'grad_norm': 44.47309875488281, 'learning_rate': 9.110783061721196e-07, 'epoch': 3.7272727272727275}
[36m(train_hpo pid=3198804)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=8, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=4, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3197549)[0m {'train_runtime': 43.4422, 'train_samples_per_second': 27.347, 'train_steps_per_second': 0.276, 'train_loss': 3.8288466930389404, 'epoch': 5.7272727272727275}
[36m(train_hpo pid=3197549)[0m STATE at ending of training  :  TrainerState(epoch=5.7272727272727275, global_step=12, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=6, num_input_tokens_seen=0, total_flos=289945779677184.0, log_history=[{'loss': 4.1515, 'grad_norm': 46.98078536987305, 'learning_rate': 1.246338876535363e-06, 'epoch': 0.7272727272727273, 'step': 2}, {'loss': 4.0073, 'grad_norm': 43.4157600402832, 'learning_rate': 9.970711012282902e-07, 'epoch': 1.7272727272727273, 'step': 4}, {'loss': 3.9272, 'grad_norm': 35.4646110534668, 'learning_rate': 7.478033259212177e-07, 'epoch': 2.7272727272727275, 'step': 6}, {'loss': 3.8284, 'grad_norm': 40.80557632446289, 'learning_rate': 4.985355506141451e-07, 'epoch': 3.7272727272727275, 'step': 8}, {'loss': 3.8707, 'grad_norm': 37.42695999145508, 'learning_rate': 2.4926777530707256e-07, 'epoch': 4.7272727272727275, 'step': 10}, {'loss': 3.1881, 'grad_norm': 45.89863586425781, 'learning_rate': 0.0, 'epoch': 5.7272727272727275, 'step': 12}, {'train_runtime': 43.4422, 'train_samples_per_second': 27.347, 'train_steps_per_second': 0.276, 'total_flos': 289945779677184.0, 'train_loss': 3.8288466930389404, 'epoch': 5.7272727272727275, 'step': 12}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': True, 'should_epoch_stop': False, 'should_save': True, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3197713)[0m STATE at ending of training  :  TrainerState(epoch=4.7272727272727275, global_step=10, max_steps=10, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=5, num_input_tokens_seen=0, total_flos=239955128008704.0, log_history=[{'loss': 4.8644, 'grad_norm': 52.7984504699707, 'learning_rate': 3.6443132246884782e-06, 'epoch': 0.7272727272727273, 'step': 2}, {'loss': 4.5577, 'grad_norm': 48.597862243652344, 'learning_rate': 2.7332349185163582e-06, 'epoch': 1.7272727272727273, 'step': 4}, {'loss': 4.3061, 'grad_norm': 37.91750717163086, 'learning_rate': 1.8221566123442391e-06, 'epoch': 2.7272727272727275, 'step': 6}, {'loss': 4.215, 'grad_norm': 44.47309875488281, 'learning_rate': 9.110783061721196e-07, 'epoch': 3.7272727272727275, 'step': 8}, {'loss': 3.226, 'grad_norm': 39.70376968383789, 'learning_rate': 0.0, 'epoch': 4.7272727272727275, 'step': 10}, {'train_runtime': 39.6864, 'train_samples_per_second': 24.946, 'train_steps_per_second': 0.252, 'total_flos': 239955128008704.0, 'train_loss': 4.233835029602051, 'epoch': 4.7272727272727275, 'step': 10}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': True, 'should_epoch_stop': False, 'should_save': True, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})[36m(train_hpo pid=3197549)[0m 2025-06-03 17:20:50,869 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3197549)[0m 2025-06-03 17:20:50,871 - INFO - eval_result: {'eval_loss': 3.042147159576416, 'eval_f1': 0.8521739130434782, 'eval_recall': 1.0, 'eval_accuracy': 0.7424242424242424, 'eval_precision': 0.7424242424242424, 'eval_optim_threshold': 0.6314823031425476, 'eval_runtime': 4.1461, 'eval_samples_per_second': 15.918, 'eval_steps_per_second': 0.965, 'epoch': 5.7272727272727275}
2025-06-03 17:20:50,929 - INFO - Cleaning up trial dfc200b7
2025-06-03 17:20:50,929 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-03_17-19-50/train_hpo_dfc200b7_1_learning_rate=0.0000,num_train_epochs=6,pos_weight=8.4937,weight_decay=0.1364_2025-06-03_17-19-51
2025-06-03 17:20:50,929 - INFO - Current best: 362470e0 with eval_f1 : 0.8521739130434782 at iteration 1
[36m(train_hpo pid=3197549)[0m 2025-06-03 17:20:50,905 - INFO - Cleared CUDA cache. Memory allocated: 1.33 GB, Memory reserved: 1.58 GB
[36m(train_hpo pid=3197713)[0m /home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2708: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3197713)[0m   warnings.warn([32m [repeated 2x across cluster][0m
2025-06-03 17:20:53,851 - INFO - Cleaning up trial cdf89bf1
2025-06-03 17:20:53,851 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-03_17-19-50/train_hpo_cdf89bf1_2_learning_rate=0.0000,num_train_epochs=5,pos_weight=7.5495,weight_decay=0.1230_2025-06-03_17-19-58
2025-06-03 17:20:53,851 - INFO - Current best: dfc200b7 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:20:53,851 - INFO - Current best: 362470e0 with eval_f1 : 0.8521739130434782 at iteration 1
[36m(train_hpo pid=3199260)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3199260)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3197713)[0m 2025-06-03 17:20:53,780 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3197713)[0m 2025-06-03 17:20:53,782 - INFO - eval_result: {'eval_loss': 3.2957334518432617, 'eval_f1': 0.8521739130434782, 'eval_recall': 1.0, 'eval_accuracy': 0.7424242424242424, 'eval_precision': 0.7424242424242424, 'eval_optim_threshold': 0.5802130699157715, 'eval_runtime': 3.3596, 'eval_samples_per_second': 19.645, 'eval_steps_per_second': 1.191, 'epoch': 4.7272727272727275}
[36m(train_hpo pid=3197713)[0m 2025-06-03 17:20:53,826 - INFO - Cleared CUDA cache. Memory allocated: 1.33 GB, Memory reserved: 1.58 GB
[36m(train_hpo pid=3199260)[0m 2025-06-03 17:20:59,599 - INFO - pos_weight value in TrainingArguments : 2.546844052569046
[36m(train_hpo pid=3199260)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:106: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3199260)[0m   super().__init__(*args, **kwargs)

[36m(train_hpo pid=3197713)[0m {'loss': 3.226, 'grad_norm': 39.70376968383789, 'learning_rate': 0.0, 'epoch': 4.7272727272727275}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3197549)[0m {'eval_loss': 3.042147159576416, 'eval_f1': 0.8521739130434782, 'eval_recall': 1.0, 'eval_accuracy': 0.7424242424242424, 'eval_precision': 0.7424242424242424, 'eval_optim_threshold': 0.6314823031425476, 'eval_runtime': 4.1461, 'eval_samples_per_second': 15.918, 'eval_steps_per_second': 0.965, 'epoch': 5.7272727272727275}

Trial train_hpo_dfc200b7 finished iteration 1 at 2025-06-03 17:20:50. Total running time: 59s
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_dfc200b7 result             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ checkpoint_dir_name                         ‚îÇ
‚îÇ time_this_iter_s                    52.3332 ‚îÇ
‚îÇ time_total_s                        52.3332 ‚îÇ
‚îÇ training_iteration                        1 ‚îÇ
‚îÇ epoch                               5.72727 ‚îÇ
‚îÇ eval_accuracy                       0.74242 ‚îÇ
‚îÇ eval_f1                             0.85217 ‚îÇ
‚îÇ eval_loss                           3.04215 ‚îÇ
‚îÇ eval_optim_threshold                0.63148 ‚îÇ
‚îÇ eval_precision                      0.74242 ‚îÇ
‚îÇ eval_recall                               1 ‚îÇ
‚îÇ eval_runtime                         4.1461 ‚îÇ
‚îÇ eval_samples_per_second              15.918 ‚îÇ
‚îÇ eval_steps_per_second                 0.965 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

Trial train_hpo_dfc200b7 completed after 1 iterations at 2025-06-03 17:20:50. Total running time: 59s

Trial status: 2 TERMINATED | 2 RUNNING | 1 PENDING
Current time: 2025-06-03 17:20:51. Total running time: 1min 0s
Logical resource usage: 20.0/32 CPUs, 2.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_recall     eval_accuracy ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ train_hpo_cdf89bf1   RUNNING           7.54953       4.55539e-06         0.123031                    5                                                                                         ‚îÇ
‚îÇ train_hpo_4e37bbde   RUNNING           9.2685        1.10121e-06         0.13345                     4                                                                                         ‚îÇ
‚îÇ train_hpo_dfc200b7   TERMINATED        8.49369       1.49561e-06         0.13641                     6        1            52.3332       3.04215    0.852174               1          0.742424 ‚îÇ
‚îÇ train_hpo_362470e0   TERMINATED        8.94984       7.98818e-05         0.251217                    3        1            20.9872       1.07363    0.852174               1          0.742424 ‚îÇ
‚îÇ train_hpo_4c09466a   PENDING           2.54684       4.03208e-05         0.243719                    5                                                                                         ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
[36m(train_hpo pid=3197713)[0m {'train_runtime': 39.6864, 'train_samples_per_second': 24.946, 'train_steps_per_second': 0.252, 'train_loss': 4.233835029602051, 'epoch': 4.7272727272727275}

Trial train_hpo_cdf89bf1 finished iteration 1 at 2025-06-03 17:20:53. Total running time: 1min 2s
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_cdf89bf1 result             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ checkpoint_dir_name                         ‚îÇ
‚îÇ time_this_iter_s                    47.9327 ‚îÇ
‚îÇ time_total_s                        47.9327 ‚îÇ
‚îÇ training_iteration                        1 ‚îÇ
‚îÇ epoch                               4.72727 ‚îÇ
‚îÇ eval_accuracy                       0.74242 ‚îÇ
‚îÇ eval_f1                             0.85217 ‚îÇ
‚îÇ eval_loss                           3.29573 ‚îÇ
‚îÇ eval_optim_threshold                0.58021 ‚îÇ
‚îÇ eval_precision                      0.74242 ‚îÇ
‚îÇ eval_recall                               1 ‚îÇ
‚îÇ eval_runtime                         3.3596 ‚îÇ
‚îÇ eval_samples_per_second              19.645 ‚îÇ
‚îÇ eval_steps_per_second                 1.191 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

Trial train_hpo_cdf89bf1 completed after 1 iterations at 2025-06-03 17:20:53. Total running time: 1min 2s
[36m(train_hpo pid=3198804)[0m {'loss': 5.4151, 'grad_norm': 48.152610778808594, 'learning_rate': 2.753032222766959e-07, 'epoch': 2.7272727272727275}[32m [repeated 3x across cluster][0m
[36m(train_hpo pid=3197713)[0m {'eval_loss': 3.2957334518432617, 'eval_f1': 0.8521739130434782, 'eval_recall': 1.0, 'eval_accuracy': 0.7424242424242424, 'eval_precision': 0.7424242424242424, 'eval_optim_threshold': 0.5802130699157715, 'eval_runtime': 3.3596, 'eval_samples_per_second': 19.645, 'eval_steps_per_second': 1.191, 'epoch': 4.7272727272727275}

Trial train_hpo_4c09466a started with configuration:
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_4c09466a config             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ learning_rate                         4e-05 ‚îÇ
‚îÇ num_train_epochs                          5 ‚îÇ
‚îÇ pos_weight                          2.54684 ‚îÇ
‚îÇ weight_decay                        0.24372 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
[36m(train_hpo pid=3199260)[0m [2025-06-03 17:20:59,878] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(train_hpo pid=3198804)[0m {'train_runtime': 16.8457, 'train_samples_per_second': 47.015, 'train_steps_per_second': 0.475, 'train_loss': 5.242302775382996, 'epoch': 3.7272727272727275}[36m(train_hpo pid=3198804)[0m /home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2708: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
[36m(train_hpo pid=3198804)[0m   warnings.warn(
[36m(train_hpo pid=3198804)[0m 2025-06-03 17:21:06,443 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3198804)[0m 2025-06-03 17:21:06,445 - INFO - eval_result: {'eval_loss': 4.36940860748291, 'eval_f1': 0.8521739130434782, 'eval_recall': 1.0, 'eval_accuracy': 0.7424242424242424, 'eval_precision': 0.7424242424242424, 'eval_optim_threshold': 0.5374532341957092, 'eval_runtime': 3.346, 'eval_samples_per_second': 19.725, 'eval_steps_per_second': 1.195, 'epoch': 3.7272727272727275}
2025-06-03 17:21:06,514 - INFO - Cleaning up trial 4e37bbde
2025-06-03 17:21:06,514 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-03_17-19-50/train_hpo_4e37bbde_4_learning_rate=0.0000,num_train_epochs=4,pos_weight=9.2685,weight_decay=0.1334_2025-06-03_17-20-13
2025-06-03 17:21:06,515 - INFO - Current best: dfc200b7 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:21:06,515 - INFO - Current best: cdf89bf1 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:21:06,515 - INFO - Current best: 362470e0 with eval_f1 : 0.8521739130434782 at iteration 1
[36m(train_hpo pid=3198804)[0m 2025-06-03 17:21:06,487 - INFO - Cleared CUDA cache. Memory allocated: 1.33 GB, Memory reserved: 1.58 GB
[36m(train_hpo pid=3199441)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3199441)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3199441)[0m 2025-06-03 17:21:06,800 - INFO - pos_weight value in TrainingArguments : 4.942262677968309
[36m(train_hpo pid=3199441)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:106: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3199441)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3199441)[0m /home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2708: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3199441)[0m   warnings.warn([32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3199835)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3199835)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3199835)[0m 2025-06-03 17:21:15,734 - INFO - pos_weight value in TrainingArguments : 9.454327638424944
[36m(train_hpo pid=3199835)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:106: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3199835)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3199835)[0m /home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2708: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
[36m(train_hpo pid=3199835)[0m   warnings.warn(

[36m(train_hpo pid=3198804)[0m STATE at ending of training  :  TrainerState(epoch=3.7272727272727275, global_step=8, max_steps=8, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=4, num_input_tokens_seen=0, total_flos=189964476340224.0, log_history=[{'loss': 5.7011, 'grad_norm': 63.07164001464844, 'learning_rate': 8.259096668300877e-07, 'epoch': 0.7272727272727273, 'step': 2}, {'loss': 5.4586, 'grad_norm': 58.40663528442383, 'learning_rate': 5.506064445533918e-07, 'epoch': 1.7272727272727273, 'step': 4}, {'loss': 5.4151, 'grad_norm': 48.152610778808594, 'learning_rate': 2.753032222766959e-07, 'epoch': 2.7272727272727275, 'step': 6}, {'loss': 4.3945, 'grad_norm': 57.44441604614258, 'learning_rate': 0.0, 'epoch': 3.7272727272727275, 'step': 8}, {'train_runtime': 16.8457, 'train_samples_per_second': 47.015, 'train_steps_per_second': 0.475, 'total_flos': 189964476340224.0, 'train_loss': 5.242302775382996, 'epoch': 3.7272727272727275, 'step': 8}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': True, 'should_epoch_stop': False, 'should_save': True, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3198804)[0m {'loss': 4.3945, 'grad_norm': 57.44441604614258, 'learning_rate': 0.0, 'epoch': 3.7272727272727275}
[36m(train_hpo pid=3199260)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=10, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=5, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})

Trial train_hpo_376a667c started with configuration:
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_376a667c config             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ learning_rate                         3e-05 ‚îÇ
‚îÇ num_train_epochs                          3 ‚îÇ
‚îÇ pos_weight                          4.94226 ‚îÇ
‚îÇ weight_decay                        0.23987 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
[36m(train_hpo pid=3198804)[0m {'eval_loss': 4.36940860748291, 'eval_f1': 0.8521739130434782, 'eval_recall': 1.0, 'eval_accuracy': 0.7424242424242424, 'eval_precision': 0.7424242424242424, 'eval_optim_threshold': 0.5374532341957092, 'eval_runtime': 3.346, 'eval_samples_per_second': 19.725, 'eval_steps_per_second': 1.195, 'epoch': 3.7272727272727275}

Trial train_hpo_4e37bbde finished iteration 1 at 2025-06-03 17:21:06. Total running time: 1min 15s
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_4e37bbde result             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ checkpoint_dir_name                         ‚îÇ
‚îÇ time_this_iter_s                    24.8281 ‚îÇ
‚îÇ time_total_s                        24.8281 ‚îÇ
‚îÇ training_iteration                        1 ‚îÇ
‚îÇ epoch                               3.72727 ‚îÇ
‚îÇ eval_accuracy                       0.74242 ‚îÇ
‚îÇ eval_f1                             0.85217 ‚îÇ
‚îÇ eval_loss                           4.36941 ‚îÇ
‚îÇ eval_optim_threshold                0.53745 ‚îÇ
‚îÇ eval_precision                      0.74242 ‚îÇ
‚îÇ eval_recall                               1 ‚îÇ
‚îÇ eval_runtime                          3.346 ‚îÇ
‚îÇ eval_samples_per_second              19.725 ‚îÇ
‚îÇ eval_steps_per_second                 1.195 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

Trial train_hpo_4e37bbde completed after 1 iterations at 2025-06-03 17:21:06. Total running time: 1min 15s
[36m(train_hpo pid=3199441)[0m [2025-06-03 17:21:07,218] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(train_hpo pid=3199260)[0m {'loss': 1.3184, 'grad_norm': 9.878808975219727, 'learning_rate': 3.225667134399158e-05, 'epoch': 0.7272727272727273}
[36m(train_hpo pid=3199441)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=6, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=3, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3199260)[0m {'loss': 1.0279, 'grad_norm': 3.920391321182251, 'learning_rate': 2.419250350799368e-05, 'epoch': 1.7272727272727273}

Trial train_hpo_81553241 started with configuration:
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_81553241 config             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ learning_rate                         4e-05 ‚îÇ
‚îÇ num_train_epochs                          4 ‚îÇ
‚îÇ pos_weight                          9.45433 ‚îÇ
‚îÇ weight_decay                        0.22021 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
[36m(train_hpo pid=3199835)[0m [2025-06-03 17:21:16,003] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(train_hpo pid=3199835)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=8, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=4, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3199441)[0m {'loss': 2.9155, 'grad_norm': 29.509288787841797, 'learning_rate': 1.800260137456896e-05, 'epoch': 0.7272727272727273}

Trial status: 4 TERMINATED | 3 RUNNING | 1 PENDING
Current time: 2025-06-03 17:21:21. Total running time: 1min 30s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_recall     eval_accuracy ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ train_hpo_4c09466a   RUNNING           2.54684       4.03208e-05         0.243719                    5                                                                                         ‚îÇ
‚îÇ train_hpo_376a667c   RUNNING           4.94226       2.70039e-05         0.239866                    3                                                                                         ‚îÇ
‚îÇ train_hpo_81553241   RUNNING           9.45433       4.00602e-05         0.220208                    4                                                                                         ‚îÇ
‚îÇ train_hpo_dfc200b7   TERMINATED        8.49369       1.49561e-06         0.13641                     6        1            52.3332       3.04215    0.852174               1          0.742424 ‚îÇ
‚îÇ train_hpo_cdf89bf1   TERMINATED        7.54953       4.55539e-06         0.123031                    5        1            47.9327       3.29573    0.852174               1          0.742424 ‚îÇ
‚îÇ train_hpo_362470e0   TERMINATED        8.94984       7.98818e-05         0.251217                    3        1            20.9872       1.07363    0.852174               1          0.742424 ‚îÇ
‚îÇ train_hpo_4e37bbde   TERMINATED        9.2685        1.10121e-06         0.13345                     4        1            24.8281       4.36941    0.852174               1          0.742424 ‚îÇ
‚îÇ train_hpo_717586ed   PENDING           7.97828       2.7847e-06          0.185124                    2                                                                                         ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ[36m(train_hpo pid=3199835)[0m /home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2708: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
[36m(train_hpo pid=3199835)[0m   warnings.warn(
2025-06-03 17:21:36,182	ERROR tune_controller.py:1331 -- Trial task failed for trial train_hpo_4c09466a
Traceback (most recent call last):
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
             ^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/worker.py", line 2782, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/_private/worker.py", line 929, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(SafetensorError): [36mray::ImplicitFunc.train()[39m (pid=3199260, ip=172.30.120.56, actor_id=24555054964a94063f8a1d0a01000000, repr=train_hpo)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/trainable.py", line 330, in train
    raise skipped from exception_cause(skipped)
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/air/_internal/util.py", line 107, in run
    self._ret = self._target(*self._args, **self._kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py", line 45, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py", line 261, in _trainable_func
    output = fn()
             ^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/trainable/util.py", line 130, in inner
    return trainable(config, **fn_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/binary_pipeline.py", line 164, in train_hpo
    trainer.train()
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 2241, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 2612, in _inner_training_loop
    self._maybe_log_save_evaluate(
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 3092, in _maybe_log_save_evaluate
    self._save_checkpoint(model, trial)
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 3190, in _save_checkpoint
    self.save_model(output_dir, _internal_call=True)
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 3860, in save_model
    self._save(output_dir)
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 3964, in _save
    self.model.save_pretrained(
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py", line 3032, in save_pretrained
    safe_save_file(shard, os.path.join(save_directory, shard_file), metadata={"format": "pt"})
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/safetensors/torch.py", line 286, in save_file
    serialize_file(_flatten(tensors), filename, metadata=metadata)
safetensors_rust.SafetensorError: Error while serializing: IoError(Os { code: 2, kind: NotFound, message: "No such file or directory" })
[36m(train_hpo pid=3199441)[0m /home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2708: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
[36m(train_hpo pid=3199441)[0m   warnings.warn(
[36m(train_hpo pid=3199835)[0m 2025-06-03 17:21:39,437 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3199835)[0m 2025-06-03 17:21:39,439 - INFO - eval_result: {'eval_loss': 1.2669097185134888, 'eval_f1': 0.8521739130434782, 'eval_recall': 1.0, 'eval_accuracy': 0.7424242424242424, 'eval_precision': 0.7424242424242424, 'eval_optim_threshold': 0.8597410917282104, 'eval_runtime': 3.3555, 'eval_samples_per_second': 19.669, 'eval_steps_per_second': 1.192, 'epoch': 3.7272727272727275}
2025-06-03 17:21:39,518 - INFO - Cleaning up trial 81553241
2025-06-03 17:21:39,518 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-03_17-19-50/train_hpo_81553241_7_learning_rate=0.0000,num_train_epochs=4,pos_weight=9.4543,weight_decay=0.2202_2025-06-03_17-21-05
2025-06-03 17:21:39,518 - INFO - Current best: dfc200b7 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:21:39,518 - INFO - Current best: cdf89bf1 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:21:39,518 - INFO - Current best: 362470e0 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:21:39,518 - INFO - Current best: 4e37bbde with eval_f1 : 0.8521739130434782 at iteration 1
[36m(train_hpo pid=3199835)[0m 2025-06-03 17:21:39,479 - INFO - Cleared CUDA cache. Memory allocated: 1.33 GB, Memory reserved: 1.58 GB
2025-06-03 17:21:40,844 - INFO - Cleaning up trial 376a667c
2025-06-03 17:21:40,844 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-03_17-19-50/train_hpo_376a667c_6_learning_rate=0.0000,num_train_epochs=3,pos_weight=4.9423,weight_decay=0.2399_2025-06-03_17-20-58
2025-06-03 17:21:40,844 - INFO - Current best: dfc200b7 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:21:40,844 - INFO - Current best: cdf89bf1 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:21:40,844 - INFO - Current best: 362470e0 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:21:40,844 - INFO - Current best: 4e37bbde with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:21:40,844 - INFO - Current best: 81553241 with eval_f1 : 0.8521739130434782 at iteration 1
[36m(train_hpo pid=3200527)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3200527)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3199441)[0m 2025-06-03 17:21:40,778 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3199441)[0m 2025-06-03 17:21:40,780 - INFO - eval_result: {'eval_loss': 1.4585893154144287, 'eval_f1': 0.8521739130434782, 'eval_recall': 1.0, 'eval_accuracy': 0.7424242424242424, 'eval_precision': 0.7424242424242424, 'eval_optim_threshold': 0.7242268919944763, 'eval_runtime': 3.2935, 'eval_samples_per_second': 20.039, 'eval_steps_per_second': 1.215, 'epoch': 2.7272727272727275}
[36m(train_hpo pid=3200527)[0m 2025-06-03 17:21:44,610 - INFO - pos_weight value in TrainingArguments : 7.978279409450941
[36m(train_hpo pid=3200527)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:106: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3200527)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3199441)[0m 2025-06-03 17:21:40,817 - INFO - Cleared CUDA cache. Memory allocated: 1.33 GB, Memory reserved: 1.58 GB

[36m(train_hpo pid=3199835)[0m {'loss': 2.7255, 'grad_norm': 25.4379825592041, 'learning_rate': 2.0030081337922637e-05, 'epoch': 1.7272727272727273}[32m [repeated 3x across cluster][0m
[36m(train_hpo pid=3199835)[0m {'train_runtime': 16.7018, 'train_samples_per_second': 47.42, 'train_steps_per_second': 0.479, 'train_loss': 2.805526852607727, 'epoch': 3.7272727272727275}
[36m(train_hpo pid=3199835)[0m STATE at ending of training  :  TrainerState(epoch=3.7272727272727275, global_step=8, max_steps=8, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=4, num_input_tokens_seen=0, total_flos=189964476340224.0, log_history=[{'loss': 5.0015, 'grad_norm': 36.18595886230469, 'learning_rate': 3.0045122006883954e-05, 'epoch': 0.7272727272727273, 'step': 2}, {'loss': 2.7255, 'grad_norm': 25.4379825592041, 'learning_rate': 2.0030081337922637e-05, 'epoch': 1.7272727272727273, 'step': 4}, {'loss': 2.0572, 'grad_norm': 13.477666854858398, 'learning_rate': 1.0015040668961318e-05, 'epoch': 2.7272727272727275, 'step': 6}, {'loss': 1.4378, 'grad_norm': 13.159868240356445, 'learning_rate': 0.0, 'epoch': 3.7272727272727275, 'step': 8}, {'train_runtime': 16.7018, 'train_samples_per_second': 47.42, 'train_steps_per_second': 0.479, 'total_flos': 189964476340224.0, 'train_loss': 2.805526852607727, 'epoch': 3.7272727272727275, 'step': 8}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': True, 'should_epoch_stop': False, 'should_save': True, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3199835)[0m {'loss': 1.4378, 'grad_norm': 13.159868240356445, 'learning_rate': 0.0, 'epoch': 3.7272727272727275}[32m [repeated 4x across cluster][0m

Trial train_hpo_4c09466a errored after 0 iterations at 2025-06-03 17:21:36. Total running time: 1min 45s
Error file: /tmp/ray/session_2025-06-03_17-19-23_431813_3194092/artifacts/2025-06-03_17-19-50/train_hpo_2025-06-03_17-19-50/driver_artifacts/train_hpo_4c09466a_5_learning_rate=0.0000,num_train_epochs=5,pos_weight=2.5468,weight_decay=0.2437_2025-06-03_17-20-41/error.txt
[36m(train_hpo pid=3199441)[0m STATE at ending of training  :  TrainerState(epoch=2.7272727272727275, global_step=6, max_steps=6, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=3, num_input_tokens_seen=0, total_flos=139973824671744.0, log_history=[{'loss': 2.9155, 'grad_norm': 29.509288787841797, 'learning_rate': 1.800260137456896e-05, 'epoch': 0.7272727272727273, 'step': 2}, {'loss': 2.2853, 'grad_norm': 21.834917068481445, 'learning_rate': 9.00130068728448e-06, 'epoch': 1.7272727272727273, 'step': 4}, {'loss': 1.5647, 'grad_norm': 13.00870418548584, 'learning_rate': 0.0, 'epoch': 2.7272727272727275, 'step': 6}, {'train_runtime': 26.8884, 'train_samples_per_second': 22.091, 'train_steps_per_second': 0.223, 'total_flos': 139973824671744.0, 'train_loss': 2.2551554441452026, 'epoch': 2.7272727272727275, 'step': 6}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': True, 'should_epoch_stop': False, 'should_save': True, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3199835)[0m {'eval_loss': 1.2669097185134888, 'eval_f1': 0.8521739130434782, 'eval_recall': 1.0, 'eval_accuracy': 0.7424242424242424, 'eval_precision': 0.7424242424242424, 'eval_optim_threshold': 0.8597410917282104, 'eval_runtime': 3.3555, 'eval_samples_per_second': 19.669, 'eval_steps_per_second': 1.192, 'epoch': 3.7272727272727275}

Trial train_hpo_81553241 finished iteration 1 at 2025-06-03 17:21:39. Total running time: 1min 48s
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_81553241 result             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ checkpoint_dir_name                         ‚îÇ
‚îÇ time_this_iter_s                     24.714 ‚îÇ
‚îÇ time_total_s                         24.714 ‚îÇ
‚îÇ training_iteration                        1 ‚îÇ
‚îÇ epoch                               3.72727 ‚îÇ
‚îÇ eval_accuracy                       0.74242 ‚îÇ
‚îÇ eval_f1                             0.85217 ‚îÇ
‚îÇ eval_loss                           1.26691 ‚îÇ
‚îÇ eval_optim_threshold                0.85974 ‚îÇ
‚îÇ eval_precision                      0.74242 ‚îÇ
‚îÇ eval_recall                               1 ‚îÇ
‚îÇ eval_runtime                         3.3555 ‚îÇ
‚îÇ eval_samples_per_second              19.669 ‚îÇ
‚îÇ eval_steps_per_second                 1.192 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

Trial train_hpo_81553241 completed after 1 iterations at 2025-06-03 17:21:39. Total running time: 1min 48s

Trial train_hpo_376a667c finished iteration 1 at 2025-06-03 17:21:40. Total running time: 1min 49s
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_376a667c result             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ checkpoint_dir_name                         ‚îÇ
‚îÇ time_this_iter_s                    34.9803 ‚îÇ
‚îÇ time_total_s                        34.9803 ‚îÇ
‚îÇ training_iteration                        1 ‚îÇ
‚îÇ epoch                               2.72727 ‚îÇ
‚îÇ eval_accuracy                       0.74242 ‚îÇ
‚îÇ eval_f1                             0.85217 ‚îÇ
‚îÇ eval_loss                           1.45859 ‚îÇ
‚îÇ eval_optim_threshold                0.72423 ‚îÇ
‚îÇ eval_precision                      0.74242 ‚îÇ
‚îÇ eval_recall                               1 ‚îÇ
‚îÇ eval_runtime                         3.2935 ‚îÇ
‚îÇ eval_samples_per_second              20.039 ‚îÇ
‚îÇ eval_steps_per_second                 1.215 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

Trial train_hpo_376a667c completed after 1 iterations at 2025-06-03 17:21:40. Total running time: 1min 49s

Trial train_hpo_717586ed started with configuration:
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_717586ed config             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ learning_rate                             0 ‚îÇ
‚îÇ num_train_epochs                          2 ‚îÇ
‚îÇ pos_weight                          7.97828 ‚îÇ
‚îÇ weight_decay                        0.18512 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
[36m(train_hpo pid=3200527)[0m [2025-06-03 17:21:44,876] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(train_hpo pid=3199441)[0m {'train_runtime': 26.8884, 'train_samples_per_second': 22.091, 'train_steps_per_second': 0.223, 'train_loss': 2.2551554441452026, 'epoch': 2.7272727272727275}
[36m(train_hpo pid=3199441)[0m {'loss': 1.5647, 'grad_norm': 13.00870418548584, 'learning_rate': 0.0, 'epoch': 2.7272727272727275}
[36m(train_hpo pid=3199441)[0m {'eval_loss': 1.4585893154144287, 'eval_f1': 0.8521739130434782, 'eval_recall': 1.0, 'eval_accuracy': 0.7424242424242424, 'eval_precision': 0.7424242424242424, 'eval_optim_threshold': 0.7242268919944763, 'eval_runtime': 3.2935, 'eval_samples_per_second': 20.039, 'eval_steps_per_second': 1.215, 'epoch': 2.7272727272727275}[36m(train_hpo pid=3200527)[0m /home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2708: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
[36m(train_hpo pid=3200527)[0m   warnings.warn(
[36m(train_hpo pid=3200798)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3200798)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3200798)[0m 2025-06-03 17:21:51,915 - INFO - pos_weight value in TrainingArguments : 9.280083037935846
[36m(train_hpo pid=3200798)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:106: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3200798)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3200798)[0m /home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2708: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
[36m(train_hpo pid=3200798)[0m   warnings.warn(
[36m(train_hpo pid=3200527)[0m /home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2708: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
[36m(train_hpo pid=3200527)[0m   warnings.warn(

[36m(train_hpo pid=3200527)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=4, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=2, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})

Trial train_hpo_2753649d started with configuration:
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_2753649d config             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ learning_rate                         5e-05 ‚îÇ
‚îÇ num_train_epochs                          6 ‚îÇ
‚îÇ pos_weight                          9.28008 ‚îÇ
‚îÇ weight_decay                        0.16302 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

Trial status: 6 TERMINATED | 1 ERROR | 2 RUNNING | 1 PENDING
Current time: 2025-06-03 17:21:51. Total running time: 2min 0s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_recall     eval_accuracy ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ train_hpo_717586ed   RUNNING           7.97828       2.7847e-06          0.185124                    2                                                                                         ‚îÇ
‚îÇ train_hpo_2753649d   RUNNING           9.28008       4.73492e-05         0.163021                    6                                                                                         ‚îÇ
‚îÇ train_hpo_dfc200b7   TERMINATED        8.49369       1.49561e-06         0.13641                     6        1            52.3332       3.04215    0.852174               1          0.742424 ‚îÇ
‚îÇ train_hpo_cdf89bf1   TERMINATED        7.54953       4.55539e-06         0.123031                    5        1            47.9327       3.29573    0.852174               1          0.742424 ‚îÇ
‚îÇ train_hpo_362470e0   TERMINATED        8.94984       7.98818e-05         0.251217                    3        1            20.9872       1.07363    0.852174               1          0.742424 ‚îÇ
‚îÇ train_hpo_4e37bbde   TERMINATED        9.2685        1.10121e-06         0.13345                     4        1            24.8281       4.36941    0.852174               1          0.742424 ‚îÇ
‚îÇ train_hpo_376a667c   TERMINATED        4.94226       2.70039e-05         0.239866                    3        1            34.9803       1.45859    0.852174               1          0.742424 ‚îÇ
‚îÇ train_hpo_81553241   TERMINATED        9.45433       4.00602e-05         0.220208                    4        1            24.714        1.26691    0.852174               1          0.742424 ‚îÇ
‚îÇ train_hpo_3fb36b31   PENDING           7.30559       6.78644e-06         0.286643                    3                                                                                         ‚îÇ
‚îÇ train_hpo_4c09466a   ERROR             2.54684       4.03208e-05         0.243719                    5                                                                                         ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
[36m(train_hpo pid=3200798)[0m [2025-06-03 17:21:52,315] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(train_hpo pid=3200527)[0m {'loss': 5.5543, 'grad_norm': 60.471160888671875, 'learning_rate': 1.3923519932932234e-06, 'epoch': 0.7272727272727273}
[36m(train_hpo pid=3200798)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=6, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3200527)[0m {'loss': 4.2846, 'grad_norm': 56.743534088134766, 'learning_rate': 0.0, 'epoch': 1.7272727272727273}
[36m(train_hpo pid=3200527)[0m {'train_runtime': 9.4377, 'train_samples_per_second': 41.959, 'train_steps_per_second': 0.424, 'train_loss': 4.91948676109314, 'epoch': 1.7272727272727273}
[36m(train_hpo pid=3200527)[0m STATE at ending of training  :  TrainerState(epoch=1.7272727272727273, global_step=4, max_steps=4, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=2, num_input_tokens_seen=0, total_flos=89983173003264.0, log_history=[{'loss': 5.5543, 'grad_norm': 60.471160888671875, 'learning_rate': 1.3923519932932234e-06, 'epoch': 0.7272727272727273, 'step': 2}, {'loss': 4.2846, 'grad_norm': 56.743534088134766, 'learning_rate': 0.0, 'epoch': 1.7272727272727273, 'step': 4}, {'train_runtime': 9.4377, 'train_samples_per_second': 41.959, 'train_steps_per_second': 0.424, 'total_flos': 89983173003264.0, 'train_loss': 4.91948676109314, 'epoch': 1.7272727272727273, 'step': 4}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': True, 'should_epoch_stop': False, 'should_save': True, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})

Trial train_hpo_3fb36b31 started with configuration:
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_3fb36b31 config             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ learning_rate                         1e-05 ‚îÇ
‚îÇ num_train_epochs                          3 ‚îÇ
‚îÇ pos_weight                          7.30559 ‚îÇ
‚îÇ weight_decay                        0.28664 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ[36m(train_hpo pid=3201083)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3201083)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3201083)[0m 2025-06-03 17:21:59,131 - INFO - pos_weight value in TrainingArguments : 7.3055930015922925
[36m(train_hpo pid=3201083)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:106: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3201083)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3200527)[0m 2025-06-03 17:22:02,473 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3200527)[0m 2025-06-03 17:22:02,474 - INFO - eval_result: {'eval_loss': 4.301432132720947, 'eval_f1': 0.5822784810126582, 'eval_recall': 0.46938775510204084, 'eval_accuracy': 0.5, 'eval_precision': 0.7666666666666667, 'eval_optim_threshold': 0.5003576874732971, 'eval_runtime': 4.8008, 'eval_samples_per_second': 13.748, 'eval_steps_per_second': 0.833, 'epoch': 1.7272727272727273}
[36m(train_hpo pid=3200527)[0m 2025-06-03 17:22:02,510 - INFO - Cleared CUDA cache. Memory allocated: 1.33 GB, Memory reserved: 1.58 GB
2025-06-03 17:22:02,535 - INFO - Cleaning up trial 717586ed
2025-06-03 17:22:02,535 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-03_17-19-50/train_hpo_717586ed_8_learning_rate=0.0000,num_train_epochs=2,pos_weight=7.9783,weight_decay=0.1851_2025-06-03_17-21-14
2025-06-03 17:22:02,535 - INFO - Current best: dfc200b7 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:02,535 - INFO - Current best: cdf89bf1 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:02,535 - INFO - Current best: 362470e0 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:02,535 - INFO - Current best: 4e37bbde with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:02,535 - INFO - Current best: 376a667c with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:02,535 - INFO - Current best: 81553241 with eval_f1 : 0.8521739130434782 at iteration 1
[36m(train_hpo pid=3201083)[0m /home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2708: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
[36m(train_hpo pid=3201083)[0m   warnings.warn(
[36m(train_hpo pid=3201586)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3201586)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3201586)[0m 2025-06-03 17:22:11,504 - INFO - pos_weight value in TrainingArguments : 8.360470176973763
[36m(train_hpo pid=3201586)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:106: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3201586)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3201586)[0m /home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2708: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
[36m(train_hpo pid=3201586)[0m   warnings.warn(
2025-06-03 17:22:19,240 - INFO - Cleaning up trial 3fb36b31
2025-06-03 17:22:19,240 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-03_17-19-50/train_hpo_3fb36b31_10_learning_rate=0.0000,num_train_epochs=3,pos_weight=7.3056,weight_decay=0.2866_2025-06-03_17-21-51
2025-06-03 17:22:19,240 - INFO - Current best: dfc200b7 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:19,240 - INFO - Current best: cdf89bf1 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:19,240 - INFO - Current best: 362470e0 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:19,240 - INFO - Current best: 4e37bbde with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:19,240 - INFO - Current best: 376a667c with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:19,240 - INFO - Current best: 81553241 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:19,240 - INFO - Cleaning up trial 717586ed
2025-06-03 17:22:19,240 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-03_17-19-50/train_hpo_717586ed_8_learning_rate=0.0000,num_train_epochs=2,pos_weight=7.9783,weight_decay=0.1851_2025-06-03_17-21-14
[36m(train_hpo pid=3201083)[0m 2025-06-03 17:22:19,178 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3201083)[0m 2025-06-03 17:22:19,180 - INFO - eval_result: {'eval_loss': 2.234632968902588, 'eval_f1': 0.8521739130434782, 'eval_recall': 1.0, 'eval_accuracy': 0.7424242424242424, 'eval_precision': 0.7424242424242424, 'eval_optim_threshold': 0.6897740364074707, 'eval_runtime': 3.361, 'eval_samples_per_second': 19.637, 'eval_steps_per_second': 1.19, 'epoch': 2.7272727272727275}
[36m(train_hpo pid=3201083)[0m 2025-06-03 17:22:19,217 - INFO - Cleared CUDA cache. Memory allocated: 1.33 GB, Memory reserved: 1.58 GB

[36m(train_hpo pid=3201083)[0m [2025-06-03 17:21:59,397] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(train_hpo pid=3200798)[0m {'loss': 3.9168, 'grad_norm': 39.2793083190918, 'learning_rate': 3.945768742227825e-05, 'epoch': 0.7272727272727273}

Trial train_hpo_717586ed finished iteration 1 at 2025-06-03 17:22:02. Total running time: 2min 11s
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_717586ed result             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ checkpoint_dir_name                         ‚îÇ
‚îÇ time_this_iter_s                     18.832 ‚îÇ
‚îÇ time_total_s                         18.832 ‚îÇ
‚îÇ training_iteration                        1 ‚îÇ
‚îÇ epoch                               1.72727 ‚îÇ
‚îÇ eval_accuracy                           0.5 ‚îÇ
‚îÇ eval_f1                             0.58228 ‚îÇ
‚îÇ eval_loss                           4.30143 ‚îÇ
‚îÇ eval_optim_threshold                0.50036 ‚îÇ
‚îÇ eval_precision                      0.76667 ‚îÇ
‚îÇ eval_recall                         0.46939 ‚îÇ
‚îÇ eval_runtime                         4.8008 ‚îÇ
‚îÇ eval_samples_per_second              13.748 ‚îÇ
‚îÇ eval_steps_per_second                 0.833 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
[36m(train_hpo pid=3200527)[0m {'eval_loss': 4.301432132720947, 'eval_f1': 0.5822784810126582, 'eval_recall': 0.46938775510204084, 'eval_accuracy': 0.5, 'eval_precision': 0.7666666666666667, 'eval_optim_threshold': 0.5003576874732971, 'eval_runtime': 4.8008, 'eval_samples_per_second': 13.748, 'eval_steps_per_second': 0.833, 'epoch': 1.7272727272727273}

Trial train_hpo_717586ed completed after 1 iterations at 2025-06-03 17:22:02. Total running time: 2min 11s
[36m(train_hpo pid=3201083)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=6, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=3, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3200798)[0m {'loss': 2.4661, 'grad_norm': 30.64963150024414, 'learning_rate': 3.15661499378226e-05, 'epoch': 1.7272727272727273}
[36m(train_hpo pid=3201083)[0m {'loss': 3.2429, 'grad_norm': 35.72221755981445, 'learning_rate': 4.524295014519432e-06, 'epoch': 0.7272727272727273}
[36m(train_hpo pid=3200798)[0m {'loss': 1.8208, 'grad_norm': 62.318115234375, 'learning_rate': 2.367461245336695e-05, 'epoch': 2.7272727272727275}

Trial train_hpo_5d396941 started with configuration:
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_5d396941 config             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ learning_rate                         3e-05 ‚îÇ
‚îÇ num_train_epochs                          6 ‚îÇ
‚îÇ pos_weight                          8.36047 ‚îÇ
‚îÇ weight_decay                        0.00109 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
[36m(train_hpo pid=3201586)[0m [2025-06-03 17:22:11,897] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(train_hpo pid=3201586)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=6, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3200798)[0m {'loss': 1.5742, 'grad_norm': 7.683216571807861, 'learning_rate': 1.57830749689113e-05, 'epoch': 3.7272727272727275}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3201083)[0m {'train_runtime': 13.0731, 'train_samples_per_second': 45.437, 'train_steps_per_second': 0.459, 'train_loss': 2.8146769205729165, 'epoch': 2.7272727272727275}
[36m(train_hpo pid=3201083)[0m STATE at ending of training  :  TrainerState(epoch=2.7272727272727275, global_step=6, max_steps=6, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=3, num_input_tokens_seen=0, total_flos=139973824671744.0, log_history=[{'loss': 3.2429, 'grad_norm': 35.72221755981445, 'learning_rate': 4.524295014519432e-06, 'epoch': 0.7272727272727273, 'step': 2}, {'loss': 2.9748, 'grad_norm': 31.92438507080078, 'learning_rate': 2.262147507259716e-06, 'epoch': 1.7272727272727273, 'step': 4}, {'loss': 2.2264, 'grad_norm': 23.920339584350586, 'learning_rate': 0.0, 'epoch': 2.7272727272727275, 'step': 6}, {'train_runtime': 13.0731, 'train_samples_per_second': 45.437, 'train_steps_per_second': 0.459, 'total_flos': 139973824671744.0, 'train_loss': 2.8146769205729165, 'epoch': 2.7272727272727275, 'step': 6}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': True, 'should_epoch_stop': False, 'should_save': True, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})

Trial train_hpo_3fb36b31 finished iteration 1 at 2025-06-03 17:22:19. Total running time: 2min 28s
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_3fb36b31 result             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ checkpoint_dir_name                         ‚îÇ
‚îÇ time_this_iter_s                    21.0466 ‚îÇ
‚îÇ time_total_s                        21.0466 ‚îÇ
‚îÇ training_iteration                        1 ‚îÇ
‚îÇ epoch                               2.72727 ‚îÇ
‚îÇ eval_accuracy                       0.74242 ‚îÇ
‚îÇ eval_f1                             0.85217 ‚îÇ
‚îÇ eval_loss                           2.23463 ‚îÇ
‚îÇ eval_optim_threshold                0.68977 ‚îÇ
‚îÇ eval_precision                      0.74242 ‚îÇ
‚îÇ eval_recall                               1 ‚îÇ
‚îÇ eval_runtime                          3.361 ‚îÇ
‚îÇ eval_samples_per_second              19.637 ‚îÇ
‚îÇ eval_steps_per_second                  1.19 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

Trial train_hpo_3fb36b31 completed after 1 iterations at 2025-06-03 17:22:19. Total running time: 2min 28s
[36m(train_hpo pid=3201083)[0m {'eval_loss': 2.234632968902588, 'eval_f1': 0.8521739130434782, 'eval_recall': 1.0, 'eval_accuracy': 0.7424242424242424, 'eval_precision': 0.7424242424242424, 'eval_optim_threshold': 0.6897740364074707, 'eval_runtime': 3.361, 'eval_samples_per_second': 19.637, 'eval_steps_per_second': 1.19, 'epoch': 2.7272727272727275}

Trial status: 8 TERMINATED | 1 ERROR | 2 RUNNING | 1 PENDING
Current time: 2025-06-03 17:22:21. Total running time: 2min 30s
Logical resource usage: 30.0/32 CPUs, 3.0/3 GPUs (0.0/1.0 accelerator_type:A100D)[36m(train_hpo pid=3200798)[0m /home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2708: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3200798)[0m   warnings.warn([32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3202107)[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']
[36m(train_hpo pid=3202107)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(train_hpo pid=3202107)[0m 2025-06-03 17:22:27,689 - INFO - pos_weight value in TrainingArguments : 4.226333703160277
[36m(train_hpo pid=3202107)[0m /home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/model_init.py:106: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.
[36m(train_hpo pid=3202107)[0m   super().__init__(*args, **kwargs)
[36m(train_hpo pid=3200798)[0m 2025-06-03 17:22:29,347 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3200798)[0m 2025-06-03 17:22:29,349 - INFO - eval_result: {'eval_loss': 1.0804526805877686, 'eval_f1': 0.8521739130434782, 'eval_recall': 1.0, 'eval_accuracy': 0.7424242424242424, 'eval_precision': 0.7424242424242424, 'eval_optim_threshold': 0.9422253966331482, 'eval_runtime': 3.8798, 'eval_samples_per_second': 17.011, 'eval_steps_per_second': 1.031, 'epoch': 5.7272727272727275}

‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_recall     eval_accuracy ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ train_hpo_2753649d   RUNNING           9.28008       4.73492e-05       0.163021                      6                                                                                         ‚îÇ
‚îÇ train_hpo_5d396941   RUNNING           8.36047       3.23119e-05       0.00108909                    6                                                                                         ‚îÇ
‚îÇ train_hpo_dfc200b7   TERMINATED        8.49369       1.49561e-06       0.13641                       6        1            52.3332       3.04215    0.852174        1                 0.742424 ‚îÇ
‚îÇ train_hpo_cdf89bf1   TERMINATED        7.54953       4.55539e-06       0.123031                      5        1            47.9327       3.29573    0.852174        1                 0.742424 ‚îÇ
‚îÇ train_hpo_362470e0   TERMINATED        8.94984       7.98818e-05       0.251217                      3        1            20.9872       1.07363    0.852174        1                 0.742424 ‚îÇ
‚îÇ train_hpo_4e37bbde   TERMINATED        9.2685        1.10121e-06       0.13345                       4        1            24.8281       4.36941    0.852174        1                 0.742424 ‚îÇ
‚îÇ train_hpo_376a667c   TERMINATED        4.94226       2.70039e-05       0.239866                      3        1            34.9803       1.45859    0.852174        1                 0.742424 ‚îÇ
‚îÇ train_hpo_81553241   TERMINATED        9.45433       4.00602e-05       0.220208                      4        1            24.714        1.26691    0.852174        1                 0.742424 ‚îÇ
‚îÇ train_hpo_717586ed   TERMINATED        7.97828       2.7847e-06        0.185124                      2        1            18.8321       4.30143    0.582278        0.469388          0.5      ‚îÇ
‚îÇ train_hpo_3fb36b31   TERMINATED        7.30559       6.78644e-06       0.286643                      3        1            21.0466       2.23463    0.852174        1                 0.742424 ‚îÇ
‚îÇ train_hpo_0b66afdd   PENDING           4.22633       2.07214e-05       0.263741                      4                                                                                         ‚îÇ
‚îÇ train_hpo_4c09466a   ERROR             2.54684       4.03208e-05       0.243719                      5                                                                                         ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
[36m(train_hpo pid=3201586)[0m {'loss': 5.8326, 'grad_norm': 59.47175216674805, 'learning_rate': 2.6926604377058517e-05, 'epoch': 0.7272727272727273}[32m [repeated 3x across cluster][0m
[36m(train_hpo pid=3200798)[0m {'train_runtime': 29.7801, 'train_samples_per_second': 39.892, 'train_steps_per_second': 0.403, 'train_loss': 2.057605028152466, 'epoch': 5.7272727272727275}
[36m(train_hpo pid=3200798)[0m STATE at ending of training  :  TrainerState(epoch=5.7272727272727275, global_step=12, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=6, num_input_tokens_seen=0, total_flos=289945779677184.0, log_history=[{'loss': 3.9168, 'grad_norm': 39.2793083190918, 'learning_rate': 3.945768742227825e-05, 'epoch': 0.7272727272727273, 'step': 2}, {'loss': 2.4661, 'grad_norm': 30.64963150024414, 'learning_rate': 3.15661499378226e-05, 'epoch': 1.7272727272727273, 'step': 4}, {'loss': 1.8208, 'grad_norm': 62.318115234375, 'learning_rate': 2.367461245336695e-05, 'epoch': 2.7272727272727275, 'step': 6}, {'loss': 1.5742, 'grad_norm': 7.683216571807861, 'learning_rate': 1.57830749689113e-05, 'epoch': 3.7272727272727275, 'step': 8}, {'loss': 1.47, 'grad_norm': 3.4725112915039062, 'learning_rate': 7.89153748445565e-06, 'epoch': 4.7272727272727275, 'step': 10}, {'loss': 1.0976, 'grad_norm': 5.972642421722412, 'learning_rate': 0.0, 'epoch': 5.7272727272727275, 'step': 12}, {'train_runtime': 29.7801, 'train_samples_per_second': 39.892, 'train_steps_per_second': 0.403, 'total_flos': 289945779677184.0, 'train_loss': 2.057605028152466, 'epoch': 5.7272727272727275, 'step': 12}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': True, 'should_epoch_stop': False, 'should_save': True, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})

Trial train_hpo_0b66afdd started with configuration:
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_0b66afdd config             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ learning_rate                         2e-05 ‚îÇ
‚îÇ num_train_epochs                          4 ‚îÇ
‚îÇ pos_weight                          4.22633 ‚îÇ
‚îÇ weight_decay                        0.26374 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
[36m(train_hpo pid=3202107)[0m [2025-06-03 17:22:27,927] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(train_hpo pid=3200798)[0m {'eval_loss': 1.0804526805877686, 'eval_f1': 0.8521739130434782, 'eval_recall': 1.0, 'eval_accuracy': 0.7424242424242424, 'eval_precision': 0.7424242424242424, 'eval_optim_threshold': 0.9422253966331482, 'eval_runtime': 3.8798, 'eval_samples_per_second': 17.011, 'eval_steps_per_second': 1.031, 'epoch': 5.7272727272727275}
[36m(train_hpo pid=3201586)[0m {'loss': 3.4807, 'grad_norm': 29.456336975097656, 'learning_rate': 2.154128350164681e-05, 'epoch': 1.7272727272727273}[32m [repeated 2x across cluster][0m

Trial train_hpo_2753649d finished iteration 1 at 2025-06-03 17:22:29. Total running time: 2min 38s
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_2753649d result             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ checkpoint_dir_name                         ‚îÇ
‚îÇ time_this_iter_s                    38.3821 ‚îÇ
‚îÇ time_total_s                        38.3821 ‚îÇ
‚îÇ training_iteration                        1 ‚îÇ
‚îÇ epoch                               5.72727 ‚îÇ
‚îÇ eval_accuracy                       0.74242 ‚îÇ
‚îÇ eval_f1                             0.85217 ‚îÇ
‚îÇ eval_loss                           1.08045 ‚îÇ
‚îÇ eval_optim_threshold                0.94223 ‚îÇ
‚îÇ eval_precision                      0.74242 ‚îÇ
‚îÇ eval_recall                               1 ‚îÇ
‚îÇ eval_runtime                         3.8798 ‚îÇ
‚îÇ eval_samples_per_second              17.011 ‚îÇ
‚îÇ eval_steps_per_second                 1.031 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ2025-06-03 17:22:29,419 - INFO - Cleaning up trial 2753649d
2025-06-03 17:22:29,419 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-03_17-19-50/train_hpo_2753649d_9_learning_rate=0.0000,num_train_epochs=6,pos_weight=9.2801,weight_decay=0.1630_2025-06-03_17-21-43
2025-06-03 17:22:29,419 - INFO - Current best: dfc200b7 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:29,419 - INFO - Current best: cdf89bf1 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:29,419 - INFO - Current best: 362470e0 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:29,419 - INFO - Current best: 4e37bbde with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:29,419 - INFO - Current best: 376a667c with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:29,419 - INFO - Current best: 81553241 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:29,419 - INFO - Cleaning up trial 717586ed
2025-06-03 17:22:29,419 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-03_17-19-50/train_hpo_717586ed_8_learning_rate=0.0000,num_train_epochs=2,pos_weight=7.9783,weight_decay=0.1851_2025-06-03_17-21-14
2025-06-03 17:22:29,419 - INFO - Current best: 3fb36b31 with eval_f1 : 0.8521739130434782 at iteration 1
[36m(train_hpo pid=3200798)[0m 2025-06-03 17:22:29,394 - INFO - Cleared CUDA cache. Memory allocated: 1.33 GB, Memory reserved: 1.58 GB
[36m(train_hpo pid=3202107)[0m /home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2708: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
[36m(train_hpo pid=3202107)[0m   warnings.warn(
[36m(train_hpo pid=3201586)[0m /home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2708: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
[36m(train_hpo pid=3201586)[0m   warnings.warn(
[36m(train_hpo pid=3201586)[0m 2025-06-03 17:22:48,382 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3201586)[0m 2025-06-03 17:22:48,384 - INFO - eval_result: {'eval_loss': 1.1111011505126953, 'eval_f1': 0.8521739130434782, 'eval_recall': 1.0, 'eval_accuracy': 0.7424242424242424, 'eval_precision': 0.7424242424242424, 'eval_optim_threshold': 0.9058770537376404, 'eval_runtime': 3.5349, 'eval_samples_per_second': 18.671, 'eval_steps_per_second': 1.132, 'epoch': 5.7272727272727275}
[36m(train_hpo pid=3201586)[0m 2025-06-03 17:22:48,420 - INFO - Cleared CUDA cache. Memory allocated: 1.33 GB, Memory reserved: 1.58 GB
2025-06-03 17:22:48,446 - INFO - Cleaning up trial 5d396941
2025-06-03 17:22:48,446 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-03_17-19-50/train_hpo_5d396941_11_learning_rate=0.0000,num_train_epochs=6,pos_weight=8.3605,weight_decay=0.0011_2025-06-03_17-21-58
2025-06-03 17:22:48,446 - INFO - Current best: dfc200b7 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:48,446 - INFO - Current best: cdf89bf1 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:48,446 - INFO - Current best: 362470e0 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:48,446 - INFO - Current best: 4e37bbde with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:48,446 - INFO - Current best: 376a667c with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:48,446 - INFO - Current best: 81553241 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:48,446 - INFO - Cleaning up trial 717586ed
2025-06-03 17:22:48,446 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-03_17-19-50/train_hpo_717586ed_8_learning_rate=0.0000,num_train_epochs=2,pos_weight=7.9783,weight_decay=0.1851_2025-06-03_17-21-14
2025-06-03 17:22:48,446 - INFO - Current best: 2753649d with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:48,446 - INFO - Current best: 3fb36b31 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:51,376 - INFO - Cleaning up trial 0b66afdd
2025-06-03 17:22:51,376 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-03_17-19-50/train_hpo_0b66afdd_12_learning_rate=0.0000,num_train_epochs=4,pos_weight=4.2263,weight_decay=0.2637_2025-06-03_17-22-10
2025-06-03 17:22:51,376 - INFO - Current best: dfc200b7 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:51,376 - INFO - Current best: cdf89bf1 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:51,376 - INFO - Current best: 362470e0 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:51,376 - INFO - Current best: 4e37bbde with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:51,376 - INFO - Current best: 376a667c with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:51,376 - INFO - Current best: 81553241 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:51,376 - INFO - Cleaning up trial 717586ed
2025-06-03 17:22:51,376 - INFO - Trial path: /home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-03_17-19-50/train_hpo_717586ed_8_learning_rate=0.0000,num_train_epochs=2,pos_weight=7.9783,weight_decay=0.1851_2025-06-03_17-21-14
2025-06-03 17:22:51,377 - INFO - Current best: 2753649d with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:51,377 - INFO - Current best: 3fb36b31 with eval_f1 : 0.8521739130434782 at iteration 1
2025-06-03 17:22:51,377 - INFO - Current best: 5d396941 with eval_f1 : 0.8521739130434782 at iteration 1
[36m(train_hpo pid=3202107)[0m /home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2708: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
[36m(train_hpo pid=3202107)[0m   warnings.warn(
2025-06-03 17:22:51,387	INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/leandre/Projects/BioMoQA_Playground/results/biomoqa/ray_results/train_hpo_2025-06-03_17-19-50' in 0.0085s.


Trial train_hpo_2753649d completed after 1 iterations at 2025-06-03 17:22:29. Total running time: 2min 38s
[36m(train_hpo pid=3202107)[0m STATE at beggining of training :  TrainerState(epoch=0, global_step=0, max_steps=8, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=4, num_input_tokens_seen=0, total_flos=0, log_history=[], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': False, 'should_epoch_stop': False, 'should_save': False, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3202107)[0m {'loss': 1.9934, 'grad_norm': 18.681198120117188, 'learning_rate': 1.5541050291109533e-05, 'epoch': 0.7272727272727273}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3202107)[0m {'loss': 1.4451, 'grad_norm': 6.579748153686523, 'learning_rate': 5.180350097036511e-06, 'epoch': 2.7272727272727275}[32m [repeated 4x across cluster][0m
[36m(train_hpo pid=3201586)[0m {'train_runtime': 29.5964, 'train_samples_per_second': 40.14, 'train_steps_per_second': 0.405, 'train_loss': 2.665424426396688, 'epoch': 5.7272727272727275}
[36m(train_hpo pid=3201586)[0m STATE at ending of training  :  TrainerState(epoch=5.7272727272727275, global_step=12, max_steps=12, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=6, num_input_tokens_seen=0, total_flos=289945779677184.0, log_history=[{'loss': 5.8326, 'grad_norm': 59.47175216674805, 'learning_rate': 2.6926604377058517e-05, 'epoch': 0.7272727272727273, 'step': 2}, {'loss': 3.4807, 'grad_norm': 29.456336975097656, 'learning_rate': 2.154128350164681e-05, 'epoch': 1.7272727272727273, 'step': 4}, {'loss': 2.1626, 'grad_norm': 15.562984466552734, 'learning_rate': 1.615596262623511e-05, 'epoch': 2.7272727272727275, 'step': 6}, {'loss': 1.7746, 'grad_norm': 12.002083778381348, 'learning_rate': 1.0770641750823405e-05, 'epoch': 3.7272727272727275, 'step': 8}, {'loss': 1.5739, 'grad_norm': 8.310640335083008, 'learning_rate': 5.3853208754117024e-06, 'epoch': 4.7272727272727275, 'step': 10}, {'loss': 1.1682, 'grad_norm': 9.574240684509277, 'learning_rate': 0.0, 'epoch': 5.7272727272727275, 'step': 12}, {'train_runtime': 29.5964, 'train_samples_per_second': 40.14, 'train_steps_per_second': 0.405, 'total_flos': 289945779677184.0, 'train_loss': 2.665424426396688, 'epoch': 5.7272727272727275, 'step': 12}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': True, 'should_epoch_stop': False, 'should_save': True, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3202107)[0m STATE at ending of training  :  TrainerState(epoch=3.7272727272727275, global_step=8, max_steps=8, logging_steps=500, eval_steps=500, save_steps=500, train_batch_size=19, num_train_epochs=4, num_input_tokens_seen=0, total_flos=189964476340224.0, log_history=[{'loss': 1.9934, 'grad_norm': 18.681198120117188, 'learning_rate': 1.5541050291109533e-05, 'epoch': 0.7272727272727273, 'step': 2}, {'loss': 1.6525, 'grad_norm': 13.347107887268066, 'learning_rate': 1.0360700194073021e-05, 'epoch': 1.7272727272727273, 'step': 4}, {'loss': 1.4451, 'grad_norm': 6.579748153686523, 'learning_rate': 5.180350097036511e-06, 'epoch': 2.7272727272727275, 'step': 6}, {'loss': 1.0644, 'grad_norm': 7.894918441772461, 'learning_rate': 0.0, 'epoch': 3.7272727272727275, 'step': 8}, {'train_runtime': 16.7646, 'train_samples_per_second': 47.242, 'train_steps_per_second': 0.477, 'total_flos': 189964476340224.0, 'train_loss': 1.5388540029525757, 'epoch': 3.7272727272727275, 'step': 8}], best_metric=None, best_model_checkpoint=None, is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None, stateful_callbacks={'TrainerControl': {'args': {'should_training_stop': True, 'should_epoch_stop': False, 'should_save': True, 'should_evaluate': False, 'should_log': False}, 'attributes': {}}})
[36m(train_hpo pid=3202107)[0m {'loss': 1.0644, 'grad_norm': 7.894918441772461, 'learning_rate': 0.0, 'epoch': 3.7272727272727275}[32m [repeated 2x across cluster][0m
[36m(train_hpo pid=3201586)[0m {'eval_loss': 1.1111011505126953, 'eval_f1': 0.8521739130434782, 'eval_recall': 1.0, 'eval_accuracy': 0.7424242424242424, 'eval_precision': 0.7424242424242424, 'eval_optim_threshold': 0.9058770537376404, 'eval_runtime': 3.5349, 'eval_samples_per_second': 18.671, 'eval_steps_per_second': 1.132, 'epoch': 5.7272727272727275}

Trial train_hpo_5d396941 finished iteration 1 at 2025-06-03 17:22:48. Total running time: 2min 57s
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_5d396941 result             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ checkpoint_dir_name                         ‚îÇ
‚îÇ time_this_iter_s                    37.8283 ‚îÇ
‚îÇ time_total_s                        37.8283 ‚îÇ
‚îÇ training_iteration                        1 ‚îÇ
‚îÇ epoch                               5.72727 ‚îÇ
‚îÇ eval_accuracy                       0.74242 ‚îÇ
‚îÇ eval_f1                             0.85217 ‚îÇ
‚îÇ eval_loss                            1.1111 ‚îÇ
‚îÇ eval_optim_threshold                0.90588 ‚îÇ
‚îÇ eval_precision                      0.74242 ‚îÇ
‚îÇ eval_recall                               1 ‚îÇ
‚îÇ eval_runtime                         3.5349 ‚îÇ
‚îÇ eval_samples_per_second              18.671 ‚îÇ
‚îÇ eval_steps_per_second                 1.132 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

Trial train_hpo_5d396941 completed after 1 iterations at 2025-06-03 17:22:48. Total running time: 2min 57s

Trial train_hpo_0b66afdd finished iteration 1 at 2025-06-03 17:22:51. Total running time: 3min 0s
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial train_hpo_0b66afdd result             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ checkpoint_dir_name                         ‚îÇ
‚îÇ time_this_iter_s                    24.6339 ‚îÇ
‚îÇ time_total_s                        24.6339 ‚îÇ
‚îÇ training_iteration                        1 ‚îÇ
‚îÇ epoch                               3.72727 ‚îÇ
‚îÇ eval_accuracy                       0.74242 ‚îÇ
‚îÇ eval_f1                             0.85217 ‚îÇ
‚îÇ eval_loss                           1.02685 ‚îÇ
‚îÇ eval_optim_threshold                 0.8092 ‚îÇ
‚îÇ eval_precision                      0.74242 ‚îÇ
‚îÇ eval_recall                               1 ‚îÇ
‚îÇ eval_runtime                         3.2543 ‚îÇ
‚îÇ eval_samples_per_second              20.281 ‚îÇ
‚îÇ eval_steps_per_second                 1.229 ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

Trial train_hpo_0b66afdd completed after 1 iterations at 2025-06-03 17:22:51. Total running time: 3min 0s
[36m(train_hpo pid=3202107)[0m {'train_runtime': 16.7646, 'train_samples_per_second': 47.242, 'train_steps_per_second': 0.477, 'train_loss': 1.5388540029525757, 'epoch': 3.7272727272727275}

Trial status: 11 TERMINATED | 1 ERROR
Current time: 2025-06-03 17:22:51. Total running time: 3min 0s
Logical resource usage: 10.0/32 CPUs, 1.0/3 GPUs (0.0/1.0 accelerator_type:A100D)
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial name           status         pos_weight     learning_rate     weight_decay     num_train_epochs     iter     total time (s)     eval_loss     eval_f1     eval_recall     eval_accuracy ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ train_hpo_dfc200b7   TERMINATED        8.49369       1.49561e-06       0.13641                       6        1            52.3332       3.04215    0.852174        1                 0.742424 ‚îÇ
‚îÇ train_hpo_cdf89bf1   TERMINATED        7.54953       4.55539e-06       0.123031                      5        1            47.9327       3.29573    0.852174        1                 0.742424 ‚îÇ
‚îÇ train_hpo_362470e0   TERMINATED        8.94984       7.98818e-05       0.251217                      3        1            20.9872       1.07363    0.852174        1                 0.742424 ‚îÇ
‚îÇ train_hpo_4e37bbde   TERMINATED        9.2685        1.10121e-06       0.13345                       4        1            24.8281       4.36941    0.852174        1                 0.742424 ‚îÇ
‚îÇ train_hpo_376a667c   TERMINATED        4.94226       2.70039e-05       0.239866                      3        1            34.9803       1.45859    0.852174        1                 0.742424 ‚îÇ
‚îÇ train_hpo_81553241   TERMINATED        9.45433       4.00602e-05       0.220208                      4        1            24.714        1.26691    0.852174        1                 0.742424 ‚îÇ
‚îÇ train_hpo_717586ed   TERMINATED        7.97828       2.7847e-06        0.185124                      2        1            18.8321       4.30143    0.582278        0.469388          0.5      ‚îÇ
‚îÇ train_hpo_2753649d   TERMINATED        9.28008       4.73492e-05       0.163021                      6        1            38.3821       1.08045    0.852174        1                 0.742424 ‚îÇ
‚îÇ train_hpo_3fb36b31   TERMINATED        7.30559       6.78644e-06       0.286643                      3        1            21.0466       2.23463    0.852174        1                 0.742424 ‚îÇ
‚îÇ train_hpo_5d396941   TERMINATED        8.36047       3.23119e-05       0.00108909                    6        1            37.8283       1.1111     0.852174        1                 0.742424 ‚îÇ
‚îÇ train_hpo_0b66afdd   TERMINATED        4.22633       2.07214e-05       0.263741                      4        1            24.6339       1.02685    0.852174        1                 0.742424 ‚îÇ
‚îÇ train_hpo_4c09466a   ERROR             2.54684       4.03208e-05       0.243719                      5                                                                                         ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

Number of errored trials: 1
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Trial name             # failures   error file                                                                                                                                                                                                                                                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ train_hpo_4c09466a              1   /tmp/ray/session_2025-06-03_17-19-23_431813_3194092/artifacts/2025-06-03_17-19-50/train_hpo_2025-06-03_17-19-50/driver_artifacts/train_hpo_4c09466a_5_learning_rate=0.0000,num_train_epochs=5,pos_weight=2.5468,weight_decay=0.2437_2025-06-03_17-20-41/error.txt ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

Traceback (most recent call last):
  File "/home/leandre/Projects/BioMoQA_Playground/experiments/biomoqa.py", line 54, in <module>
    main()
  File "/home/leandre/Projects/BioMoQA_Playground/experiments/biomoqa.py", line 43, in main
    pipeline.whole_pipeline()
  File "/home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/binary_pipeline.py", line 508, in whole_pipeline
    avg_ens_metrics=self.run_pipeline()
                    ^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/binary_pipeline.py", line 433, in run_pipeline
    scores_by_fold = self.train(model_name=model_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/src/models/biomoqa/binary_pipeline.py", line 250, in train
    analysis = tune.run(
               ^^^^^^^^^
  File "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/ray/tune/tune.py", line 1035, in run
    raise TuneError("Trials did not complete", incomplete_trials)
ray.tune.error.TuneError: ('Trials did not complete', [train_hpo_4c09466a])
[36m(train_hpo pid=3202107)[0m 2025-06-03 17:22:51,308 - INFO - ROC curve saved to /home/leandre/Projects/BioMoQA_Playground/plots/roc_curve_val.png
[36m(train_hpo pid=3202107)[0m 2025-06-03 17:22:51,310 - INFO - eval_result: {'eval_loss': 1.0268479585647583, 'eval_f1': 0.8521739130434782, 'eval_recall': 1.0, 'eval_accuracy': 0.7424242424242424, 'eval_precision': 0.7424242424242424, 'eval_optim_threshold': 0.8091970086097717, 'eval_runtime': 3.2543, 'eval_samples_per_second': 20.281, 'eval_steps_per_second': 1.229, 'epoch': 3.7272727272727275}
[36m(train_hpo pid=3202107)[0m 2025-06-03 17:22:51,347 - INFO - Cleared CUDA cache. Memory allocated: 1.33 GB, Memory reserved: 1.58 GB
[36m(train_hpo pid=3202107)[0m {'eval_loss': 1.0268479585647583, 'eval_f1': 0.8521739130434782, 'eval_recall': 1.0, 'eval_accuracy': 0.7424242424242424, 'eval_precision': 0.7424242424242424, 'eval_optim_threshold': 0.8091970086097717, 'eval_runtime': 3.2543, 'eval_samples_per_second': 20.281, 'eval_steps_per_second': 1.229, 'epoch': 3.7272727272727275}
