{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Data description :\n",
    "\n",
    "The dataset used in this project is a corpus of scientific abstract associated with a human supervized label describing whether the abstract is relevant or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "Here we load the data files (that are scattered in different directories), into one dataset for positives and negatives.\n",
    "\n",
    "We also consider only instances that have a doi value (we reject None values)\n",
    "\n",
    "The other we do is that we extract positives and negatives from the corpus with the help of the given positive data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "Successfully loaded dataset from: /home/leandre/Projects/BioMoQA_Playground/data/corpus/Raw/Positives/IPBES IAS_2352922\n",
      "86\n",
      "Successfully loaded dataset from: /home/leandre/Projects/BioMoQA_Playground/data/corpus/Raw/Positives/IPBES SUA_2344805\n",
      "128\n",
      "Successfully loaded dataset from: /home/leandre/Projects/BioMoQA_Playground/data/corpus/Raw/Positives/IPBES VA_2345372\n",
      "{'DOI': Value(dtype='string', id=None), 'Title': Value(dtype='string', id=None), 'Abstract Note': Value(dtype='string', id=None), 'Language': Value(dtype='string', id=None)}\n",
      "creating corpus dataset\n",
      "dataset loaded\n",
      "['id', 'display_name', 'author', 'ab', 'doi', 'topics', 'author_abbr']\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=32): 100%|██████████| 4227131/4227131 [00:47<00:00, 89714.49 examples/s] \n",
      "Filter (num_proc=32): 100%|██████████| 4227131/4227131 [00:32<00:00, 131807.85 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Finished positives and negatives creation pipeline\n",
      "corpus columns : {'id': Value(dtype='string', id=None), 'display_name': Value(dtype='string', id=None), 'author': [{'au_id': Value(dtype='string', id=None), 'au_display_name': Value(dtype='string', id=None), 'au_orcid': Value(dtype='string', id=None), 'author_position': Value(dtype='string', id=None), 'is_corresponding': Value(dtype='bool', id=None), 'au_affiliation_raw': Value(dtype='string', id=None), 'institution_id': Value(dtype='string', id=None), 'institution_display_name': Value(dtype='string', id=None), 'institution_ror': Value(dtype='string', id=None), 'institution_country_code': Value(dtype='string', id=None), 'institution_type': Value(dtype='string', id=None), 'institution_lineage': Value(dtype='string', id=None)}], 'ab': Value(dtype='string', id=None), 'doi': Value(dtype='string', id=None), 'topics': [{'i': Value(dtype='int32', id=None), 'score': Value(dtype='float64', id=None), 'name': Value(dtype='string', id=None), 'id': Value(dtype='string', id=None), 'display_name': Value(dtype='string', id=None)}], 'author_abbr': Value(dtype='string', id=None)}\n",
      "positives columns : {'doi': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'abstract': Value(dtype='string', id=None)}\n",
      "negatives columns : {'title': Value(dtype='string', id=None), 'abstract': Value(dtype='string', id=None), 'doi': Value(dtype='string', id=None)}\n",
      "corpus size : 4227131\n",
      "positives size : 5251\n",
      "negatives size : 4190054\n",
      "128\n",
      "Successfully loaded dataset from: /home/leandre/Projects/BioMoQA_Playground/data/corpus/Raw/Positives/IPBES IAS_2352922\n",
      "86\n",
      "Successfully loaded dataset from: /home/leandre/Projects/BioMoQA_Playground/data/corpus/Raw/Positives/IPBES SUA_2344805\n",
      "128\n",
      "Successfully loaded dataset from: /home/leandre/Projects/BioMoQA_Playground/data/corpus/Raw/Positives/IPBES VA_2345372\n"
     ]
    }
   ],
   "source": [
    "from create_ipbes_raw import *\n",
    "\n",
    "pos_ds, neg_ds, corpus_ds=loading_pipeline_from_raw()\n",
    "print(\"corpus columns :\",corpus_ds.features)\n",
    "print(\"positives columns :\",pos_ds[0].features)\n",
    "print(\"negatives columns :\",neg_ds[0].features)\n",
    "\n",
    "print(\"corpus size :\",len(corpus_ds))\n",
    "print(\"positives size :\",len(pos_ds[0]))\n",
    "print(\"negatives size :\",len(neg_ds[0]))\n",
    "\n",
    "pos_raw=get_ipbes_positives()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset({\n",
      "    features: ['doi', 'title', 'abstract'],\n",
      "    num_rows: 5251\n",
      "}), Dataset({\n",
      "    features: ['doi', 'title', 'abstract'],\n",
      "    num_rows: 6281\n",
      "}), Dataset({\n",
      "    features: ['doi', 'title', 'abstract'],\n",
      "    num_rows: 3109\n",
      "})]\n",
      "[Dataset({\n",
      "    features: ['title', 'abstract', 'doi'],\n",
      "    num_rows: 4190054\n",
      "}), Dataset({\n",
      "    features: ['title', 'abstract', 'doi'],\n",
      "    num_rows: 4190005\n",
      "}), Dataset({\n",
      "    features: ['title', 'abstract', 'doi'],\n",
      "    num_rows: 4185398\n",
      "})]\n"
     ]
    }
   ],
   "source": [
    "print(pos_ds)\n",
    "print(neg_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'display_name', 'author', 'ab', 'doi', 'topics', 'author_abbr']\n",
      "{'id': 'https://openalex.org/W1979751022', 'display_name': 'Observations on an apparatus to illustrate the composition and resolution forces, and to measure the power obtained by certain parts of machinery operating on this principle', 'author': [{'au_id': 'https://openalex.org/A5055018967', 'au_display_name': 'W. R. Johnson', 'au_orcid': None, 'author_position': 'first', 'is_corresponding': True, 'au_affiliation_raw': '', 'institution_id': None, 'institution_display_name': None, 'institution_ror': None, 'institution_country_code': None, 'institution_type': None, 'institution_lineage': None}], 'ab': \"Physical components of societies like infrastructures need biophysical resources for their construction, maintenance and use. These components, analyzed as societies' material stocks, predefine energy and raw materials and provide societal services, necessary for their functioning and for social welfare. The nexus between stocks, the resource flows and the services, is crucial for the analysis of social-ecological transformations. In this paper, we build on recent work in socio-metabolic research on the stock-flow-service nexus and develop a conceptual approach how to examine this nexus while addressing the challenges of social-ecological transformations. We refer to the concept of provisioning systems to analyze the institutions, technologies, knowledge and practices mediating between actors and resources but also the power relations involved in the creation and transformation of this nexus. It enables us to understand how specific stock-flow-service nexuses are constructed, which lock-in effects result from specific stock-flow-service configurations and which options can be envisaged for its transformation towards lower resource use. We argue that provisioning systems need to be analyzed as structuring space and time as well as embedded within the contested terrain of the state. By providing this conceptualization, we aim to offer an understanding which can help to define options for the transformation of the stock-flow-service nexus in a transdisciplinary process.\", 'doi': 'https://doi.org/10.1016/s0016-0032(29)90208-8', 'topics': [{'i': 1, 'score': 0.8759, 'name': 'topic', 'id': 'https://openalex.org/T10435', 'display_name': 'Life Cycle Assessment and Environmental Impact Analysis'}, {'i': 1, 'score': 0.8759, 'name': 'subfield', 'id': 'https://openalex.org/subfields/2305', 'display_name': 'Environmental Engineering'}, {'i': 1, 'score': 0.8759, 'name': 'field', 'id': 'https://openalex.org/fields/23', 'display_name': 'Environmental Science'}, {'i': 1, 'score': 0.8759, 'name': 'domain', 'id': 'https://openalex.org/domains/3', 'display_name': 'Physical Sciences'}, {'i': 2, 'score': 0.8448, 'name': 'topic', 'id': 'https://openalex.org/T11336', 'display_name': 'Indoor Air Pollution in Developing Countries'}, {'i': 2, 'score': 0.8448, 'name': 'subfield', 'id': 'https://openalex.org/subfields/2310', 'display_name': 'Pollution'}, {'i': 2, 'score': 0.8448, 'name': 'field', 'id': 'https://openalex.org/fields/23', 'display_name': 'Environmental Science'}, {'i': 2, 'score': 0.8448, 'name': 'domain', 'id': 'https://openalex.org/domains/3', 'display_name': 'Physical Sciences'}, {'i': 3, 'score': 0.8394, 'name': 'topic', 'id': 'https://openalex.org/T11091', 'display_name': 'Battery Recycling and Rare Earth Recovery'}, {'i': 3, 'score': 0.8394, 'name': 'subfield', 'id': 'https://openalex.org/subfields/2210', 'display_name': 'Mechanical Engineering'}, {'i': 3, 'score': 0.8394, 'name': 'field', 'id': 'https://openalex.org/fields/22', 'display_name': 'Engineering'}, {'i': 3, 'score': 0.8394, 'name': 'domain', 'id': 'https://openalex.org/domains/3', 'display_name': 'Physical Sciences'}], 'author_abbr': 'Johnson (1829)'}\n"
     ]
    }
   ],
   "source": [
    "print(corpus_ds.column_names)\n",
    "print(corpus_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5251\n",
      "2657\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_raw[0][\"Abstract Note\"]))\n",
    "new_pos_raw=pos_raw[0].filter(lambda x: x[\"Abstract Note\"] != None)\n",
    "print(len(new_pos_raw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'display_name', 'author', 'ab', 'doi', 'topics', 'author_abbr'],\n",
      "    num_rows: 4227131\n",
      "})\n",
      "[Dataset({\n",
      "    features: ['doi', 'title', 'abstract', 'Language'],\n",
      "    num_rows: 5251\n",
      "}), Dataset({\n",
      "    features: ['doi', 'title', 'abstract', 'Language'],\n",
      "    num_rows: 6281\n",
      "}), Dataset({\n",
      "    features: ['doi', 'title', 'abstract', 'Language'],\n",
      "    num_rows: 3109\n",
      "})]\n",
      "0\n",
      "titles_set size : 5228\n",
      "abs_set size : 2653\n",
      "dois_set size : 3861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=32): 100%|██████████| 4227131/4227131 [01:02<00:00, 67720.70 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'display_name', 'author', 'ab', 'doi', 'topics', 'author_abbr'],\n",
      "    num_rows: 1161\n",
      "})\n",
      "1\n",
      "titles_set size : 6169\n",
      "abs_set size : 1368\n",
      "dois_set size : 2919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=32): 100%|██████████| 4227131/4227131 [00:48<00:00, 86788.27 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'display_name', 'author', 'ab', 'doi', 'topics', 'author_abbr'],\n",
      "    num_rows: 1191\n",
      "})\n",
      "2\n",
      "titles_set size : 2945\n",
      "abs_set size : 2069\n",
      "dois_set size : 1892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=32): 100%|██████████| 4227131/4227131 [00:32<00:00, 131456.24 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'display_name', 'author', 'ab', 'doi', 'topics', 'author_abbr'],\n",
      "    num_rows: 723\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(corpus_ds)\n",
    "print(pos_ds)\n",
    "\n",
    "corpus_pos_ds=[]\n",
    "for i in range(len(pos_ds)):\n",
    "    print(i)\n",
    "    abs_set=set(e.strip() for e in pos_ds[i]['abstract'] if e is not None)\n",
    "    titles_set=set(e.strip() for e in pos_ds[i]['title'] if e is not None)\n",
    "    dois_set=set(e.strip() for e in pos_ds[i]['doi'] if e is not None)\n",
    "    if None in dois_set : dois_set.remove(None) \n",
    "    if None in titles_set : titles_set.remove(None) \n",
    "    if None in abs_set : abs_set.remove(None) \n",
    "    print(\"titles_set size :\",len(titles_set))\n",
    "    print(\"abs_set size :\",len(abs_set))\n",
    "    print(\"dois_set size :\",len(dois_set))\n",
    "\n",
    "    seen_abstracts=set()\n",
    "    seen_titles=set()\n",
    "    seen_dois=set()\n",
    "    def find(batch):\n",
    "        batch_bools=[]\n",
    "        for j in range(len(batch['display_name'])):\n",
    "            title=batch['display_name'][j]\n",
    "            title=title.strip() if title is not None else None\n",
    "            abstract=batch['ab'][j]\n",
    "            abstract=abstract.strip() if abstract is not None else None\n",
    "            doi=batch['doi'][j]\n",
    "            doi=doi.strip() if doi is not None else None\n",
    "            \n",
    "            if (abstract in abs_set) and (abstract not in seen_abstracts):\n",
    "                seen_abstracts.add(abstract)\n",
    "                batch_bools.append(True)\n",
    "            elif (title in titles_set) and (title not in seen_titles):\n",
    "                seen_titles.add(title)\n",
    "                batch_bools.append(True)\n",
    "            elif (doi is not None) and(any(doi.endswith(p_doi) for p_doi in dois_set)) and (doi not in seen_dois):\n",
    "                batch_bools.append(True)\n",
    "                seen_dois.add(doi)\n",
    "            else:\n",
    "                batch_bools.append(False)\n",
    "        return batch_bools\n",
    "    temp_ds=corpus_ds.filter(find, batched=True, batch_size=1000,num_proc=32)\n",
    "    corpus_pos_ds.append(temp_ds)\n",
    "    print(temp_ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=32): 100%|██████████| 5251/5251 [00:00<00:00, 19313.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['doi', 'title', 'abstract'],\n",
      "    num_rows: 0\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def is_weird(batch):\n",
    "    batch_bools=[]\n",
    "    for j in range(len(batch['title'])):\n",
    "        title=batch['title'][j]\n",
    "        abstract=batch['abstract'][j]\n",
    "        doi=batch['doi'][j]\n",
    "        if doi =='DOI':\n",
    "            batch_bools.append(True)\n",
    "        elif title == 'Title':\n",
    "            batch_bools.append(True)\n",
    "        elif abstract == 'Abstract Note':\n",
    "            batch_bools.append(True)\n",
    "        else:\n",
    "            batch_bools.append(False)\n",
    "    return batch_bools\n",
    "\n",
    "weird_pos=pos_ds[0].filter(is_weird, batched=True, batch_size=1000,num_proc=32)\n",
    "print(weird_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Convert corpus_ds to a set for faster lookups\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m abstract_set = \u001b[38;5;28mset\u001b[39m(\u001b[43mcorpus_ds\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mab\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      3\u001b[39m title_set = \u001b[38;5;28mset\u001b[39m(corpus_ds[\u001b[33m'\u001b[39m\u001b[33mdisplay_name\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Check for matches based on Abstract\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'corpus_ds' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert corpus_ds to a set for faster lookups\n",
    "abstract_set = set(corpus_ds['ab'])\n",
    "title_set = set(corpus_ds['display_name'])\n",
    "\n",
    "# Check for matches based on Abstract\n",
    "abstract_matches = []\n",
    "for pos_dataset in pos_raw:\n",
    "    matches = pos_dataset.filter(lambda x: x['Abstract Note'] in abstract_set)\n",
    "    abstract_matches.append(matches)\n",
    "\n",
    "# Check for matches based on Title\n",
    "title_matches = []\n",
    "for pos_dataset in pos_raw:\n",
    "    matches = pos_dataset.filter(lambda x: x['Title'] in title_set)\n",
    "    title_matches.append(matches)\n",
    "\n",
    "# Print results\n",
    "print(\"Matches based on abstract:\")\n",
    "for i, match in enumerate(abstract_matches):\n",
    "    print(f\"Dataset {i}: {len(match)} matches\")\n",
    "\n",
    "print(\"\\nMatches based on Title:\")\n",
    "for i, match in enumerate(title_matches):\n",
    "    print(f\"Dataset {i}: {len(match)} matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 128/128 [00:00<00:00, 319566.02files/s]\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading files from /home/leandre/Projects/BioMoQA_Playground/data/corpus/Raw/Positives/IPBES IAS_2352922: An error occurred while generating the dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 86/86 [00:00<00:00, 283131.98files/s]\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading files from /home/leandre/Projects/BioMoQA_Playground/data/corpus/Raw/Positives/IPBES SUA_2344805: An error occurred while generating the dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 128/128 [00:00<00:00, 295796.65files/s]\n",
      "Generating train split: 0 examples [00:00, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading files from /home/leandre/Projects/BioMoQA_Playground/data/corpus/Raw/Positives/IPBES VA_2345372: An error occurred while generating the dataset\n",
      "[]\n",
      "positives raw size : []\n",
      "positives raw columns : []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(pos_raw)\n",
    "print(\"positives raw size :\",[len(pos_raw[i]) for i in range(len(pos_raw))])\n",
    "print(\"positives raw columns :\",[pos_raw[i].features for i in range(len(pos_raw))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing\n",
    "\n",
    "Now that we have loaded the data we are able to clean them and pre-process them in order to give them to the model.\n",
    "\n",
    "In particular what we want to do is :\n",
    "- Reject abstracts with None values\n",
    "- Manage duplicates\n",
    "- Manage conflicts (cases wher you have an isntance in both positives and negatives)\n",
    "- Consider only journal articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'https://openalex.org/W2099622325', 'display_name': 'Habitat and Community Modification by An Introduced Herbivorous Snail', 'author': [{'au_id': 'https://openalex.org/A5033598790', 'au_display_name': 'Mark D. Bertness', 'au_orcid': None, 'author_position': 'first', 'is_corresponding': True, 'au_affiliation_raw': '', 'institution_id': None, 'institution_display_name': None, 'institution_ror': None, 'institution_country_code': None, 'institution_type': None, 'institution_lineage': None}], 'ab': 'Experimental removal of the introduced herbivorous snail Littorina littorea from a protected New England rocky beach resulted in rapid habitat and community changes. At normal snail densities, L. littorea grazing bulldozes sediments from hard substrate and precludes the presence of an algal canopy. Snail removal resulted in rapid sediment accumulation and the development of an algal canopy, which accelerated sedimentation and bound sediment to hard substrate. These changes led to the increased success of organisms characteristic of soft—sediment habitats, such as polychaetes, tubiculous amphipods, mud crabs, and mud snails, and decreased success of organisms characteristic of hard—substrate habitats, such as barnacles and encrusting algae. Snail removal also significantly influenced the success of the marsh grass Spartina alterniflora. L. littorea consumes the shoots and rhizomes of marsh grass, as well as mediating sediment accumulation, which is necessary for vegetative expansion of root mat. Removal of L. littorea resulted in expansion of the littoral area dominated by S. alterniflora, as well as increased productivity of the marsh grass. These results suggest that the North American invasion of the European periwinkle has altered habitats and communities in protected littoral waters. Prior to the introduction of L. littorea, soft—bottomed littoral habitats and fringing salt marsh environments may have been more common that they are presently. Herbivorous snails in general may have an important habitat—modifying effect in protected marine communities that has not been appreciated previously.', 'doi': 'https://doi.org/10.2307/1941400', 'topics': [{'i': 1, 'score': 0.9991, 'name': 'topic', 'id': 'https://openalex.org/T10779', 'display_name': 'Importance of Mangrove Ecosystems in Coastal Protection'}, {'i': 1, 'score': 0.9991, 'name': 'subfield', 'id': 'https://openalex.org/subfields/2303', 'display_name': 'Ecology'}, {'i': 1, 'score': 0.9991, 'name': 'field', 'id': 'https://openalex.org/fields/23', 'display_name': 'Environmental Science'}, {'i': 1, 'score': 0.9991, 'name': 'domain', 'id': 'https://openalex.org/domains/3', 'display_name': 'Physical Sciences'}, {'i': 2, 'score': 0.9989, 'name': 'topic', 'id': 'https://openalex.org/T10643', 'display_name': 'Ecological Dynamics of Marine Environments'}, {'i': 2, 'score': 0.9989, 'name': 'subfield', 'id': 'https://openalex.org/subfields/1910', 'display_name': 'Oceanography'}, {'i': 2, 'score': 0.9989, 'name': 'field', 'id': 'https://openalex.org/fields/19', 'display_name': 'Earth and Planetary Sciences'}, {'i': 2, 'score': 0.9989, 'name': 'domain', 'id': 'https://openalex.org/domains/3', 'display_name': 'Physical Sciences'}, {'i': 3, 'score': 0.9886, 'name': 'topic', 'id': 'https://openalex.org/T10765', 'display_name': 'Marine Biodiversity and Ecosystem Functioning'}, {'i': 3, 'score': 0.9886, 'name': 'subfield', 'id': 'https://openalex.org/subfields/1910', 'display_name': 'Oceanography'}, {'i': 3, 'score': 0.9886, 'name': 'field', 'id': 'https://openalex.org/fields/19', 'display_name': 'Earth and Planetary Sciences'}, {'i': 3, 'score': 0.9886, 'name': 'domain', 'id': 'https://openalex.org/domains/3', 'display_name': 'Physical Sciences'}], 'author_abbr': 'Bertness (1984)'}\n"
     ]
    }
   ],
   "source": [
    "print(pos_ds[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IAS :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leandre/Projects/BioMoQA_Playground/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "Successfully loaded dataset from: /home/leandre/Projects/BioMoQA_Playground/data/corpus/Raw/Positives/IPBES IAS_2352922\n",
      "86\n",
      "Successfully loaded dataset from: /home/leandre/Projects/BioMoQA_Playground/data/corpus/Raw/Positives/IPBES SUA_2344805\n",
      "128\n",
      "Successfully loaded dataset from: /home/leandre/Projects/BioMoQA_Playground/data/corpus/Raw/Positives/IPBES VA_2345372\n",
      "{'DOI': Value(dtype='string', id=None), 'Title': Value(dtype='string', id=None), 'Abstract Note': Value(dtype='string', id=None), 'Language': Value(dtype='string', id=None)}\n",
      "creating corpus dataset\n",
      "dataset loaded\n",
      "['id', 'display_name', 'author', 'ab', 'doi', 'topics', 'author_abbr']\n",
      "1\n",
      "2\n",
      "Finished positives and negatives creation pipeline\n",
      "Processing dataset for type: IAS\n",
      "Positive dataset size: 5251\n",
      "Negative dataset size: 4190054\n",
      "pos_ds size: 5251\n",
      "neg_ds size: 4190054\n",
      "Dataset({\n",
      "    features: ['doi', 'title', 'abstract', 'labels'],\n",
      "    num_rows: 4195305\n",
      "})\n",
      "5251\n",
      "Filtering out rows with no abstracts or DOI...\n",
      "Size of the dataset before cleaning: 4195305\n",
      "Applying clean_filter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=32): 100%|██████████| 4195305/4195305 [00:04<00:00, 952645.45 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['doi', 'title', 'abstract', 'labels'],\n",
      "    num_rows: 4114546\n",
      "})\n",
      "Processing dataset for type: SUA\n",
      "Positive dataset size: 6281\n",
      "Negative dataset size: 4190005\n",
      "pos_ds size: 6281\n",
      "neg_ds size: 4190005\n",
      "Dataset({\n",
      "    features: ['doi', 'title', 'abstract', 'labels'],\n",
      "    num_rows: 4196286\n",
      "})\n",
      "6281\n",
      "Filtering out rows with no abstracts or DOI...\n",
      "Size of the dataset before cleaning: 4196286\n",
      "Applying clean_filter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=32): 100%|██████████| 4196286/4196286 [00:05<00:00, 780807.76 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['doi', 'title', 'abstract', 'labels'],\n",
      "    num_rows: 4113318\n",
      "})\n",
      "Processing dataset for type: VA\n",
      "Positive dataset size: 3109\n",
      "Negative dataset size: 4185398\n",
      "pos_ds size: 3109\n",
      "neg_ds size: 4185398\n",
      "Dataset({\n",
      "    features: ['doi', 'title', 'abstract', 'labels'],\n",
      "    num_rows: 4188507\n",
      "})\n",
      "3109\n",
      "Filtering out rows with no abstracts or DOI...\n",
      "Size of the dataset before cleaning: 4188507\n",
      "Applying clean_filter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=32): 100%|██████████| 4188507/4188507 [00:04<00:00, 864190.78 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['doi', 'title', 'abstract', 'labels'],\n",
      "    num_rows: 4109595\n",
      "})\n",
      "Completed processing all datasets.\n",
      "{'IAS': (Dataset({\n",
      "    features: ['doi', 'title', 'abstract', 'labels'],\n",
      "    num_rows: 2880182\n",
      "}), Dataset({\n",
      "    features: ['doi', 'title', 'abstract', 'labels'],\n",
      "    num_rows: 1049209\n",
      "}), Dataset({\n",
      "    features: ['doi', 'title', 'abstract', 'labels'],\n",
      "    num_rows: 185155\n",
      "}), Dataset({\n",
      "    features: ['doi', 'title', 'abstract', 'labels'],\n",
      "    num_rows: 4114546\n",
      "})), 'SUA': (Dataset({\n",
      "    features: ['doi', 'title', 'abstract', 'labels'],\n",
      "    num_rows: 2879322\n",
      "}), Dataset({\n",
      "    features: ['doi', 'title', 'abstract', 'labels'],\n",
      "    num_rows: 1048896\n",
      "}), Dataset({\n",
      "    features: ['doi', 'title', 'abstract', 'labels'],\n",
      "    num_rows: 185100\n",
      "}), Dataset({\n",
      "    features: ['doi', 'title', 'abstract', 'labels'],\n",
      "    num_rows: 4113318\n",
      "})), 'VA': (Dataset({\n",
      "    features: ['doi', 'title', 'abstract', 'labels'],\n",
      "    num_rows: 2876716\n",
      "}), Dataset({\n",
      "    features: ['doi', 'title', 'abstract', 'labels'],\n",
      "    num_rows: 1047947\n",
      "}), Dataset({\n",
      "    features: ['doi', 'title', 'abstract', 'labels'],\n",
      "    num_rows: 184932\n",
      "}), Dataset({\n",
      "    features: ['doi', 'title', 'abstract', 'labels'],\n",
      "    num_rows: 4109595\n",
      "}))}\n"
     ]
    }
   ],
   "source": [
    "from preprocess_ipbes import *\n",
    "\n",
    "data_dict=data_pipeline()\n",
    "\n",
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
